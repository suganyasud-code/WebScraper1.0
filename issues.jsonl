{"summary":"ABFS: Support for new auth type: User-bound SAS","created":"2025-10-24T09:31:18.000+0000","description":"Adding support for new authentication type: user bound SAS","assignee":"Manika Joshi","priority":"Major","updated":"2025-10-24T11:45:38.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-24T09:44:17.799+0000]: manika137 opened a new pull request, #8051: URL: https://github.com/apache/hadoop/pull/8051 ### Description of PR Adding support for new authentication type: user bound SAS ### How was this patch tested? Test suite will be run for the patch\n[ASF GitHub Bot @ 2025-10-24T11:45:38.208+0000]: hadoop-yetus commented on PR #8051: URL: https://github.com/apache/hadoop/pull/8051#issuecomment-3442714485 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 20m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | markdownlint | 0m 0s | | markdownlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 5 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 34m 38s | | trunk passed | | +1 :green_heart: | compile | 0m 44s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 45s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 34s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 50s | | trunk passed | | +1 :green_heart: | javadoc | 0m 45s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 37s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 1m 23s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) | hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 26m 16s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | mvninstall | 0m 34s | [/patch-mvninstall-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-mvninstall-hadoop-tools_hadoop-azure.txt) | hadoop-azure in the patch failed. | | -1 :x: | compile | 0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) | hadoop-azure in the patch failed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) | hadoop-azure in the patch failed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) | hadoop-azure in the patch failed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 0m 35s | [/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-compile-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) | hadoop-azure in the patch failed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04. | | -1 :x: | blanks | 0m 0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/blanks-eol.txt) | The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply | | -0 :warning: | checkstyle | 0m 22s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) | hadoop-tools/hadoop-azure: The patch generated 36 new + 4 unchanged - 0 fixed = 40 total (was 4) | | -1 :x: | mvnsite | 0m 37s | [/patch-mvnsite-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-mvnsite-hadoop-tools_hadoop-azure.txt) | hadoop-azure in the patch failed. | | -1 :x: | javadoc | 0m 32s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) | hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 2 new + 1472 unchanged - 0 fixed = 1474 total (was 1472) | | -1 :x: | javadoc | 0m 30s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) | hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 2 new + 1413 unchanged - 0 fixed = 1415 total (was 1413) | | -1 :x: | spotbugs | 0m 34s | [/patch-spotbugs-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-spotbugs-hadoop-tools_hadoop-azure.txt) | hadoop-azure in the patch failed. | | +1 :green_heart: | shadedclient | 29m 4s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 41s | [/patch-unit-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/patch-unit-hadoop-tools_hadoop-azure.txt) | hadoop-azure in the patch failed. | | +1 :green_heart: | asflicense | 0m 34s | | The patch does not generate ASF License warnings. | | | | 119m 57s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8051 | | JIRA Issue | HADOOP-19736 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets markdownlint | | uname | Linux 88abe69cd96c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 05b52e40f1bc99edc039fc0d2ab5f83d1ceb0da9 | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/testReport/ | | Max. process+thread count | 779 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8051/1/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.","key":"HADOOP-19736","status":"Open","labels":"pull-request-available"}
{"summary":"ABFS: Adding request priority for prefetches","created":"2025-10-24T04:46:13.000+0000","description":"Adding low traffic request priority (behind a config flag) for prefetches to reduce load on server during throttling","assignee":"Manika Joshi","priority":"Major","updated":"2025-10-24T05:00:42.000+0000","commentText":"","key":"HADOOP-19735","status":"Open","labels":""}
{"summary":"S3A: retry on MPU completion failure \"One or more of the specified parts could not be found\"","created":"2025-10-23T15:42:38.000+0000","description":"\r\nExperienced transient failure in test run of https://github.com/apache/hadoop/pull/7882 : all MPU complete posts failed because the request or parts were not found...the tests started succeeding 60-90s later *and* a \"hadoop s3guards uploads\" call listed the outstanding uploads of the failing tests.\r\n\r\nHypothesis: a transient failure meant the server receiving the POST calls to complete the uploads was mistakenly reporting no upload IDs.\r\n\r\nOutcome: all active write operations failed, without any retry attempts. This can lose data and fail jobs, even though the store may recover.\r\n\r\nProposed. The multipart uploads, especially block output stream, retry on this error; treat it as a connectivity issue. ","assignee":"","priority":"Minor","updated":"2025-10-24T13:48:33.000+0000","commentText":"[Steve Loughran @ 2025-10-23T15:47:44.415+0000]: {code} [ERROR] ITestS3AHugeMagicCommits.test_030_postCreationAssertions:192 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: JAEYPCZ4P3JYGMTD, Extended Request ID: O/135mw9Xd2aEuFUh0ICWYc8DLXSpBUWaVGkEgEFGf0xO8o+XlZXY0hI+mvennOGt+C/UI7mNrQ=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeMagicCommits>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin in s3a://stevel-london/job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 Â» FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesArrayBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/bytebuffer/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: K0K75V8AH7SVBHS3, Extended Request ID: kDosbp+Z2PLZn9tVtRF9QfOqh1MgLbIKYaYFn2JeIptXlBV4v1a/wFukoXnaF7fCp6zx3vR8feE0fScUJEw+WhNW9lzu9dBxssOA62UA2kg=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 Â» FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src [ERROR] ITestS3AHugeFilesByteBufferBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/bytebuffer/src [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 73T4YAYRWE63WAW5, Extended Request ID: 6ucEY2heh2NsxE8dBrlZp9AE4Tb+hbvnyxea1/yp5H85BEvkQdYsfNlRH5XZM1g4hHPDSoGMVtM=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 Â» FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/disk/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: ZSY181YB49GQFR83, Extended Request ID: FrPEfsXO3Gbhxi3m4ZmyYSiyfscQ1QSm/1lKjRPLHEbLWH5vtGked+fHvZl281Dm6u013/5VP6pj42h4XISftk7p9uEIDGw31E7Ymcoviq4=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 Â» FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_040_PositionedReadHugeFile:478->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_050_readHugeFile:624->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesSSECDiskBlocks>AbstractSTestS3AHugeFiles.test_100_renameHugeFile:679->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/disk/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/disk/src [ERROR] ITestS3AHugeFilesStorageClass.test_010_CreateHugeFile:74->AbstractSTestS3AHugeFiles.test_010_CreateHugeFile:276 Â» AWSBadRequest Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: APYCQNP1GY02DGDE, Extended Request ID: lE0hQJ67sSwCYSMmO7tDEAvEIOCcpwIbLdfqqrNTpWT0bHIaacaIEzZusajj79rnFQlWudxsMHBIUXdS9ELiKR0T923lcULZy4Essx1LoTs=) (SDK Attempt Count: 1) [ERROR] ITestS3AHugeFilesStorageClass.test_030_postCreationAssertions:81->AbstractSTestS3AHugeFiles.test_030_postCreationAssertions:433 Â» FileNotFound Huge file: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesStorageClass>AbstractSTestS3AHugeFiles.test_045_vectoredIOHugeFile:538->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [ERROR] ITestS3AHugeFilesStorageClass.test_100_renameHugeFile:108->AbstractSTestS3AHugeFiles.assumeHugeFileExists:404->AbstractSTestS3AHugeFiles.assumeFileExists:414 Â» FileNotFound huge file not created: not found s3a://stevel-london/job-00/test/tests3ascale/array/src/hugefile in s3a://stevel-london/job-00/test/tests3ascale/array/src [INFO] [ERROR] Tests run: 124, Failures: 1, Errors: 30, Skipped: 13 [INFO] {code} This has to be some transient issue with my s3 london bucket, as if in progress upload parts were not being retained. Never seen this before; the expiry time is set to 24h When these uploads fail we do leave incomplete uploads in progress: {code} Listing uploads under path \"\" job-00-fork-0005/test/testCommitOperations 141OKG11JHhWF1GOnunHUd9ZzBJ8cUG9z0LsW_4wUGgCXCvDMQM3kRi5IOCUV8FdCHtg_w8SlipfubRtzCQoT5yEpOLv.cWOiOwjEaBzUjnuJORppfXuKy1piHpLnu98 job-00-fork-0005/test/testIfMatchTwoMultipartUploadsRaceConditionOneClosesFirst yBJpm3zh4DjNQIDtyWgEmWVCk5sehVz5Vzn3QGr_tQT2iOonRp5ErXsQy24yIvnzRxBCZqVapy5VepLeu2udZBT5EXLnKRA3bchvzjtKDlipywSzYlL2N_xLUDCT359I job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4 job-00-fork-0005/test/testMagicWriteRecovery/file.txt KpvoTuVh85Wzm9XuU1EuxbATjb6D.Zv8vEj3z2S6AvJBHCBssy4iphxNhTkLDs7ceEwak4IPtdXED1vRf3geXT7MRMJn8d6feafvHVEgzbD31odpzTLmOaPrU_mFQXGV job-00-fork-0005/test/testMagicWriteRecovery/file.txt CnrbWU3pzgEGvjRuDuaP43Xcv1eBF5aLknqYaZA1vwO3b1QUIu9QJSiZjuLMYKT9GKw1QXwqoKo4iuxTY1a18bARx4XMEiL98kZBv0TPMaAfXE.70Olh8Q2kTyDlUCSh job-00-fork-0005/test/testMagicWriteRecovery/file.txt dEVGPBRsuOAzL5pGA02ve9qJhAlNK8lb8khF6laKjo9U0j_aG1xLkHEfPLrmcrcsLxC3R755Yv_uKbzY_Vnoc.nXCprvutM1TZmLLN_7LHrQ0tY0IjYSS6hVzDVlHbvC job-00-fork-0006/test/restricted/testCommitEmptyFile/empty-commit.txt NOCjVJqycZhkalrvU26F5oIaJP51q055et2N6b74.2JVjiKL8KwrhOhdrtumOrZ2tZWNqaK4iKZ_iosqgehJOiPbWJwxvrfvA5V.dAUTLNqjtEf5tfWh0UXu.vahDy_S5SSgNLFXK.VB82i5MZtOcw-- job-00/test/tests3ascale/ITestS3AHugeMagicCommits/commit/commit.bin lsYNpdn_oiWLwEVvvM621hCvIwDVaL4y_bbwVpQouW1OBThA.P9cR8fZtxvBjGdMY41UH0dTjxGHtF3BXEY8WXqmcnO9QHs_Jy.os781pE3MGzqgzFyxmd0yN6LFcTbq test/restricted/testCommitEmptyFile/empty-commit.txt T3W9V56Bv_FMhKpgcBgJ1H2wOBkPKk23T0JomesBzZyqiIAu3NiROibAgoZUhWSdoTKSJoOgcn3UWYGOvGBbsHteS_N_c1QoTEp0GE7PNlzDfs1GheJ5SOpUgaEY6MaYdNe0mn0gY48FDXpVB2nqiA-- test/restricted/testCommitEmptyFile/empty-commit.txt .cr4b3xkfze4N24Bj3PAm_ACIyIVuTU4DueDktU1abNu2LJWXH2HKnUu1oOjfnnQwnUXp4VmXBVbZ5aq8E8gVCxN.Oyb7hmGVtESmRjpqIXSW80JrB_0_dqXe.uAT.JH7kEWywAlb4NIqJ5Xz99tvA-- Total 10 uploads found. {code} Most interesting here is `testIfNoneMatchTwoConcurrentMultipartUploads`, because this initiates then completes an MPU, so as to create a zero byte file. It doesn't upload any parts. The attempt to complete failed. {code} [ERROR] org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.testIfNoneMatchTwoConcurrentMultipartUploads -- Time elapsed: 2.783 s <<< ERROR! org.apache.hadoop.fs.s3a.AWSBadRequestException: Completing multipart upload on job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1) at org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:265) at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:124) at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:376) at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:468) at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:372) at org.apache.hadoop.fs.s3a.WriteOperationHelper.finalizeMultipartUpload(WriteOperationHelper.java:318) at org.apache.hadoop.fs.s3a.WriteOperationHelper.completeMPUwithRetries(WriteOperationHelper.java:370) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.lambda$complete$3(S3ABlockOutputStream.java:1227) at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.measureDurationOfInvocation(IOStatisticsBinding.java:493) at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDurationOfInvocation(IOStatisticsBinding.java:464) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.complete(S3ABlockOutputStream.java:1225) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.access$1500(S3ABlockOutputStream.java:876) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.close(S3ABlockOutputStream.java:545) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106) at org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.createFileWithFlags(ITestS3APutIfMatchAndIfNoneMatch.java:190) at org.apache.hadoop.fs.s3a.impl.ITestS3APutIfMatchAndIfNoneMatch.testIfNoneMatchTwoConcurrentMultipartUploads(ITestS3APutIfMatchAndIfNoneMatch.java:380) at java.lang.reflect.Method.invoke(Method.java:498) at java.util.ArrayList.forEach(ArrayList.java:1259) at java.util.ArrayList.forEach(ArrayList.java:1259) Caused by: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 9JCJ6M5QRDGJNYYS, Extended Request ID: Z7Q7+LA0o/5B4xoIGhgo+tVppawZ0UBj7X4RNb+0m9RbOAOwD/Apv1o+KmnW0aypjwmfFlarxjo=) (SDK Attempt Count: 1) at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:113) at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:61) at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper.retryPolicyDisallowedRetryException(RetryableStageHelper.java:168) at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:73) at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:36) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:53) at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:35) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:82) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:62) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:43) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37) at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26) at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:210) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:80) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:74) at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45) at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:53) at software.amazon.awssdk.services.s3.DefaultS3Client.completeMultipartUpload(DefaultS3Client.java:801) at software.amazon.awssdk.services.s3.DelegatingS3Client.lambda$completeMultipartUpload$1(DelegatingS3Client.java:611) at software.amazon.awssdk.services.s3.internal.crossregion.S3CrossRegionSyncClient.invokeOperation(S3CrossRegionSyncClient.java:67) at software.amazon.awssdk.services.s3.DelegatingS3Client.completeMultipartUpload(DelegatingS3Client.java:611) at org.apache.hadoop.fs.s3a.impl.S3AStoreImpl.completeMultipartUpload(S3AStoreImpl.java:906) at org.apache.hadoop.fs.s3a.S3AFileSystem$WriteOperationHelperCallbacksImpl.completeMultipartUpload(S3AFileSystem.java:1953) at org.apache.hadoop.fs.s3a.WriteOperationHelper.lambda$finalizeMultipartUpload$1(WriteOperationHelper.java:324) at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:122) ... 18 more {code} Yet the uploads list afterwards finds it {code} job-00-fork-0005/test/testIfNoneMatchTwoConcurrentMultipartUploads AnspJPHUoPJqg61t28OvLfAogi6G9ocyx1Dm6XY2C.a_H_onklM0Nr0LIXaPiYlQjZIiH0fTsQ1e2KhEjS9pGxvSKOXq_4YibiGZmFC6rBolmfACMqIRpoeaqYDgzYW4 {code}\n[Steve Loughran @ 2025-10-23T15:52:03.066+0000]: And stack on a write failure. {code} [ERROR] org.apache.hadoop.fs.s3a.scale.ITestS3AHugeFilesArrayBlocks.test_010_CreateHugeFile -- Time elapsed: 2.870 s <<< ERROR! org.apache.hadoop.fs.s3a.AWSBadRequestException: Completing multipart upload on job-00/test/tests3ascale/array/src/hugefile: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1):InvalidPart: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1) at org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:265) at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:124) at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:376) at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:468) at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:372) at org.apache.hadoop.fs.s3a.WriteOperationHelper.finalizeMultipartUpload(WriteOperationHelper.java:318) at org.apache.hadoop.fs.s3a.WriteOperationHelper.completeMPUwithRetries(WriteOperationHelper.java:370) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.lambda$complete$3(S3ABlockOutputStream.java:1227) at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.measureDurationOfInvocation(IOStatisticsBinding.java:493) at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDurationOfInvocation(IOStatisticsBinding.java:464) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.complete(S3ABlockOutputStream.java:1225) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.access$1500(S3ABlockOutputStream.java:876) at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.close(S3ABlockOutputStream.java:545) at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77) at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106) at org.apache.hadoop.fs.s3a.scale.AbstractSTestS3AHugeFiles.test_010_CreateHugeFile(AbstractSTestS3AHugeFiles.java:276) at java.lang.reflect.Method.invoke(Method.java:498) at java.util.ArrayList.forEach(ArrayList.java:1259) at java.util.ArrayList.forEach(ArrayList.java:1259) Caused by: software.amazon.awssdk.services.s3.model.S3Exception: One or more of the specified parts could not be found. The part may not have been uploaded, or the specified entity tag may not match the part's entity tag. (Service: S3, Status Code: 400, Request ID: 1NNBCSX4NCDN7G9X, Extended Request ID: 8vMmeyt1GfjGrf3UL9AN8vlwWSn9860f1gdeIBC3drmcjeQwC6wOPinMD8MSO6ggGw9ywwdcXroGTdVSFLYq0S0VdM/5bYfanDXJ43Eb4QU=) (SDK Attempt Count: 1) at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:113) at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:61) at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper.retryPolicyDisallowedRetryException(RetryableStageHelper.java:168) at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:73) at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:36) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:53) at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:35) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:82) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:62) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:43) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50) at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206) at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37) at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26) at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:210) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:80) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182) at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:74) at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45) at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:53) at software.amazon.awssdk.services.s3.DefaultS3Client.completeMultipartUpload(DefaultS3Client.java:801) at software.amazon.awssdk.services.s3.DelegatingS3Client.lambda$completeMultipartUpload$1(DelegatingS3Client.java:611) at software.amazon.awssdk.services.s3.internal.crossregion.S3CrossRegionSyncClient.invokeOperation(S3CrossRegionSyncClient.java:67) at software.amazon.awssdk.services.s3.DelegatingS3Client.completeMultipartUpload(DelegatingS3Client.java:611) at org.apache.hadoop.fs.s3a.impl.S3AStoreImpl.completeMultipartUpload(S3AStoreImpl.java:906) at org.apache.hadoop.fs.s3a.S3AFileSystem$WriteOperationHelperCallbacksImpl.completeMultipartUpload(S3AFileSystem.java:1953) at org.apache.hadoop.fs.s3a.WriteOperationHelper.lambda$finalizeMultipartUpload$1(WriteOperationHelper.java:324) at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:122) ... 17 more {code} we'd have to map 400 + the error text to a \"MultipartUploadCompleteFailed\" exception and add a policy for it, leaving other 400s as unrecoverable.\n[Steve Loughran @ 2025-10-23T15:57:00.573+0000]: + any tracking in block output stream should record when the POST to initiate the MPU was issued. That way if an error still surfaces but the output stream has been open for three days, we have a good cause \"stream open too long\"\n[Steve Loughran @ 2025-10-24T13:48:33.158+0000]: this is actually me making a mess of checksum config if the sdk checksum clalculation is set to \"always\" then the user MUST choose a checksum algorithm for s3 uploads (proposed: CRC32). I\"m going to leave checksum calculation off by default for performance and compatibility","key":"HADOOP-19734","status":"Resolved","labels":""}
{"summary":"S3A: Credentials provider classes not found despite setting `fs.s3a.classloader.isolation` to `false`","created":"2025-10-22T19:56:55.000+0000","description":"HADOOP-18993 added the option `fs.s3a.classloader.isolation` to support, for example, a Spark job using an AWS credentials provider class that is bundled into the Spark job JAR. In testing this, the AWS credentials provider classes are still not found.\r\n\r\nI think the cause is:\r\n * `fs.s3a.classloader.isolation` is implemented by setting (or not setting) a classloader on the `Configuration`\r\n * However, code paths to load AWS credential provider call `S3AUtils.getInstanceFromReflection`, which uses the classloader that loaded the S3AUtils class. That's likely to be the built-in application classloader, which won't be able to load classes in a Spark job JAR.\r\n\r\nAnd the fix seems small:\r\n * Change `S3AUtils.getInstanceFromReflection` to load classes using the `Configuration`'s classloader. Luckily we already have the Configuration in this method.","assignee":"Brandon","priority":"Minor","updated":"2025-10-23T19:44:03.000+0000","commentText":"[Brandon @ 2025-10-22T20:36:34.829+0000]: I haven't contributed to Hadoop or other Apache projects before, but this approachable for a first contribution. I'll open a PR.\n[ASF GitHub Bot @ 2025-10-23T04:13:15.711+0000]: brandonvin opened a new pull request, #8048: URL: https://github.com/apache/hadoop/pull/8048 \u2026lassloader <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR Follow-up to [HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) and [HADOOP-19733](https://issues.apache.org/jira/browse/HADOOP-19733) before it. With `fs.s3a.classloader.isolation` set to `false` in a Spark application, it was still impossible to load a credentials provider class from the Spark application jar. `fs.s3a.classloader.isolation` works by saving a reference to the intended classloader in the `Configuration`. However, loading credentials providers goes through `S3AUtils#getInstanceFromReflection`, which always used the classloader that loaded `S3AUtils`. With this patch, credentials providers will be loaded using the `Configuration`'s classloader. ### How was this patch tested? Unit tests in `org.apache.hadoop.fs.s3a.ITestS3AFileSystemIsolatedClassloader`. Manual testing in a Spark application. ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [x] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [x] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-23T04:43:50.648+0000]: brandonvin commented on code in PR #8048: URL: https://github.com/apache/hadoop/pull/8048#discussion_r2453905622 ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS } } - private Map<String, String> mapOf() { - return new HashMap<>(); - } - - private Map<String, String> mapOf(String key, String value) { - HashMap<String, String> m = new HashMap<>(); - m.put(key, value); - return m; - } Review Comment: Since I added test cases that set 2 key-value pairs, I switched to `Map.of` instead of extending these. Not sure if there was a reason to avoid `Map.of` here.\n[ASF GitHub Bot @ 2025-10-23T05:17:39.742+0000]: hadoop-yetus commented on PR #8048: URL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435132657 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 20s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 24m 19s | | trunk passed | | +1 :green_heart: | compile | 0m 24s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 24s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 20s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 30s | | trunk passed | | +1 :green_heart: | javadoc | 0m 25s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 18s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) | hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 14m 51s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 21s | | the patch passed | | +1 :green_heart: | compile | 0m 20s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 20s | | the patch passed | | +1 :green_heart: | compile | 0m 20s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 20s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 0m 11s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) | hadoop-tools/hadoop-aws: The patch generated 31 new + 4 unchanged - 0 fixed = 35 total (was 4) | | +1 :green_heart: | mvnsite | 0m 21s | | the patch passed | | +1 :green_heart: | javadoc | 0m 16s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 15s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 47s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) | hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188) | | +1 :green_heart: | shadedclient | 15m 9s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 1m 57s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) | hadoop-aws in the patch passed. | | +1 :green_heart: | asflicense | 0m 19s | | The patch does not generate ASF License warnings. | | | | 63m 28s | | | | Reason | Tests | |-------:|:------| | SpotBugs | module:hadoop-tools/hadoop-aws | | | Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At S3AUtils.java:[line 645] | | | Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At SignerFactory.java:[line 125] | | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8048 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 573c49df2825 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 032c335082f24aef12ee3e002ae1cfd9c5f40507 | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/testReport/ | | Max. process+thread count | 610 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-23T05:46:12.703+0000]: hadoop-yetus commented on PR #8048: URL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435205771 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 21s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 25m 39s | | trunk passed | | +1 :green_heart: | compile | 0m 23s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 24s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 17s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 27s | | trunk passed | | +1 :green_heart: | javadoc | 0m 23s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 19s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) | hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 14m 50s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 21s | | the patch passed | | +1 :green_heart: | compile | 0m 20s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 20s | | the patch passed | | +1 :green_heart: | compile | 0m 23s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 23s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 0m 10s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) | hadoop-tools/hadoop-aws: The patch generated 12 new + 4 unchanged - 0 fixed = 16 total (was 4) | | +1 :green_heart: | mvnsite | 0m 23s | | the patch passed | | +1 :green_heart: | javadoc | 0m 16s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 15s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 46s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) | hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188) | | +1 :green_heart: | shadedclient | 14m 2s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 2m 0s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) | hadoop-aws in the patch passed. | | +1 :green_heart: | asflicense | 0m 20s | | The patch does not generate ASF License warnings. | | | | 63m 47s | | | | Reason | Tests | |-------:|:------| | SpotBugs | module:hadoop-tools/hadoop-aws | | | Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At S3AUtils.java:[line 645] | | | Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String) At SignerFactory.java:[line 125] | | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8048 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 55f7cbac0d20 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 249aef5213fa039d252e7f7ae03c060b6c87d94f | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/testReport/ | | Max. process+thread count | 616 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-23T13:03:14.097+0000]: steveloughran commented on code in PR #8048: URL: https://github.com/apache/hadoop/pull/8048#discussion_r2455036391 ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -37,10 +46,33 @@ */ public class ITestS3AFileSystemIsolatedClassloader extends AbstractS3ATestBase { + private static String customClassName = \"custom.class.name\"; + + private static class CustomCredentialsProvider implements AwsCredentialsProvider { + + public CustomCredentialsProvider() { + } + + @Override + public AwsCredentials resolveCredentials() { + return null; + } + + } + private static class CustomClassLoader extends ClassLoader { } - private final ClassLoader customClassLoader = new CustomClassLoader(); + private final ClassLoader customClassLoader = spy(new CustomClassLoader()); + { + try { Review Comment: this is a nice way to simulate classloader pain. ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -28,6 +29,14 @@ import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.FileSystem; +import org.apache.hadoop.fs.s3a.impl.InstantiationIOException; + +import software.amazon.awssdk.auth.credentials.AwsCredentials; Review Comment: nit: put the amazon imports in the same group as the junit ones ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -100,11 +122,26 @@ public void defaultIsolatedClassloader() throws IOException { .isEqualTo(fs.getClass().getClassLoader()) .describedAs(\"the classloader that loaded the fs\"); }); + + Throwable thrown = Assertions.catchThrowable(() -> { Review Comment: Use our `LambdaTestUtils.intercept()`; it's like the spark one and does the casting checks ``` InstantiationIOException ex = intercept(InstantiationIOException.class, () -> { assert...}) ``` we have a `assertExceptionContains` to look at the inner stuff, but the assert of L136 is fine. ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -115,11 +152,31 @@ public void isolatedClassloader() throws IOException { .isEqualTo(fs.getClass().getClassLoader()) .describedAs(\"the classloader that loaded the fs\"); }); + + Throwable thrown = Assertions.catchThrowable(() -> { Review Comment: again `intercept()` and cut the assert at L163 ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS } } - private Map<String, String> mapOf() { - return new HashMap<>(); - } - - private Map<String, String> mapOf(String key, String value) { - HashMap<String, String> m = new HashMap<>(); - m.put(key, value); - return m; - } Review Comment: It's because we only switched to java17 yesterday! And in trunk only. If you want to see this change in Hadoop 3.4.3 it'll still need to be java8 code, so this needs to be restored. Otherwise: trunk/3.5.0 only\n[Brandon @ 2025-10-23T16:33:11.604+0000]: Ok, will also update the custom signer loading to use the configuration, for consistency.\n[ASF GitHub Bot @ 2025-10-23T19:44:03.691+0000]: brandonvin commented on code in PR #8048: URL: https://github.com/apache/hadoop/pull/8048#discussion_r2456994430 ########## hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java: ########## @@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS } } - private Map<String, String> mapOf() { - return new HashMap<>(); - } - - private Map<String, String> mapOf(String key, String value) { - HashMap<String, String> m = new HashMap<>(); - m.put(key, value); - return m; - } Review Comment: Thanks, makes sense!","key":"HADOOP-19733","status":"Open","labels":"pull-request-available"}
{"summary":"Namenode Crash Due to Delegation Renewer Runtime Exit (NoMatchingRule)","created":"2025-10-21T18:43:38.000+0000","description":"The delegation token renewer enters runtime exit when a _NoMatchingRule_ error, which caused the entire namenode to crash. I think returning an error to the client should be fine but bringing down the namenode is not acceptable to anyone.\r\n\r\nAfter the AD change, the new realm was updated, but some jobs are still using the old realm as users are updating them gradually. This migration process will take time, and during this period, other jobs are still catching up with the new realm configuration. However, the namenode down disrupts all of them.\r\n\r\nÂ \r\n{code:java}\r\nERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover thread received unexpected exception\r\njava.lang.IllegalArgumentException: Illegal principal name hive/xxxxx@yyyy.COM\r\norg.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to hive/xxxxx@yyyy.COM Â  Â  Â  Â  at org.apache.hadoop.security.User.<init>(User.java:51)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.User.<init>(User.java:43)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1417)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1401)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier.getUser(AbstractDelegationTokenIdentifier.java:80)\r\nÂ  Â  Â  Â  at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier.getUser(DelegationTokenIdentifier.java:81)\r\nÂ  Â  Â  Â  at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier.toString(DelegationTokenIdentifier.java:91)\r\nÂ  Â  Â  Â  at java.lang.String.valueOf(String.java:2994)\r\nÂ  Â  Â  Â  at java.lang.StringBuilder.append(StringBuilder.java:137)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.formatTokenId(AbstractDelegationTokenSecretManager.java:58)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.logExpireTokens(AbstractDelegationTokenSecretManager.java:642)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.removeExpiredToken(AbstractDelegationTokenSecretManager.java:635)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.access$400(AbstractDelegationTokenSecretManager.java:51)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:694)\r\nÂ  Â  Â  Â  at java.lang.Thread.run(Thread.java:750)\r\nCaused by: org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to hive/xxxxx@yyyy.COM\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429)\r\nÂ  Â  Â  Â  at org.apache.hadoop.security.User.<init>(User.java:48)\r\nÂ  Â  Â  Â  ... 14 more {code}\r\nÂ ","assignee":"","priority":"Major","updated":"2025-10-23T17:47:42.000+0000","commentText":"[Steve Loughran @ 2025-10-23T12:41:51.201+0000]: looks a duplicate of HDFS-17138. [~kpalanisamy] please set the hadoop version you saw it with. If it is a version without HDFS-17138 -please upgrade. closing as a duplicate. If it surfaces on branches with HDFS-17138, re-open\n[Karthik Palanisamy @ 2025-10-23T17:47:42.603+0000]: You\u2019re right [~stevel@apache.org].Â My user version is 3.1.1, so it is missing this HDFS-17138 fix, which clearly addresses my user scenarios. Thanks for checking so quickly. I should have checked it, but unfortunately I taken your time :)Â ","key":"HADOOP-19732","status":"Resolved","labels":""}
{"summary":"Fix SpotBugs warnings introduced after SpotBugs version upgrade.","created":"2025-10-19T09:57:26.000+0000","description":"Following the upgrade to SpotBugs {*}4.9.7{*}, several new warnings have emerged.\r\nWe plan to address these warnings to improve code safety and maintain compatibility with the updated analysis rules.","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-23T12:26:45.000+0000","commentText":"[Anuj Modi @ 2025-10-23T12:10:33.527+0000]: Hi [~slfan1989]Â  Thanks for tracking this. We do have a bunch of PRs open that are facing issue reported here. What are the expectations here? Do we need to address all warnings with the PR itself or they can be ignored and taken later as part of this Jira? I think later would be better. It will help keep the changes in PR limited to what is being done and will ease the review process.\n[Shilun Fan @ 2025-10-23T12:20:20.684+0000]: I agree with your point. We\u2019ll work on submitting a common PR that includes a SpotBugs rule to temporarily suppress the new static analysis warnings and restore the state back to the 4.2.0 level.\n[Anuj Modi @ 2025-10-23T12:26:45.915+0000]: Sounds awesome. Thanks for all the efforts.","key":"HADOOP-19731","status":"In Progress","labels":""}
{"summary":"upgrade bouncycastle to 1.82 due to CVE-2025-8916","created":"2025-10-19T09:09:36.000+0000","description":"https://github.com/advisories/GHSA-4cx2-fc23-5wg6\r\n\r\nThought it was tidier to upgrade to latest version even if the fix was a while ago.","assignee":"","priority":"Major","updated":"2025-10-23T17:26:09.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-19T09:15:30.542+0000]: pjfanning opened a new pull request, #8039: URL: https://github.com/apache/hadoop/pull/8039 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR HADOOP-19730 ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-20T03:00:51.681+0000]: hadoop-yetus commented on PR #8039: URL: https://github.com/apache/hadoop/pull/8039#issuecomment-3420366545 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 20m 22s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | markdownlint | 0m 0s | | markdownlint was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +0 :ok: | shelldocs | 0m 1s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 7m 51s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 28m 35s | | trunk passed | | +1 :green_heart: | compile | 15m 12s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 28s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | mvnsite | 8m 58s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | +1 :green_heart: | javadoc | 9m 36s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 36s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 43m 37s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 33s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 27m 23s | | the patch passed | | +1 :green_heart: | compile | 14m 49s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 14m 49s | | the patch passed | | +1 :green_heart: | compile | 15m 37s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 37s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 7m 1s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 9m 42s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 36s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 45m 37s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 807m 40s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 36s | | The patch does not generate ASF License warnings. | | | | 1064m 10s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList | | | hadoop.hdfs.tools.TestDFSAdmin | | | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints | | | hadoop.hdfs.server.balancer.TestBalancerWithHANameNodes | | | hadoop.hdfs.TestRollingUpgrade | | | hadoop.yarn.sls.appmaster.TestAMSimulator | | | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler | | | hadoop.yarn.server.router.webapp.TestFederationWebApp | | | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST | | | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService | | | hadoop.yarn.service.TestYarnNativeServices | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8039 | | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint compile javac javadoc mvninstall unit shadedclient xmllint shellcheck shelldocs | | uname | Linux 66cf96c27f49 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 695a0a30232b143ec8837d6a6648344ffd4efec0 | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/testReport/ | | Max. process+thread count | 4498 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-cloud-storage-project/hadoop-cos . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8039/1/console | | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-21T01:42:32.195+0000]: slfan1989 merged PR #8039: URL: https://github.com/apache/hadoop/pull/8039\n[ASF GitHub Bot @ 2025-10-21T01:44:38.858+0000]: slfan1989 commented on PR #8039: URL: https://github.com/apache/hadoop/pull/8039#issuecomment-3424343993 @pjfanning Thanks for the contribution! Merged into trunk. Could we also open a PR for branch-3.4?\n[ASF GitHub Bot @ 2025-10-23T00:19:48.036+0000]: pjfanning opened a new pull request, #8047: URL: https://github.com/apache/hadoop/pull/8047 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR backport #6976 * HADOOP-19730. Upgrade Bouncycastle to 1.82 due to CVE-2025-8916 ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-23T17:26:09.708+0000]: hadoop-yetus commented on PR #8047: URL: https://github.com/apache/hadoop/pull/8047#issuecomment-3438232725 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 12m 50s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | markdownlint | 0m 0s | | markdownlint was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ branch-3.4 Compile Tests _ | | +0 :ok: | mvndep | 2m 54s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 39m 30s | | branch-3.4 passed | | +1 :green_heart: | compile | 18m 44s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 17m 41s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 22m 5s | | branch-3.4 passed | | +1 :green_heart: | javadoc | 9m 20s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 36s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 50m 39s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 34s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 29m 11s | | the patch passed | | +1 :green_heart: | compile | 17m 19s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 19s | | the patch passed | | +1 :green_heart: | compile | 15m 51s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 51s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 18m 13s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 9m 11s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 31s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 52m 50s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 720m 55s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 49s | | The patch does not generate ASF License warnings. | | | | 1024m 55s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.mapred.gridmix.TestGridmixSubmission | | | hadoop.mapred.gridmix.TestLoadJob | | | hadoop.security.ssl.TestDelegatingSSLSocketFactory | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8047 | | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint compile javac javadoc mvninstall unit shadedclient xmllint shellcheck shelldocs | | uname | Linux d69a46a8ee67 5.15.0-160-generic #170-Ubuntu SMP Wed Oct 1 10:06:56 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | branch-3.4 / c8b8fb4e82d33a470f10a447f4799cc872fb3c01 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/testReport/ | | Max. process+thread count | 3660 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-cloud-storage-project/hadoop-cos . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8047/1/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.","key":"HADOOP-19730","status":"Open","labels":"pull-request-available"}
{"summary":"ABFS: [Perf] Network Profiling of Tailing Requests and Killing Bad Connections Proactively","created":"2025-10-17T05:41:02.000+0000","description":"","assignee":"Anuj Modi","priority":"Major","updated":"2025-10-26T10:46:14.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-26T10:46:14.005+0000]: hadoop-yetus commented on PR #8043: URL: https://github.com/apache/hadoop/pull/8043#issuecomment-3448411577 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 11m 8s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 21m 31s | | trunk passed | | +1 :green_heart: | compile | 0m 23s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 25s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 18s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 26s | | trunk passed | | +1 :green_heart: | javadoc | 0m 24s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 22s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 43s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) | hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 13m 53s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 22s | | the patch passed | | +1 :green_heart: | compile | 0m 18s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 18s | | the patch passed | | +1 :green_heart: | compile | 0m 21s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 21s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 0m 10s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) | hadoop-tools/hadoop-azure: The patch generated 43 new + 3 unchanged - 0 fixed = 46 total (was 3) | | +1 :green_heart: | mvnsite | 0m 20s | | the patch passed | | -1 :x: | javadoc | 0m 18s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) | hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 34 new + 1472 unchanged - 0 fixed = 1506 total (was 1472) | | -1 :x: | javadoc | 0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) | hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 33 new + 1413 unchanged - 0 fixed = 1446 total (was 1413) | | -1 :x: | spotbugs | 0m 46s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) | hadoop-tools/hadoop-azure generated 4 new + 177 unchanged - 1 fixed = 181 total (was 178) | | +1 :green_heart: | shadedclient | 14m 12s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 2m 8s | | hadoop-azure in the patch passed. | | +1 :green_heart: | asflicense | 0m 19s | | The patch does not generate ASF License warnings. | | | | 70m 0s | | | | Reason | Tests | |-------:|:------| | SpotBugs | module:hadoop-tools/hadoop-azure | | | Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient) At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient) At AbfsAHCHttpOperation.java:[line 123] | | | Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext) At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext) At AbfsRestOperation.java:[line 533] | | | new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration At AbfsTailLatencyTracker.java:[line 55] | | | Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType) At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType) At SlidingWindowHdrHistogram.java:[line 81] | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8043 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle | | uname | Linux d98c9c1604f2 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 7dcac93eec4dc5a48d643ae81372c581b6c3bebf | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/testReport/ | | Max. process+thread count | 614 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.","key":"HADOOP-19729","status":"Open","labels":"pull-request-available"}
{"summary":"S3A: add ipv6 support","created":"2025-10-15T13:16:53.000+0000","description":"Support IPv6 with a flag to enable/disable dual stack endpoints\r\n\r\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/ipv6-access.html","assignee":"","priority":"Major","updated":"2025-10-15T13:16:53.000+0000","commentText":"","key":"HADOOP-19728","status":"Open","labels":""}
{"summary":"Release hadoop-thirdparty 1.5.0","created":"2025-10-14T14:34:32.000+0000","description":"\r\nRelease hadoop-thirdparty 1.5.0","assignee":"Steve Loughran","priority":"Major","updated":"2025-10-20T16:40:40.000+0000","commentText":"","key":"HADOOP-19727","status":"In Progress","labels":""}
{"summary":"Add JDK 17 compile options for maven-surefire-plugin in hadoop-tos module","created":"2025-10-12T23:47:15.000+0000","description":"Currently, the {{hadoop-tos}} module does not have the JDK 17 compile options configured for the {{{}maven-surefire-plugin{}}}, which causes the following error during unit test execution:\r\n{code:java}\r\njava.lang.IllegalStateException: Failed to set environment variable\tat org.apache.hadoop.fs.tosfs.util.TestUtility.setSystemEnv(TestUtility.java:120)\tat org.apache.hadoop.fs.tosfs.object.ObjectStorageTestBase.setUp(ObjectStorageTestBase.java:59)\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)Caused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Map java.util.Collections$UnmodifiableMap.m accessible: module java.base does not \"opens java.util\" to unnamed module @69eee410\tat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)\tat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\tat java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)\tat java.base/java.lang.reflect.Field.setAccessible(Field.java:172)\tat org.apache.hadoop.fs.tosfs.util.TestUtility.setSystemEnv(TestUtility.java:116)\t... 4 more\r\n {code}\r\nThis error occurs due to the module system restrictions in JDK 17, where reflection cannot access private fields in the java.util.Collections$UnmodifiableMap class.\r\n\r\nÂ \r\n\r\nTo resolve this issue, JDK 17 compile options have been added to ensure the maven-surefire-plugin works correctly in a JDK 17 environment. This PR adds the necessary compile options for maven-surefire-plugin to support JDK 17, fixing the error and ensuring that unit tests can run smoothly.","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-19T03:00:16.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-12T23:48:43.587+0000]: slfan1989 opened a new pull request, #8029: URL: https://github.com/apache/hadoop/pull/8029 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR JIRA: HADOOP-19726. [JDK17] Add JDK 17 compile options for maven-surefire-plugin in hadoop-tos module. ### How was this patch tested? CI ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-13T00:44:42.818+0000]: hadoop-yetus commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3395542255 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 8m 39s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 25m 39s | | trunk passed | | +1 :green_heart: | compile | 0m 24s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 18s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | mvnsite | 0m 21s | | trunk passed | | +1 :green_heart: | javadoc | 0m 20s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 17s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 42m 23s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 13s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 0m 13s | | the patch passed | | +1 :green_heart: | javadoc | 0m 13s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | javadoc | 0m 12s | [/patch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/patch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-tos in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | shadedclient | 1m 41s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 13s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in the patch failed. | | +1 :green_heart: | asflicense | 0m 18s | | The patch does not generate ASF License warnings. | | | | 55m 3s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8029 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux dd7bc96b56b5 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / f188198cdec1613ae955ea31795a8cb1ca496139 | | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/testReport/ | | Max. process+thread count | 576 (vs. ulimit of 5500) | | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/1/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T15:09:25.152+0000]: hadoop-yetus commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3411382684 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 21s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 24m 30s | | trunk passed | | +1 :green_heart: | compile | 0m 19s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 21s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | mvnsite | 0m 21s | | trunk passed | | +1 :green_heart: | javadoc | 0m 22s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 20s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 40m 22s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 13s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 13s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 0m 15s | | the patch passed | | +1 :green_heart: | javadoc | 0m 14s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 13s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 14m 55s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 26s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 19s | | The patch does not generate ASF License warnings. | | | | 58m 21s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream | | | hadoop.fs.tosfs.object.TestObjectRangeInputStream | | | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider | | | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain | | | hadoop.fs.tosfs.object.TestObjectOutputStream | | | hadoop.fs.tosfs.commit.TestMagicOutputStream | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8029 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 3f25ded462da 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 2bd00ae481cc8a6aeb977fef2700e684236375a4 | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/testReport/ | | Max. process+thread count | 616 (vs. ulimit of 5500) | | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/2/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T16:27:26.865+0000]: hadoop-yetus commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3411690102 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 21s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 25m 6s | | trunk passed | | +1 :green_heart: | compile | 0m 19s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 18s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 16s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 24s | | trunk passed | | +1 :green_heart: | javadoc | 0m 21s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 19s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 35s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html) | hadoop-cloud-storage-project/hadoop-tos in trunk has 56 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 14m 11s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 12s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 12s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 8s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 15s | | the patch passed | | +1 :green_heart: | javadoc | 0m 14s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 13s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | spotbugs | 0m 31s | | the patch passed | | +1 :green_heart: | shadedclient | 14m 0s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 27s | [/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/patch-unit-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 18s | | The patch does not generate ASF License warnings. | | | | 60m 57s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream | | | hadoop.fs.tosfs.object.TestObjectRangeInputStream | | | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider | | | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain | | | hadoop.fs.tosfs.object.TestObjectOutputStream | | | hadoop.fs.tosfs.commit.TestMagicOutputStream | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8029 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle | | uname | Linux 9e3548929018 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 9ba2bc5bf9cda429475a820bfcf689479e7fdc2d | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/testReport/ | | Max. process+thread count | 639 (vs. ulimit of 5500) | | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/3/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T18:01:30.696+0000]: hadoop-yetus commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3412145538 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 44s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 24m 9s | | trunk passed | | +1 :green_heart: | compile | 0m 19s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 18s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | checkstyle | 0m 16s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 20s | | trunk passed | | +1 :green_heart: | javadoc | 0m 23s | | trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 19s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | -1 :x: | spotbugs | 0m 34s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos-warnings.html) | hadoop-cloud-storage-project/hadoop-tos in trunk has 56 extant spotbugs warnings. | | +1 :green_heart: | shadedclient | 14m 3s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 15s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 16s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 16s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 8s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 14s | | the patch passed | | +1 :green_heart: | javadoc | 0m 15s | | the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 13s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | spotbugs | 0m 31s | | the patch passed | | +1 :green_heart: | shadedclient | 14m 12s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 58s | | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 20s | | The patch does not generate ASF License warnings. | | | | 60m 20s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8029 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle | | uname | Linux 6a680a7543dc 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 1b29c9884dbd1895ea8116fe1c0cf495ce03d39f | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/testReport/ | | Max. process+thread count | 643 (vs. ulimit of 5500) | | modules | C: hadoop-cloud-storage-project/hadoop-tos U: hadoop-cloud-storage-project/hadoop-tos | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8029/4/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T23:43:30.763+0000]: slfan1989 commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3413251437 @wojiaodoubao Could you please help review this PR again? Thanks a lot!\n[ASF GitHub Bot @ 2025-10-18T09:40:49.588+0000]: slfan1989 commented on PR #8029: URL: https://github.com/apache/hadoop/pull/8029#issuecomment-3418122640 I plan to merge this PR, as the unit test errors in TOS have been resolved. If further optimization is needed later, we can submit a separate PR for improvements. cc: @steveloughran @wojiaodoubao\n[ASF GitHub Bot @ 2025-10-19T02:54:48.791+0000]: slfan1989 merged PR #8029: URL: https://github.com/apache/hadoop/pull/8029","key":"HADOOP-19726","status":"Resolved","labels":"pull-request-available"}
{"summary":"Upgrade SpotBugs Version to Support JDK 17 Compilation","created":"2025-10-12T23:27:49.000+0000","description":"The current SpotBugs version used in the project is 4.2.2 (SpotBugs) and 4.2.0 (SpotBugs Maven Plugin), which is not fully compatible with JDK 17 compilation. To ensure proper functionality of the code quality check tool in a JDK 17 environment, SpotBugs needs to be upgraded to the latest version that supports JDK 17.","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-16T14:06:32.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-12T23:31:04.168+0000]: slfan1989 opened a new pull request, #8028: URL: https://github.com/apache/hadoop/pull/8028 ### Description of PR JIRA: [JDK17] Upgrade SpotBugs Version to Support JDK 17 Compilation. ### How was this patch tested? ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-13T15:24:29.352+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3397979702 @cnauroth @szetszwo After upgrading to JDK 17, I found that spotbug could not run properly because the current version does not support JDK 17. To resolve this issue, I upgraded the versions of the two related plugins. The changes have been tested locally, and the results are as expected.\n[ASF GitHub Bot @ 2025-10-13T18:01:47.299+0000]: hadoop-yetus commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3398540465 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 14m 35s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 36m 49s | | trunk passed | | +1 :green_heart: | compile | 15m 58s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 44s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | -1 :x: | mvnsite | 9m 55s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | +1 :green_heart: | javadoc | 9m 22s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 51s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 124m 16s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 28m 30s | | the patch passed | | +1 :green_heart: | compile | 15m 17s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 17s | | the patch passed | | +1 :green_heart: | compile | 15m 43s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 43s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 7m 2s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | +1 :green_heart: | javadoc | 9m 7s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 45s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 53m 32s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 853m 28s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 44s | | The patch does not generate ASF License warnings. | | | | 1109m 31s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin | | | hadoop.yarn.sls.appmaster.TestAMSimulator | | | hadoop.yarn.server.router.webapp.TestFederationWebApp | | | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler | | | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST | | | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8028 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux da08cd8994df 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 3b47bd160a2122ed84df1730e54cbfafa3ab60b8 | | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/testReport/ | | Max. process+thread count | 3529 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/1/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-13T23:56:15.937+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3399438331 I have completed the investigation of the mvnsite build issues and confirmed that the problem is related to the JDIFF module. We plan to submit a separate PR to fix and optimize this issue.\n[ASF GitHub Bot @ 2025-10-14T11:14:05.781+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3401292116 @steveloughran Could you please review this PR? Thank you very much!\n[ASF GitHub Bot @ 2025-10-15T09:36:46.070+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3405489643 @Hexiaoqiao Could you please review this PR? Thank you very much!\n[ASF GitHub Bot @ 2025-10-15T15:23:41.790+0000]: szetszwo commented on code in PR #8028: URL: https://github.com/apache/hadoop/pull/8028#discussion_r2433007716 ########## pom.xml: ########## @@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x <maven-checkstyle-plugin.version>3.1.0<\/maven-checkstyle-plugin.version> <checkstyle.version>8.29<\/checkstyle.version> <dependency-check-maven.version>7.1.1<\/dependency-check-maven.version> - <spotbugs.version>4.2.2<\/spotbugs.version> - <spotbugs-maven-plugin.version>4.2.0<\/spotbugs-maven-plugin.version> + <spotbugs.version>4.8.3<\/spotbugs.version> + <spotbugs-maven-plugin.version>4.7.3.6<\/spotbugs-maven-plugin.version> Review Comment: Similarly, why not 4.9.7.0 (or 4.8.6.7)? ########## pom.xml: ########## @@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x <maven-checkstyle-plugin.version>3.1.0<\/maven-checkstyle-plugin.version> <checkstyle.version>8.29<\/checkstyle.version> <dependency-check-maven.version>7.1.1<\/dependency-check-maven.version> - <spotbugs.version>4.2.2<\/spotbugs.version> - <spotbugs-maven-plugin.version>4.2.0<\/spotbugs-maven-plugin.version> + <spotbugs.version>4.8.3<\/spotbugs.version> Review Comment: Why not 4.9.7 (or 4.8.6)? https://mvnrepository.com/artifact/com.github.spotbugs/spotbugs\n[ASF GitHub Bot @ 2025-10-15T15:48:03.835+0000]: slfan1989 commented on code in PR #8028: URL: https://github.com/apache/hadoop/pull/8028#discussion_r2433103901 ########## pom.xml: ########## @@ -119,8 +119,8 @@ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/x <maven-checkstyle-plugin.version>3.1.0<\/maven-checkstyle-plugin.version> <checkstyle.version>8.29<\/checkstyle.version> <dependency-check-maven.version>7.1.1<\/dependency-check-maven.version> - <spotbugs.version>4.2.2<\/spotbugs.version> - <spotbugs-maven-plugin.version>4.2.0<\/spotbugs-maven-plugin.version> + <spotbugs.version>4.8.3<\/spotbugs.version> Review Comment: Thank you for reviewing! You made a very good point \u2014 I\u2019ll update this PR accordingly.\n[ASF GitHub Bot @ 2025-10-16T09:08:38.874+0000]: hadoop-yetus commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3409917424 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 32s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 1s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 37m 51s | | trunk passed | | +1 :green_heart: | compile | 15m 40s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 43s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | -1 :x: | mvnsite | 10m 13s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | +1 :green_heart: | javadoc | 9m 11s | | trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 47s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 125m 4s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 28m 20s | | the patch passed | | +1 :green_heart: | compile | 15m 11s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 11s | | the patch passed | | +1 :green_heart: | compile | 15m 58s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 58s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 7m 5s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | +1 :green_heart: | javadoc | 9m 8s | | the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 40s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | shadedclient | 53m 57s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 792m 24s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 46s | | The patch does not generate ASF License warnings. | | | | 1035m 29s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.tools.TestDFSAdmin | | | hadoop.yarn.sls.appmaster.TestAMSimulator | | | hadoop.yarn.server.router.webapp.TestFederationWebApp | | | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler | | | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8028 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux c50dc2503f2d 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / c7ac33f5f774a890079fd002e27829cc7b38c67d | | Default Java | Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Multi-JDK versions | /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/testReport/ | | Max. process+thread count | 3553 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8028/2/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T14:03:44.942+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3411057566 > Thanks @slfan1989 . LGTM. +1. I think it is smooth after check spotbug release changes and other apache projects upgrade feedbacks. TBH, I am not check it with new JDK version carefully. @Hexiaoqiao Many thanks for reviewing the code! The new Sputbug plugin has been tested on JDK 17 and JDK 21 and works properly.\n[ASF GitHub Bot @ 2025-10-16T14:05:16.623+0000]: slfan1989 merged PR #8028: URL: https://github.com/apache/hadoop/pull/8028\n[ASF GitHub Bot @ 2025-10-16T14:05:44.423+0000]: slfan1989 commented on PR #8028: URL: https://github.com/apache/hadoop/pull/8028#issuecomment-3411067429 @szetszwo @steveloughran @Hexiaoqiao @zhtttylz Thank you very much for reviewing the code!","key":"HADOOP-19725","status":"Resolved","labels":"pull-request-available"}
{"summary":"[RISC-V]  Add rv bulk CRC32 (non-CRC32C) optimized path","created":"2025-10-12T12:49:32.000+0000","description":"","assignee":"","priority":"Major","updated":"2025-10-14T12:08:33.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-13T15:57:36.992+0000]: PeterPtroc opened a new pull request, #8031: URL: https://github.com/apache/hadoop/pull/8031 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR - Introduces a riscv64 native implementation path for CRC32 (CRC32C not optimized). - Adds runtime CPU feature detection on linux-riscv64 to enable hardware-accelerated CRC32 when available; falls back to the existing implementation if native is unavailable or disabled. Below are the performance changes observed using the built-in CRC32 benchmark. Although performance is poor when bpc <= 64, there are substantial improvements when bpc > 64. To keep the codebase simple and maintainable, I did not add bpc-size-specific handling. | bpc | #T | Native (origin) | Native (new) | Î (MB/s) | Î% | |---:|---:|---:|---:|---:|---:| | 32 | 1 | 661.5 | 463.5 | -198.0 | -29.9% | | 32 | 2 | 642.6 | 491.4 | -151.2 | -23.5% | | 32 | 4 | 663.7 | 480.5 | -183.2 | -27.6% | | 32 | 8 | 653.0 | 472.0 | -181.0 | -27.7% | | 32 | 16 | 656.1 | 473.4 | -182.7 | -27.8% | | 64 | 1 | 793.9 | 318.0 | -475.9 | -59.9% | | 64 | 2 | 771.3 | 322.1 | -449.2 | -58.2% | | 64 | 4 | 787.3 | 315.0 | -472.3 | -60.0% | | 64 | 8 | 778.0 | 309.3 | -468.7 | -60.2% | | 64 | 16 | 773.5 | 308.1 | -465.4 | -60.2% | | 128 | 1 | 878.8 | 2398.8 | +1520.0 | +173.0% | | 128 | 2 | 846.8 | 1723.9 | +877.1 | +103.6% | | 128 | 4 | 861.2 | 1690.0 | +828.8 | +96.2% | | 128 | 8 | 857.8 | 1373.3 | +515.5 | +60.1% | | 128 | 16 | 853.8 | 1361.3 | +507.5 | +59.4% | | 256 | 1 | 783.9 | 2752.5 | +1968.6 | +251.1% | | 256 | 2 | 810.0 | 2053.3 | +1243.3 | +153.5% | | 256 | 4 | 835.2 | 1966.5 | +1131.3 | +135.5% | | 256 | 8 | 812.4 | 1756.3 | +943.9 | +116.2% | | 256 | 16 | 811.8 | 1524.7 | +712.9 | +87.8% | | 512 | 1 | 923.6 | 3328.9 | +2405.3 | +260.4% | | 512 | 2 | 886.5 | 3295.1 | +2408.6 | +271.7% | | 512 | 4 | 910.5 | 2359.9 | +1449.4 | +159.2% | | 512 | 8 | 888.1 | 1637.4 | +749.3 | +84.4% | | 512 | 16 | 897.0 | 1840.1 | +943.1 | +105.1% | | 1024 | 1 | 950.4 | 3045.0 | +2094.6 | +220.4% | | 1024 | 2 | 918.0 | 2202.9 | +1284.9 | +140.0% | | 1024 | 4 | 937.6 | 2040.4 | +1102.8 | +117.6% | | 1024 | 8 | 916.5 | 1961.5 | +1045.0 | +114.0% | | 1024 | 16 | 927.4 | 2003.9 | +1076.5 | +116.1% | | 2048 | 1 | 962.3 | 3189.1 | +2226.8 | +231.4% | | 2048 | 2 | 970.1 | 3192.3 | +2222.2 | +229.1% | | 2048 | 4 | 943.4 | 2411.2 | +1467.8 | +155.6% | | 2048 | 8 | 937.6 | 1837.7 | +900.1 | +96.0% | | 2048 | 16 | 933.1 | 1864.0 | +930.9 | +99.8% | | 4096 | 1 | 969.9 | 3654.5 | +2684.6 | +276.8% | | 4096 | 2 | 972.0 | 2798.0 | +1826.0 | +187.9% | | 4096 | 4 | 960.1 | 2307.0 | +1346.9 | +140.3% | | 4096 | 8 | 948.2 | 2753.1 | +1804.9 | +190.4% | | 4096 | 16 | 938.7 | 2170.5 | +1231.8 | +131.2% | | 8192 | 1 | 973.6 | 4008.1 | +3034.5 | +311.7% | | 8192 | 2 | 922.5 | 3018.2 | +2095.7 | +227.2% | | 8192 | 4 | 955.6 | 2968.7 | +2013.1 | +210.7% | | 8192 | 8 | 943.4 | 2077.9 | +1134.5 | +120.3% | | 8192 | 16 | 944.9 | 2191.7 | +1246.8 | +132.0% | | 16384 | 1 | 974.4 | 4090.3 | +3115.9 | +319.8% | | 16384 | 2 | 978.3 | 2999.6 | +2021.3 | +206.6% | | 16384 | 4 | 956.6 | 3248.9 | +2292.3 | +239.6% | | 16384 | 8 | 950.8 | 3228.0 | +2277.2 | +239.5% | | 16384 | 16 | 941.2 | 2832.1 | +1890.9 | +200.9% | | 32768 | 1 | 972.2 | 4205.7 | +3233.5 | +332.6% | | 32768 | 2 | 938.6 | 4115.2 | +3176.6 | +338.4% | | 32768 | 4 | 957.4 | 2508.9 | +1551.5 | +162.1% | | 32768 | 8 | 952.8 | 2319.8 | +1367.0 | +143.5% | | 32768 | 16 | 944.5 | 1657.7 | +713.2 | +75.5% | | 65536 | 1 | 976.3 | 4226.6 | +3250.3 | +332.9% | | 65536 | 2 | 940.0 | 3075.8 | +2135.8 | +227.2% | | 65536 | 4 | 958.5 | 1345.2 | +386.7 | +40.3% | | 65536 | 8 | 950.2 | 1954.7 | +1004.5 | +105.7% | | 65536 | 16 | 945.8 | 2414.0 | +1468.2 | +155.2% | ### How was this patch tested? Built hadoop-common with native profile on riscv64; verified it's function by TestNativeCrc32. Ran Hadoop\u2019s CRC32 benchmark on riscv64 (OpenEuler/EulixOS) with JDK 17. Here is the commands and results: Commandï¼ ``` mvn -Pnative \\ -Dtest=org.apache.hadoop.util.TestNativeCrc32 \\ -Djava.library.path=\"$HADOOP_COMMON_LIB_NATIVE_DIR\" \\ test ``` Results ``` [INFO] ------------------------------------------------------- [INFO] T E S T S [INFO] ------------------------------------------------------- [INFO] Running org.apache.hadoop.util.TestNativeCrc32 [INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.017 s\n[ASF GitHub Bot @ 2025-10-13T19:25:51.530+0000]: hadoop-yetus commented on PR #8031: URL: https://github.com/apache/hadoop/pull/8031#issuecomment-3398778305 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 23m 29s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 47m 25s | | trunk passed | | +1 :green_heart: | compile | 14m 16s | | trunk passed | | +1 :green_heart: | mvnsite | 2m 32s | | trunk passed | | +1 :green_heart: | shadedclient | 101m 41s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 1m 10s | | the patch passed | | +1 :green_heart: | compile | 13m 15s | | the patch passed | | +1 :green_heart: | cc | 13m 15s | | the patch passed | | +1 :green_heart: | golang | 13m 15s | | the patch passed | | +1 :green_heart: | javac | 13m 15s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 2m 29s | | the patch passed | | +1 :green_heart: | shadedclient | 39m 47s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 23m 25s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 57s | | The patch does not generate ASF License warnings. | | | | 206m 55s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8031 | | Optional Tests | dupname asflicense compile cc mvnsite javac unit codespell detsecrets golang | | uname | Linux cf2b3cead534 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 0e62b049f710f680823489b1a77892ed49252fc4 | | Default Java | Red Hat, Inc.-1.8.0_462-b08 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/testReport/ | | Max. process+thread count | 1376 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8031/1/console | | versions | git=2.43.7 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-14T12:08:33.735+0000]: PeterPtroc commented on PR #8031: URL: https://github.com/apache/hadoop/pull/8031#issuecomment-3401469367 @steveloughran could you please review this PR if you have time? thanks!","key":"HADOOP-19724","status":"Open","labels":"native|pull-request-available|risc-v"}
{"summary":"Build multi-arch hadoop image","created":"2025-10-09T09:22:57.000+0000","description":"Build {{apache/hadoop}} Docker image for both amd64 and arm64.","assignee":"Attila Doroszlai","priority":"Major","updated":"2025-10-10T06:07:00.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-09T13:28:31.642+0000]: adoroszlai opened a new pull request, #8023: URL: https://github.com/apache/hadoop/pull/8023 ## What changes were proposed in this pull request? - Update `Dockerfile` (on branch `docker-hadoop-3.4.2-lean`) to support building for `arm64`, too. - Use `ghcr.io/apache/hadoop-runner:jdk11-u2204` as base, because `apache/hadoop-runner:latest` only has `amd64` image available. - Use `TARGETPLATFORM` to decide which tarball to use. - Create args for version and flavor, replacing URL. - Update the `build-hadoop-image` workflow to create multi-arch images. - Add build-arg `BASE_URL` to allow using mirrors (for faster local build). - Replace deprecated `ENV HADOOP_CONF_DIR ` syntax. https://issues.apache.org/jira/browse/HADOOP-19723 ## How was this patch tested? Workflow [run](https://github.com/adoroszlai/hadoop/actions/runs/18377713437) in my fork created multi-arch [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop/539671710?tag=HADOOP-19723). ``` #8 0.060 Building for linux/amd64 ... #8 0.060 + export HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2-lean.tar.gz ... #10 0.076 Building for linux/arm64 ... #10 0.077 + export HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2-aarch64-lean.tar.gz ``` Tested on both amd64 and arm64 platforms. ``` $ docker run -it --rm ghcr.io/adoroszlai/hadoop:HADOOP-19723 bash -c \"uname -a; hadoop version\" Linux cdb5cdd5ace9 6.8.0-65-generic #68~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 15 18:06:34 UTC 2 x86_64 x86_64 x86_64 GNU/Linux Hadoop 3.4.2 Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c Compiled by ahmarsu on 2025-08-20T10:30Z Compiled on platform linux-x86_64 Compiled with protoc 3.23.4 From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6 This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar ``` ``` $ docker run -it --rm ghcr.io/adoroszlai/hadoop:HADOOP-19723 bash -c \"uname -a; hadoop version\" Linux 9a1237ba8fbc 6.10.14-linuxkit #1 SMP Thu Oct 24 19:28:55 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux Hadoop 3.4.2 Source code repository https://github.com/apache/hadoop.git -r e1c0dee881820a4d834ec4a4d2c70d0d953bb933 Compiled by ahmar on 2025-08-07T15:32Z Compiled on platform linux-aarch_64 Compiled with protoc 3.23.4 From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6 This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar ```\n[ASF GitHub Bot @ 2025-10-09T13:32:27.838+0000]: slfan1989 commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3385915162 LGTM.\n[ASF GitHub Bot @ 2025-10-09T13:36:31.183+0000]: slfan1989 commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3385930578 @adoroszlai Thank you for the contribution. If there are no additional comments, I\u2019ll proceed to merge this PR shortly.\n[ASF GitHub Bot @ 2025-10-09T17:36:49.722+0000]: adoroszlai commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3386892439 @smengcl would you like to take a look?\n[ASF GitHub Bot @ 2025-10-10T02:17:01.464+0000]: slfan1989 commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388049001 > @smengcl would you like to take a look? @smengcl I believe this PR is fine, and since @adoroszlai has extensive experience with this, any issues that may arise in the future can be quickly addressed. I will go ahead and merge this PR.\n[ASF GitHub Bot @ 2025-10-10T02:18:07.403+0000]: slfan1989 merged PR #8023: URL: https://github.com/apache/hadoop/pull/8023\n[ASF GitHub Bot @ 2025-10-10T05:46:22.120+0000]: adoroszlai commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388373138 Thanks @slfan1989 for reviewing and merging this.\n[ASF GitHub Bot @ 2025-10-10T06:07:00.188+0000]: smengcl commented on PR #8023: URL: https://github.com/apache/hadoop/pull/8023#issuecomment-3388411324 Thanks @adoroszlai . The patch looks good. Thanks @slfan1989 for reviewing this as well.","key":"HADOOP-19723","status":"Resolved","labels":"pull-request-available"}
{"summary":"Pin robotframework version","created":"2025-10-09T07:00:41.000+0000","description":"{{hadoop-runner}} installs {{robotframework}} without version definition.  Re-building the image for unrelated changes may unexpectedly upgrade {{robotframework}}, too.","assignee":"Attila Doroszlai","priority":"Minor","updated":"2025-10-12T17:54:24.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-09T21:43:03.656+0000]: adoroszlai opened a new pull request, #8025: URL: https://github.com/apache/hadoop/pull/8025 ## What changes were proposed in this pull request? `hadoop-runner` installs `robotframework` without version definition. Re-building the image for unrelated changes may unexpectedly upgrade `robotframework`, too. This PR proposes to pin `robotframework` to version 6.1.1. https://issues.apache.org/jira/browse/HADOOP-19722 ## How was this patch tested? ``` $ docker build -t hadoop-runner:dev . ... $ docker run -it --rm hadoop-runner:dev robot --version Robot Framework 6.1.1 (Python 3.10.12 on linux) ```\n[ASF GitHub Bot @ 2025-10-10T18:04:51.727+0000]: smengcl merged PR #8025: URL: https://github.com/apache/hadoop/pull/8025\n[ASF GitHub Bot @ 2025-10-12T17:54:24.510+0000]: adoroszlai commented on PR #8025: URL: https://github.com/apache/hadoop/pull/8025#issuecomment-3395090403 Thanks @slfan1989, @smengcl for the review.","key":"HADOOP-19722","status":"Resolved","labels":"pull-request-available"}
{"summary":"Upgrade hadoop-runner to Ubuntu 24.04","created":"2025-10-09T06:23:41.000+0000","description":"Latest {{hadoop-runner}} images are based on Ubuntu 22.04.  Upgrade to 24.04.","assignee":"Attila Doroszlai","priority":"Minor","updated":"2025-10-09T06:23:41.000+0000","commentText":"","key":"HADOOP-19721","status":"Open","labels":""}
{"summary":"Publish multi-arch hadoop-runner image to GitHub","created":"2025-10-08T17:21:10.000+0000","description":"Create GitHub Actions workflow to publish the apache/hadoop-runner Docker image to GitHub Container Registry.  Build for both amd64 and arm64.","assignee":"Attila Doroszlai","priority":"Major","updated":"2025-10-09T07:01:33.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-08T17:38:33.167+0000]: adoroszlai opened a new pull request, #8021: URL: https://github.com/apache/hadoop/pull/8021 ## What changes were proposed in this pull request? Add workflow to publish `apache/hadoop-runner` (`jdk11-u2204` in this case) to GitHub Container Registry. https://issues.apache.org/jira/browse/HADOOP-19720 ## How was this patch tested? [Workflow run](https://github.com/adoroszlai/hadoop/actions/runs/18353000644) in my fork for push to branch `docker-hadoop-runner-HADOOP-19720-jdk11-u2204` built [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop-runner/538747134?tag=HADOOP-19720-jdk11-u2204) `ghcr.io/adoroszlai/hadoop-runner:HADOOP-19720-jdk11-u2204`. It has both amd64 and arm64 arch. ```bash $ docker run -it --rm ghcr.io/adoroszlai/hadoop-runner:HADOOP-19720-jdk11-u2204 bash -c 'uname -a; cat /etc/lsb-release; java -version' Linux 8099f50d7322 6.8.0-65-generic #68~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 15 18:06:34 UTC 2 x86_64 x86_64 x86_64 GNU/Linux DISTRIB_ID=Ubuntu DISTRIB_RELEASE=22.04 DISTRIB_CODENAME=jammy DISTRIB_DESCRIPTION=\"Ubuntu 22.04.5 LTS\" openjdk version \"11.0.28\" 2025-07-15 OpenJDK Runtime Environment Temurin-11.0.28+6 (build 11.0.28+6) OpenJDK 64-Bit Server VM Temurin-11.0.28+6 (build 11.0.28+6, mixed mode, sharing) ```\n[ASF GitHub Bot @ 2025-10-09T00:41:07.390+0000]: slfan1989 commented on PR #8021: URL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383664657 @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04?\n[ASF GitHub Bot @ 2025-10-09T02:06:57.985+0000]: smengcl merged PR #8021: URL: https://github.com/apache/hadoop/pull/8021\n[ASF GitHub Bot @ 2025-10-09T02:08:15.780+0000]: smengcl commented on PR #8021: URL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383797788 > @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04? We could file a new jira for that task.\n[ASF GitHub Bot @ 2025-10-09T02:16:23.811+0000]: slfan1989 commented on PR #8021: URL: https://github.com/apache/hadoop/pull/8021#issuecomment-3383809271 > > @adoroszlai Many thanks for your contribution. Could we consider upgrading the image to ubuntu 24.04? > > We could file a new jira for that task. You\u2019ve got a valid point. The branch name is indeed for 22.04, so we can address it in the next JIRA task.\n[ASF GitHub Bot @ 2025-10-09T06:05:01.762+0000]: adoroszlai commented on PR #8021: URL: https://github.com/apache/hadoop/pull/8021#issuecomment-3384254098 Thanks @slfan1989, @smengcl for the review.","key":"HADOOP-19720","status":"Resolved","labels":"pull-request-available"}
{"summary":"Upgrade to wildfly version with support for openssl 3","created":"2025-10-08T10:52:33.000+0000","description":"Wildfly 2.1.4\r\n* doesn't work with openssl 3 (that symbol change...why did they do that?)\r\n\r\n\r\nwe need a version with \r\nhttps://github.com/wildfly-security/wildfly-openssl-natives/commit/6cecd42a254cd78585fefd9a0e41ad7954ece80d\r\n\r\n2.2.5.Final does the openssl 3 support. ","assignee":"Steve Loughran","priority":"Major","updated":"2025-10-20T12:47:50.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-08T10:59:16.505+0000]: steveloughran opened a new pull request, #8019: URL: https://github.com/apache/hadoop/pull/8019 ### How was this patch tested? Going to see if it works on a mac... ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [X] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-08T12:41:04.887+0000]: steveloughran commented on PR #8019: URL: https://github.com/apache/hadoop/pull/8019#issuecomment-3381330281 the test which is parameterized on ssl (and storediag when a store is forced to OpenSSL) ``` [ERROR] org.apache.hadoop.fs.contract.s3a.ITestS3AContractSeek.testReadFullyZeroBytebufferPastEOF\n[ASF GitHub Bot @ 2025-10-08T12:55:21.261+0000]: steveloughran commented on PR #8019: URL: https://github.com/apache/hadoop/pull/8019#issuecomment-3381381104 s3a tests all good, s3 london `-Dparallel-tests -DtestsThreadCount=8`\n[ASF GitHub Bot @ 2025-10-15T11:07:38.888+0000]: steveloughran commented on PR #8019: URL: https://github.com/apache/hadoop/pull/8019#issuecomment-3405882774 OK, 2.2.5 doesn't include the arm linux binaries. It does in our private builds, which is why I was confused.\n[ASF GitHub Bot @ 2025-10-20T12:45:49.133+0000]: steveloughran merged PR #8019: URL: https://github.com/apache/hadoop/pull/8019","key":"HADOOP-19719","status":"Resolved","labels":"pull-request-available"}
{"summary":"[ABFS]: Throw HTTPException when AAD token fetch fails ","created":"2025-10-07T12:56:26.000+0000","description":"Reported by [~enigma25] :\r\nIn [this code snippet](https://github.com/Azure/azure-data-lake-store-java/blob/26eca936da60286aa70b0dd7823ff5e627987bc4/src/main/java/com/microsoft/azure/datalake/store/oauth2/AzureADAuthenticator.java#L252-L293) from AzureADAuthenticator, the `conn` is being returned as null due to a (possibly) corrupted connection between Azure Data Lake Store Client and AAD while fetching AAD token. The code snippet linked, runs into an NPE. I wanted to know from the maintainers and community if this bug/symptom has been seen by them earlier and what might be the best way to handle this? Secondly, I wanted to know the right place for the fix too - whether it should be the application code or the SDK code itself should handle such NPEs and fail more gracefully?\r\nOpen to thoughts and comments.\r\nCheers,\r\nNikhil\r\nÂ \r\nÂ \r\n```\r\njava.util.concurrent.ExecutionException: java.lang.NullPointerException: Cannot invoke \"java.io.InputStream.read(byte[], int, int)\" because \"inStream\" is null\r\nat org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:135)\r\nat org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:122)\r\nat org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource.validateConfigs(ConnectorPluginsResource.java:129)\r\nat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\nat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\nat org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)\r\nat org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)\r\nat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)\r\nat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)\r\nat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)\r\nat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\r\nat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\r\nat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\r\nat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)\r\nat org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)\r\nat org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)\r\nat org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)\r\nat org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)\r\nat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)\r\nat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\r\nat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\nat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\r\nat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\r\nat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\nat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\r\nat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)\r\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\nat org.eclipse.jetty.server.Server.handle(Server.java:516)\r\nat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\r\nat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\r\nat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\r\nat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\r\nat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\nat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\nat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\r\nat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\r\nat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.lang.NullPointerException: Cannot invoke \"java.io.InputStream.read(byte[], int, int)\" because \"inStream\" is null\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.consumeInputStream(AzureADAuthenticator.java:345)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenSingleCall(AzureADAuthenticator.java:275)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenCall(AzureADAuthenticator.java:216)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator.getTokenUsingClientCreds(AzureADAuthenticator.java:95)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider.refreshToken(ClientCredsTokenProvider.java:58)\r\nat org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider.getToken(AccessTokenProvider.java:50)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getAccessToken(AbfsClient.java:583)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(AbfsRestOperation.java:162)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\r\nat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:205)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.verifyClient(Validations.java:175)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.createAndValidateClient(Validations.java:395)\r\nat io.confluent.connect.azure.datalake.gen2.validation.Validations.validateAll(Validations.java:131)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.lambda$callValidators$0(ConfigValidation.java:222)\r\nat java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)\r\nat java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.callValidators(ConfigValidation.java:222)\r\nat io.confluent.connect.utils.validators.all.ConfigValidation.validate(ConfigValidation.java:182)\r\nat io.confluent.connect.azure.datalake.gen2.AzureDataLakeGen2SinkConnector.validate(AzureDataLakeGen2SinkConnector.java:97)\r\nat org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:641)\r\nat org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$7(AbstractHerder.java:493)\r\nat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\r\nat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\nat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n... 1 more\r\n```","assignee":"Sneha Vijayarajan","priority":"Minor","updated":"2025-10-07T12:56:26.000+0000","commentText":"","key":"HADOOP-19718","status":"Open","labels":""}
{"summary":"Resolve build error caused by missing Checker Framework (NonNull not recognized)","created":"2025-10-07T03:49:55.000+0000","description":"In the recent build, we encountered the following issue: *org.checkerframework.checker.nullness.qual.NonNull* could not be recognized, and the following error was observed.\r\n{code:java}\r\n[ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-8011/ubuntu-focal/src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[216,50] package org.checkerframework.checker.nullness.qual does not exist\r\n[ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-8011/ubuntu-focal/src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[2509,30] cannot find symbol\r\n[ERROR]   symbol:   class NonNull\r\n[ERROR]   location: class org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.AsyncThreadFactory\r\n {code}\r\nI checked the usage in the related modules, and we should use *org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.NonNull* instead of directly using {*}org.checkerframework.checker.nullness.qual.NonNull{*}.\r\n\r\nÂ ","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-20T16:32:20.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-07T04:01:33.037+0000]: slfan1989 opened a new pull request, #8015: URL: https://github.com/apache/hadoop/pull/8015 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR JIRA: HADOOP-19717. Resolve build error caused by missing Checker Framework (NonNull not recognized). ### How was this patch tested? ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-07T04:48:15.069+0000]: pan3793 commented on code in PR #8015: URL: https://github.com/apache/hadoop/pull/8015#discussion_r2409341008 ########## hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java: ########## @@ -19,7 +19,7 @@ package org.apache.hadoop.fs.tosfs.util; import org.apache.hadoop.util.Preconditions; -import org.checkerframework.checker.nullness.qual.Nullable; +import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable; Review Comment: I suspect this makes the `Nullable` useless, I don't think the static analyzer tools can recognize such a relocated annotation.\n[ASF GitHub Bot @ 2025-10-07T06:36:36.034+0000]: hadoop-yetus commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3375421893 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 8m 31s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 8m 35s | | Maven dependency ordering for branch | | -1 :x: | mvninstall | 22m 41s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 5m 25s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 4m 39s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 1m 18s | | trunk passed | | -1 :x: | mvnsite | 0m 24s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | mvnsite | 0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | -1 :x: | javadoc | 0m 27s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 16s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | +1 :green_heart: | javadoc | 0m 39s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | spotbugs | 0m 25s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | spotbugs | 0m 16s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | +1 :green_heart: | shadedclient | 24m 7s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 23s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 0m 37s | | the patch passed | | -1 :x: | compile | 5m 41s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 5m 41s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 5m 11s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 5m 10s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 12s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 41s | | the patch passed | | +1 :green_heart: | javadoc | 0m 20s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 16s | | hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 21s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | javadoc | 0m 19s | | hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | spotbugs | 1m 33s | | the patch passed | | +1 :green_heart: | shadedclient | 20m 26s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 38m 54s | | hadoop-hdfs-rbf in the patch passed. | | +1 :green_heart: | unit | 0m 54s | | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 26s | | The patch does not generate ASF License warnings. | | | | 154m 4s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8015 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 1ad3180c6b2e 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / f0c771fd1f48e1cc45617d4e2eb0afb552e5ba1f | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/testReport/ | | Max. process+thread count | 4610 (vs. ulimit of 5500) | | modules | C: hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/1/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T11:19:14.896+0000]: slfan1989 commented on code in PR #8015: URL: https://github.com/apache/hadoop/pull/8015#discussion_r2410285097 ########## hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java: ########## @@ -19,7 +19,7 @@ package org.apache.hadoop.fs.tosfs.util; import org.apache.hadoop.util.Preconditions; -import org.checkerframework.checker.nullness.qual.Nullable; +import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable; Review Comment: I think what you said makes some sense, but there are similar users in AzureBFS as well. https://github.com/apache/hadoop/blob/1566613c725979d0ccda45822dfa275cbd97467a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java#L38\n[ASF GitHub Bot @ 2025-10-07T11:20:49.833+0000]: slfan1989 commented on code in PR #8015: URL: https://github.com/apache/hadoop/pull/8015#discussion_r2410285097 ########## hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java: ########## @@ -19,7 +19,7 @@ package org.apache.hadoop.fs.tosfs.util; import org.apache.hadoop.util.Preconditions; -import org.checkerframework.checker.nullness.qual.Nullable; +import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable; Review Comment: I think what you said makes some sense, but there are similar users in AzureBFS as well. https://github.com/apache/hadoop/blob/1566613c725979d0ccda45822dfa275cbd97467a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java#L38 @steveloughran I\u2019d like to hear your thoughts \u2014 do you think we should reintroduce a new dependency to resolve the issue where org.checkerframework.checker.nullness.qual.Nullable cannot be found? cc: @szetszwo\n[ASF GitHub Bot @ 2025-10-07T13:18:47.987+0000]: hadoop-yetus commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3376863181 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 20s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 2 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 8m 12s | | Maven dependency ordering for branch | | -1 :x: | mvninstall | 22m 36s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 5m 21s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 4m 43s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 1m 24s | | trunk passed | | -1 :x: | mvnsite | 0m 24s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | mvnsite | 0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | -1 :x: | javadoc | 0m 18s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 16s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | +1 :green_heart: | javadoc | 1m 4s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | spotbugs | 0m 22s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | spotbugs | 0m 17s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | +1 :green_heart: | shadedclient | 21m 20s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 22s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 1m 4s | | the patch passed | | -1 :x: | compile | 5m 49s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 5m 49s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 5m 5s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 5m 5s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 12s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 19s | | the patch passed | | +1 :green_heart: | javadoc | 0m 25s | | hadoop-yarn-server-resourcemanager in the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | +1 :green_heart: | javadoc | 0m 20s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 17s | | hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 27s | | hadoop-yarn-server-resourcemanager in the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | javadoc | 0m 22s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | javadoc | 0m 19s | | hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | spotbugs | 2m 41s | | the patch passed | | +1 :green_heart: | shadedclient | 20m 13s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 90m 40s | | hadoop-yarn-server-resourcemanager in the patch passed. | | +1 :green_heart: | unit | 38m 2s | | hadoop-hdfs-rbf in the patch passed. | | +1 :green_heart: | unit | 0m 53s | | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 24s | | The patch does not generate ASF License warnings. | | | | 241m 25s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8015 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux de756f6ac704 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / aca0e73a716b49f41b6eb3e0a57c876842a258a8 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/testReport/ | | Max. process+thread count | 4761 (vs. ulimit of 5500) | | modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/2/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T13:54:35.628+0000]: hadoop-yetus commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377007084 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 21s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 8m 46s | | Maven dependency ordering for branch | | -1 :x: | mvninstall | 26m 13s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 6m 12s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 5m 18s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 1m 19s | | trunk passed | | -1 :x: | mvnsite | 0m 25s | [/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | mvnsite | 0m 18s | [/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-mvnsite-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | -1 :x: | javadoc | 0m 23s | [/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-javadoc-hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-hdfs-rbf in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 17s | [/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-javadoc-hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | hadoop-tos in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | +1 :green_heart: | javadoc | 0m 40s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | spotbugs | 0m 25s | [/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-spotbugs-hadoop-hdfs-project_hadoop-hdfs-rbf.txt) | hadoop-hdfs-rbf in trunk failed. | | -1 :x: | spotbugs | 0m 16s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | +1 :green_heart: | shadedclient | 26m 8s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 25s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 0m 41s | | the patch passed | | -1 :x: | compile | 6m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 6m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 5m 50s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 5m 50s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 24s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 45s | | the patch passed | | +1 :green_heart: | javadoc | 0m 20s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 16s | | hadoop-cloud-storage-project_hadoop-tos-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) | | +1 :green_heart: | javadoc | 0m 18s | | hadoop-hdfs-project_hadoop-hdfs-rbf-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | javadoc | 0m 17s | | hadoop-cloud-storage-project_hadoop-tos-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 0 new + 0 unchanged - 2 fixed = 0 total (was 2) | | +1 :green_heart: | spotbugs | 1m 28s | | the patch passed | | +1 :green_heart: | shadedclient | 23m 54s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 39m 4s | | hadoop-hdfs-rbf in the patch passed. | | +1 :green_heart: | unit | 0m 54s | | hadoop-tos in the patch passed. | | +1 :green_heart: | asflicense | 0m 25s | | The patch does not generate ASF License warnings. | | | | 158m 17s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8015 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 30e4a84a468c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / f0c771fd1f48e1cc45617d4e2eb0afb552e5ba1f | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/testReport/ | | Max. process+thread count | 4202 (vs. ulimit of 5500) | | modules | C: hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-cloud-storage-project/hadoop-tos U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8015/3/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T14:28:09.076+0000]: slfan1989 commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377166843 @szetszwo @pan3793 My thought is that since `AzureBFS` already uses this approach, we should be able to apply the same solution in other places as well. For now, we can use`org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable` instead of `org.checkerframework.checker.nullness.qual.Nullable` to unblock the trunk build issue first. A follow-up PR can be submitted later to fully resolve this dependency problem in a cleaner way. Currently, the build result is as expected \u2014 before applying this patch, the trunk could not compile successfully, but after merging it, the build now passes under both JDK 8 and JDK 11.\n[ASF GitHub Bot @ 2025-10-07T15:30:58.356+0000]: szetszwo commented on code in PR #8015: URL: https://github.com/apache/hadoop/pull/8015#discussion_r2411050812 ########## hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java: ########## @@ -19,7 +19,7 @@ package org.apache.hadoop.fs.tosfs.util; import org.apache.hadoop.util.Preconditions; -import org.checkerframework.checker.nullness.qual.Nullable; +import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable; Review Comment: > ... this makes the Nullable useless, ... Making it useless seems better than breaking the build. Unforturately, the the builds after this remain failing.\n[ASF GitHub Bot @ 2025-10-07T15:32:12.017+0000]: szetszwo commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377457340 @slfan1989 , if it can fix the build, then it is fine. But the builds after this remain failing.\n[ASF GitHub Bot @ 2025-10-07T15:36:23.621+0000]: slfan1989 commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377471954 > @slfan1989 , if it can fix the build, then it is fine. But the builds after this remain failing. @szetszwo A new issue occurred during the compilation of yarn-ui. The log output is as follows: ``` [INFO] [2/4] Fetching packages... [INFO] error color@5.0.2: The engine \"node\" is incompatible with this module. Expected version \">=18\". Got \"12.22.1\" [INFO] error Found incompatible module. ```\n[ASF GitHub Bot @ 2025-10-07T15:55:40.527+0000]: slfan1989 commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377538969 > > @slfan1989 , if it can fix the build, then it is fine. But the builds after this remain failing. > > @szetszwo A new issue occurred during the compilation of yarn-ui. The log output is as follows: > > ``` > [INFO] [2/4] Fetching packages... > [INFO] error color@5.0.2: The engine \"node\" is incompatible with this module. Expected version \">=18\". Got \"12.22.1\" > [INFO] error Found incompatible module. > ``` > > I tried to apply a local fix for this issue. I manually specified `color@^3.1.3` in the package.json, and it took effect successfully. I will submit a PR to fix this issue. ``` [INFO] -\n[ASF GitHub Bot @ 2025-10-07T15:58:33.738+0000]: slfan1989 merged PR #8015: URL: https://github.com/apache/hadoop/pull/8015\n[ASF GitHub Bot @ 2025-10-07T15:59:04.147+0000]: slfan1989 commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377550294 @szetszwo Thank you very much for the review!\n[ASF GitHub Bot @ 2025-10-07T16:20:51.703+0000]: szetszwo commented on PR #8015: URL: https://github.com/apache/hadoop/pull/8015#issuecomment-3377632827 @slfan1989 , thanks for fixing it!\n[Steve Loughran @ 2025-10-20T16:32:20.848+0000]: this is complicating the new thirdparty release FWIW. this should all be using the unshaded javax. Nullable/nonnull. And the hadoop-thirdparty release needs to address this stuff getting left out so 1.5.0 can be a drop-in replacement for 1.4.0 {code} [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-tos: Compilation failure: Compilation failure: [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:[22,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/src/main/java/org/apache/hadoop/fs/tosfs/util/Iterables.java:[89,29] cannot find symbol [ERROR] symbol: class Nullable [ERROR] location: class org.apache.hadoop.fs.tosfs.util.Iterables [ERROR] -> [Help 1] [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-azure: Compilation failure: Compilation failure: [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java:[38,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java:[183,30] cannot find symbol [ERROR] symbol: class Nullable [ERROR] -> [Help 1] [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.10.1:compile (default-compile) on project hadoop-hdfs-rbf: Compilation failure: Compilation failure: [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[102,79] package org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual does not exist [ERROR] /Users/stevel/Projects/hadoop-trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java:[2509,30] cannot find symbol [ERROR] symbol: class NonNull [ERROR] location: class org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.AsyncThreadFactory [ERROR] -> [Help 1] [ERROR] {code}","key":"HADOOP-19717","status":"Resolved","labels":"pull-request-available"}
{"summary":"Create lean docker image","created":"2025-10-06T09:52:36.000+0000","description":"Create a new docker image based on the lean tarball.\r\n\r\nhadoop-3.4.2-lean.tar.gz","assignee":"Attila Doroszlai","priority":"Minor","updated":"2025-10-09T10:04:45.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-06T10:21:27.419+0000]: adoroszlai opened a new pull request, #8013: URL: https://github.com/apache/hadoop/pull/8013 ### Description of PR Create a new docker image based on `hadoop-3.4.2-lean.tar.gz`, which omits AWS `bundle-2.29.52.jar`. This PR should not be merged. I will push it from CLI as a new branch to publish the image with Docker tag `3.4.2-lean`, rather than overwrite the existing image `3.4.2`. ### How was this patch tested? [Workflow run](https://github.com/adoroszlai/hadoop/actions/runs/18277349554/job/52032416240) in my fork created the [image](https://github.com/adoroszlai/hadoop/pkgs/container/hadoop/535792302?tag=3.4.2-lean).\n[ASF GitHub Bot @ 2025-10-06T13:24:55.757+0000]: steveloughran commented on PR #8013: URL: https://github.com/apache/hadoop/pull/8013#issuecomment-3371636931 I did check the url resolved, BTW. Note that in #7980 packaging will change where we move hadoop-aws and hadoop azure to common/lib, with all dependencies except bundle.jar; that'll come iff you do a \"-Paws-sdk\" build. And the other cloud modules will come in if you explicitly ask for them. Still a WiP; hope to be done ASAP with hadoop 3.4.3 like this. No more \"let's strip the build\" work, instead just choose the build options for a release.\n[ASF GitHub Bot @ 2025-10-06T13:29:21.550+0000]: adoroszlai commented on PR #8013: URL: https://github.com/apache/hadoop/pull/8013#issuecomment-3371660323 Thanks @steveloughran for the review. Pushed 4cb319a9a98350bb0711029cf13c170f3c9ce043 to `docker-hadoop-3.4.2-lean`.\n[ASF GitHub Bot @ 2025-10-06T13:29:23.259+0000]: adoroszlai closed pull request #8013: HADOOP-19716. Create lean docker image URL: https://github.com/apache/hadoop/pull/8013\n[ASF GitHub Bot @ 2025-10-07T03:27:48.606+0000]: slfan1989 commented on PR #8013: URL: https://github.com/apache/hadoop/pull/8013#issuecomment-3375033744 > Thanks @steveloughran for the review. Pushed [4cb319a](https://github.com/apache/hadoop/commit/4cb319a9a98350bb0711029cf13c170f3c9ce043) to `docker-hadoop-3.4.2-lean`. @adoroszlai Thanks for the contribution! LGTM.","key":"HADOOP-19716","status":"Resolved","labels":"pull-request-available"}
{"summary":"Update restrict-imports-enforcer-rule from 2.0.0 to 2.6.1","created":"2025-10-06T01:54:13.000+0000","description":"The project is currently using {{restrict-imports-enforcer-rule}} version {*}2.0.0{*}, which was released in *2021* and is now outdated. Since then, several new versions have been released with important bug fixes, performance improvements, and enhanced compatibility. To maintain a modern and stable build environment, it is necessary to upgrade to version {*}2.6.1{*}.","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-09T02:36:22.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-06T01:56:49.760+0000]: slfan1989 opened a new pull request, #8012: URL: https://github.com/apache/hadoop/pull/8012 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR JIRA: HADOOP-19715. Update restrict-imports-enforcer-rule from 2.0.0 to 2.6.1. ### How was this patch tested? CI. ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-08T02:31:11.496+0000]: hadoop-yetus commented on PR #8012: URL: https://github.com/apache/hadoop/pull/8012#issuecomment-3379348657 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 43s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | -1 :x: | mvninstall | 0m 25s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 0m 24s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 0m 25s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | mvnsite | 0m 25s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | -1 :x: | javadoc | 0m 25s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 24s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | shadedclient | 3m 37s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | mvninstall | 0m 24s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-mvninstall-root.txt) | root in the patch failed. | | -1 :x: | compile | 0m 24s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 0m 24s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 0m 22s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 0m 22s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 0m 25s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | -1 :x: | javadoc | 0m 24s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 24s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | shadedclient | 4m 41s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +0 :ok: | asflicense | 0m 28s | | ASF License check generated no output? | | | | 13m 6s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8012 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux bcae851086b8 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / f59839a3b410ba91d777948cc1b8683d10006e31 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/testReport/ | | Max. process+thread count | 55 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/2/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-08T06:30:10.067+0000]: hadoop-yetus commented on PR #8012: URL: https://github.com/apache/hadoop/pull/8012#issuecomment-3379885563 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 41s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | -1 :x: | mvninstall | 3m 52s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 1m 29s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 3m 18s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | mvnsite | 1m 41s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | -1 :x: | javadoc | 0m 25s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 26s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | shadedclient | 13m 13s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | mvninstall | 1m 44s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-mvninstall-root.txt) | root in the patch failed. | | -1 :x: | compile | 0m 39s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 0m 39s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 0m 24s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 0m 24s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 0m 24s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | -1 :x: | javadoc | 0m 25s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 24s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | shadedclient | 4m 6s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 24s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 0m 27s | | The patch does not generate ASF License warnings. | | | | 23m 47s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8012 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 679e127e6ac4 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 67cae1f9eee8d0b5bb049e7b261a4e70c00d46a3 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/testReport/ | | Max. process+thread count | 106 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/3/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-09T02:36:22.249+0000]: hadoop-yetus commented on PR #8012: URL: https://github.com/apache/hadoop/pull/8012#issuecomment-3383838383 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 42s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 59m 35s | | trunk passed | | -1 :x: | compile | 19m 32s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 12s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | mvnsite | 0m 39s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | -1 :x: | javadoc | 0m 43s | [/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 45s | [/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/branch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | shadedclient | 93m 50s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | mvninstall | 0m 24s | [/patch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-mvninstall-root.txt) | root in the patch failed. | | -1 :x: | compile | 0m 22s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 0m 22s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 0m 21s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 0m 21s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 0m 9s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | -1 :x: | javadoc | 0m 27s | [/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javadoc | 0m 25s | [/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | shadedclient | 3m 9s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 0m 25s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +0 :ok: | asflicense | 0m 13s | | ASF License check generated no output? | | | | 101m 41s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8012 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux cfb99cb39a9f 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 96e6841274b4e99041a4d0bc12af671c07a5d62f | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/testReport/ | | Max. process+thread count | 258 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8012/4/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.","key":"HADOOP-19715","status":"In Progress","labels":"pull-request-available"}
{"summary":"make container build work on macOS Tahoe","created":"2025-10-02T23:15:57.000+0000","description":"macOS Tahoe includes a native container daemon and runtime and it is supposed to be near feature-compatible with docker. In principle, it should be possible to run the container build using the container command line on macOS Tahoe.\r\n\r\nIt would be great if we can add this functionality to the build script so folks can build on macOS natively without creating another VM.","assignee":"","priority":"Minor","updated":"2025-10-07T19:12:45.000+0000","commentText":"[Sangjin Lee @ 2025-10-02T23:16:24.184+0000]: This could be someone's good hack project.\n[Steve Loughran @ 2025-10-03T10:36:51.207+0000]: this means you can run linux in it? cool. puts it on a par with windows -though that has the advantage you can just dual boot the machine to linux or just replace windows entirely\n[Sangjin Lee @ 2025-10-03T15:05:59.967+0000]: Correct. This is a container daemon/runtime that runs natively on Apple (Silicon), which does pretty much all the things that a Docker runtime would do without involving VMs. Also, I understand you can install this on macOS before Tahoe. Here's one article (among many out there): [https://www.infoq.com/news/2025/06/apple-container-linux/]\n[Steve Loughran @ 2025-10-07T19:12:45.062+0000]: after the NPM attack last month, I'm thinking I should do all builds which pull in remote artifacts in its own container, one with restricted access to the rest of the system lyes, complicates getting aws credentials, but that's part of what I want to lock down). ...","key":"HADOOP-19713","status":"Open","labels":""}
{"summary":"S3A: Deadlock observed in IOStatistics EvaluatingStatisticsMap.entryset()","created":"2025-10-01T15:29:06.000+0000","description":"\r\nWe have evidence that `IOStatisticsSupport.snapshotIOStatistics()` can hang, specifically on the statistics collected by an S3AInputStream, whose statistics are merged in to the FS stats in close();\r\n\r\n{code}\r\njdk.internal.misc.Unsafe.park(Native Method)\r\njava.util.concurrent.locks.LockSupport.park(LockSupport.java:341)\r\njava.util.concurrent.ForkJoinTask.awaitDone(ForkJoinTask.java:468)\r\njava.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:687)\r\njava.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:927)\r\njava.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\r\njava.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)\r\norg.apache.hadoop.fs.statistics.impl.EvaluatingStatisticsMap.entrySet(EvaluatingStatisticsMap.java:166)\r\njava.util.Collections$UnmodifiableMap.entrySet(Collections.java:1529)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.copyMap(IOStatisticsBinding.java:172)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.snapshotMap(IOStatisticsBinding.java:216)\r\norg.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.snapshotMap(IOStatisticsBinding.java:199)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSnapshot.snapshot(IOStatisticsSnapshot.java:165)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSnapshot.<init>(IOStatisticsSnapshot.java:125)\r\norg.apache.hadoop.fs.statistics.IOStatisticsSupport.snapshotIOStatistics(IOStatisticsSupport.java:49)\r\n{code}\r\n\r\nthe code in question is calling `parallelStream()`, which uses a fixed pool of threads shared by all uses of the API\r\n{code}\r\n    Set<Entry<String, E>> r = evalEntries.parallelStream().map((e) ->\r\n        new EntryImpl<>(e.getKey(), e.getValue().apply(e.getKey())))\r\n        .collect(Collectors.toSet());\r\n{code}\r\n\r\nProposed: \r\n* move off parallelStream() to stream()\r\n* review code to if there is any other way this iteration can lead to a deadlock, e.g. the apply() calls.\r\n* could we do the merge more efficiently?\r\n\r\n","assignee":"Steve Loughran","priority":"Major","updated":"2025-10-16T19:22:52.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-01T17:55:27.857+0000]: steveloughran opened a new pull request, #8006: URL: https://github.com/apache/hadoop/pull/8006 Reworked how entrySet() and values() work, using .forEach() iterators after reviewing what ConcurrentHashMap does internally; it does a (safe) traverse. Add EvaluatingStatisticsMap.forEach() implementation which maps the passed in BiConsumer down to the evaluators.forEach, evaluating each value as it goes. Use that in IOStatisticsBinding.snapshot() code. Tests for all this. ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [X] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-01T17:56:35.038+0000]: steveloughran commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3357467095 tested s3 london args ` -Dparallel-tests -DtestsThreadCount=8 -Dscale` ``` [ERROR] Failures: [ERROR] ITestS3APrefetchingInputStream.testReadLargeFileFully:130 [Maxiumum named action_executor_acquired.max] Expecting: <0L> to be greater than: <0L> ```\n[ASF GitHub Bot @ 2025-10-01T21:40:26.267+0000]: hadoop-yetus commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3358241968 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 51s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | -1 :x: | mvninstall | 55m 44s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 12m 48s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 10m 53s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 0m 47s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 29s | | trunk passed | | +1 :green_heart: | javadoc | 1m 7s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 41s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 24s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 33s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 58s | | the patch passed | | -1 :x: | compile | 12m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 12m 27s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 10m 39s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 10m 39s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 0m 42s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) | hadoop-common-project/hadoop-common: The patch generated 3 new + 0 unchanged - 0 fixed = 3 total (was 0) | | +1 :green_heart: | mvnsite | 1m 24s | | the patch passed | | +1 :green_heart: | javadoc | 0m 57s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 39s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 29s | | the patch passed | | +1 :green_heart: | shadedclient | 41m 13s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 15s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 0m 40s | | The patch does not generate ASF License warnings. | | | | 223m 40s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8006 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 48973a6e0048 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 40e7c252a5e39fb8e483afe5f900412bf17cd4a3 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/testReport/ | | Max. process+thread count | 3134 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/1/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-03T10:25:16.497+0000]: steveloughran commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365176292 build failures are in the yarn-ui; it complains that node is too old ``` [INFO] -\n[ASF GitHub Bot @ 2025-10-03T10:38:19.421+0000]: steveloughran commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365209898 I see yarn-ui failure is already covered in a yarn jira.\n[ASF GitHub Bot @ 2025-10-03T14:00:21.280+0000]: hadoop-yetus commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3365792744 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 50s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 2 new or modified test files. | |||| _ trunk Compile Tests _ | | -1 :x: | mvninstall | 52m 57s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 11m 35s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 54s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 0m 45s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 29s | | trunk passed | | +1 :green_heart: | javadoc | 1m 4s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 41s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 21s | | trunk passed | | +1 :green_heart: | shadedclient | 41m 2s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 1m 0s | | the patch passed | | -1 :x: | compile | 11m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 11m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 47s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 9m 47s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 0m 42s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) | hadoop-common-project/hadoop-common: The patch generated 5 new + 0 unchanged - 0 fixed = 5 total (was 0) | | +1 :green_heart: | mvnsite | 1m 25s | | the patch passed | | +1 :green_heart: | javadoc | 0m 58s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 38s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 26s | | the patch passed | | +1 :green_heart: | shadedclient | 40m 56s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 17s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 0m 40s | | The patch does not generate ASF License warnings. | | | | 214m 43s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8006 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux bac1487e44d1 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 78880e82a6bb33e328b07c3273a73289ba5e717d | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/testReport/ | | Max. process+thread count | 1438 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/3/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-06T19:32:56.388+0000]: hadoop-yetus commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3373592220 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 22m 3s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 2 new or modified test files. | |||| _ trunk Compile Tests _ | | -1 :x: | mvninstall | 54m 40s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 11m 34s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 42s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 0m 47s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 28s | | trunk passed | | +1 :green_heart: | javadoc | 1m 5s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 40s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 21s | | trunk passed | | +1 :green_heart: | shadedclient | 41m 18s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 58s | | the patch passed | | -1 :x: | compile | 11m 25s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 11m 25s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 40s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 24s | | the patch passed | | +1 :green_heart: | javadoc | 0m 57s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 37s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 27s | | the patch passed | | +1 :green_heart: | shadedclient | 40m 51s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 32s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 0m 39s | | The patch does not generate ASF License warnings. | | | | 237m 33s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8006 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 92090e4cf01b 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / c3c15b84a4086d834b4fd9aa71b8078a2cb57b65 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/testReport/ | | Max. process+thread count | 1449 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/4/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-14T22:23:36.914+0000]: hadoop-yetus commented on PR #8006: URL: https://github.com/apache/hadoop/pull/8006#issuecomment-3403808610 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 21m 13s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 2 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 44m 40s | | trunk passed | | +1 :green_heart: | compile | 17m 35s | | trunk passed | | +1 :green_heart: | checkstyle | 1m 0s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 55s | | trunk passed | | +1 :green_heart: | javadoc | 1m 19s | | trunk passed | | -1 :x: | spotbugs | 1m 36s | [/branch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/branch-spotbugs-hadoop-common-project_hadoop-common.txt) | hadoop-common in trunk failed. | | +1 :green_heart: | shadedclient | 37m 4s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 1m 10s | | the patch passed | | +1 :green_heart: | compile | 16m 48s | | the patch passed | | +1 :green_heart: | javac | 16m 48s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 1s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 52s | | the patch passed | | +1 :green_heart: | javadoc | 1m 17s | | the patch passed | | -1 :x: | spotbugs | 1m 37s | [/patch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/patch-spotbugs-hadoop-common-project_hadoop-common.txt) | hadoop-common in the patch failed. | | +1 :green_heart: | shadedclient | 39m 31s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 47s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 3s | | The patch does not generate ASF License warnings. | | | | 204m 29s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8006 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux d65a60138612 5.15.0-157-generic #167-Ubuntu SMP Wed Sep 17 21:35:53 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 93fbc42bff57ec8dc97f2486fa6ba5ba82e31bdf | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/testReport/ | | Max. process+thread count | 1474 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8006/5/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-16T19:17:10.045+0000]: steveloughran merged PR #8006: URL: https://github.com/apache/hadoop/pull/8006","key":"HADOOP-19712","status":"Resolved","labels":"pull-request-available"}
{"summary":"Upgrade hadoop3 docker scripts to 3.4.2","created":"2025-10-01T08:56:49.000+0000","description":"The Hadoop 3.4.2 version has been released, and we need to update the Hadoop Docker image to version 3.4.2.","assignee":"Shilun Fan","priority":"Major","updated":"2025-10-09T10:05:02.000+0000","commentText":"[ASF GitHub Bot @ 2025-10-01T09:27:42.622+0000]: slfan1989 opened a new pull request, #8005: URL: https://github.com/apache/hadoop/pull/8005 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR ### How was this patch tested? ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-10-01T09:36:46.410+0000]: slfan1989 commented on PR #8005: URL: https://github.com/apache/hadoop/pull/8005#issuecomment-3355515590 @jojochuang @adoroszlai @ayushtkn Hadoop 3.4.2 has been released, and we are preparing a corresponding Docker image for Hadoop 3.4.2. I have created this PR to complete the Docker image release. Could you please review this PR? Thank you very much!\n[ASF GitHub Bot @ 2025-10-01T10:41:48.779+0000]: adoroszlai commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2394132623 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: BTW do you know why the tarball is published without `.gz`? It still seems to be gzipped: ``` $ file hadoop-3.4.2.tar hadoop-3.4.2.tar: gzip compressed data, ... ```\n[ASF GitHub Bot @ 2025-10-02T02:11:48.025+0000]: slfan1989 commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2396443322 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: Thank you very much for helping to review the code! I'm not sure why this package doesn't have the `.gz` @ahmarsuhail Could you please help take a look at this question? Thank you very much!\n[ASF GitHub Bot @ 2025-10-02T02:13:53.491+0000]: slfan1989 commented on PR #8005: URL: https://github.com/apache/hadoop/pull/8005#issuecomment-3358754054 > Thanks @slfan1989 for the patch. > > ``` > $ docker run -it --rm ghcr.io/slfan1989/hadoop:3.4.2 hadoop version > ... > Hadoop 3.4.2 > Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c > Compiled by ahmarsu on 2025-08-20T10:30Z > Compiled on platform linux-x86_64 > Compiled with protoc 3.23.4 > From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6 > This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.4.2.jar > ``` > > After this is merged, I suggest someone from Hadoop PMC upload the same image to Docker Hub, something like: > > ``` > docker pull ghcr.io/apache/hadoop:3.4.2 > docker tag ghcr.io/apache/hadoop:3.4.2 apache/hadoop:3.4.2 > docker push apache/hadoop:3.4.2 > ``` @adoroszlai Thank you very much for the detailed explanation. However, I have never published a Docker image before, and pushing to Docker Hub should require some additional authentication information. @jojochuang @ayushtkn , could you please take a look? Thank you very much!\n[ASF GitHub Bot @ 2025-10-02T10:25:27.373+0000]: ahmarsuhail commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2398213215 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: Hey, sorry I think I made a mistake while uploading the tar to [the staging repo](https://dist.apache.org/repos/dist/dev/hadoop/3.4.2-RC3/), and the it got copied incorrectly to the release directory. can someone from the PMC please update the file name in the release directory? it is gzipped, just missing the `.gz` . My apologies for the miss.\n[ASF GitHub Bot @ 2025-10-03T03:34:28.188+0000]: slfan1989 commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2400690548 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: @ahmarsuhail Thank you for the information\u2014no need to apologize. I\u2019ll try adding the `.gz` extension. Thanks again for your contribution to the hadoop-3.4.2 release.\n[ASF GitHub Bot @ 2025-10-04T09:43:54.256+0000]: slfan1989 commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2403881944 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: I\u2019ve already updated the [dist repo](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/ ), but the dlcdn hasn\u2019t synchronized yet. It may take a few more hours.\n[ASF GitHub Bot @ 2025-10-04T09:46:34.209+0000]: slfan1989 commented on code in PR #8005: URL: https://github.com/apache/hadoop/pull/8005#discussion_r2403881944 ########## Dockerfile: ########## @@ -14,7 +14,7 @@ # limitations under the License. FROM apache/hadoop-runner -ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz +ARG HADOOP_URL=https://dlcdn.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar Review Comment: I\u2019ve already updated the [dist repo](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/ ), but the dlcdn hasn\u2019t synchronized yet. It may take a few more hours. ``` .... [hadoop-3.4.2.tar.gz](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz) [hadoop-3.4.2.tar.gz.asc](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz.asc) [hadoop-3.4.2.tar.gz.sha512](https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz.sha512) .... ```\n[ASF GitHub Bot @ 2025-10-06T00:22:00.422+0000]: slfan1989 merged PR #8005: URL: https://github.com/apache/hadoop/pull/8005\n[ASF GitHub Bot @ 2025-10-06T00:23:24.418+0000]: slfan1989 commented on PR #8005: URL: https://github.com/apache/hadoop/pull/8005#issuecomment-3369556514 @adoroszlai @ahmarsuhail Thank you very much for helping review the code!","key":"HADOOP-19711","status":"Resolved","labels":"pull-request-available"}
{"summary":"ABFS: Read Buffer Manager V2 should not be allowed untill implemented","created":"2025-09-29T08:59:21.000+0000","description":"Read Buffer Manager V2 is a Work in progress and not yet fully ready to be used.\r\nThis is to stop any user explicitly enabling the config to enable RBMV2.","assignee":"Anuj Modi","priority":"Major","updated":"2025-10-07T09:54:40.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-29T09:01:28.444+0000]: anujmodi2021 opened a new pull request, #8002: URL: https://github.com/apache/hadoop/pull/8002 Read Buffer Manager V2 is a Work in progress and not yet fully ready to be used. This is to stop any user explicitly enabling the config to enable RBMV2. JIRA: https://issues.apache.org/jira/browse/HADOOP-19710\n[ASF GitHub Bot @ 2025-09-29T10:32:33.803+0000]: hadoop-yetus commented on PR #8002: URL: https://github.com/apache/hadoop/pull/8002#issuecomment-3346210665 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 9m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 30m 30s | | trunk passed | | +1 :green_heart: | compile | 0m 22s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 22s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 0m 17s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 26s | | trunk passed | | +1 :green_heart: | javadoc | 0m 24s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 20s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 0m 40s | | trunk passed | | +1 :green_heart: | shadedclient | 20m 40s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 17s | | the patch passed | | +1 :green_heart: | compile | 0m 19s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 19s | | the patch passed | | +1 :green_heart: | compile | 0m 16s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 0m 16s | | the patch passed | | +1 :green_heart: | blanks | 0m 1s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 12s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 22s | | the patch passed | | +1 :green_heart: | javadoc | 0m 16s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 18s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 0m 42s | | the patch passed | | +1 :green_heart: | shadedclient | 19m 49s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 2m 20s | | hadoop-azure in the patch passed. | | +1 :green_heart: | asflicense | 0m 25s | | The patch does not generate ASF License warnings. | | | | 90m 2s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8002 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 7ed8c85f9284 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / bc356262478fb82c786dc3bee7c312b2b1a29634 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/testReport/ | | Max. process+thread count | 566 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8002/1/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T09:54:39.930+0000]: anujmodi2021 merged PR #8002: URL: https://github.com/apache/hadoop/pull/8002","key":"HADOOP-19710","status":"Open","labels":"pull-request-available"}
{"summary":"[JDK17] Add debian:12 and debian:13 as a build platform with JDK-17 as default","created":"2025-09-27T04:38:55.000+0000","description":"Add a new Dockerfiles to compile Hadoop on latest Debian:12 and Debian:13 with JDK17 as the default compiler.","assignee":"Vinayakumar B","priority":"Major","updated":"2025-10-21T16:28:27.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-27T04:42:39.625+0000]: vinayakumarb opened a new pull request, #8001: URL: https://github.com/apache/hadoop/pull/8001 This commit introduces support for Debian 12 (Bookworm) and Debian 13 (Trixie) as build platforms, following the approach established for Ubuntu 24. Key changes include: - Creation of `Dockerfile_debian_12` and `Dockerfile_debian_13` based on `Dockerfile_ubuntu_24`, with appropriate base images and package resolver arguments. - Updates to `dev-support/docker/pkg-resolver/packages.json` to include package definitions for `debian:12` and `debian:13`. - Addition of `debian:12` and `debian:13` to `dev-support/docker/pkg-resolver/platforms.json`. - Modification of `BUILDING.txt` to list `debian_12` and `debian_13` as supported OS platforms.\n[ASF GitHub Bot @ 2025-09-27T06:22:34.799+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3341301544 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 23m 38s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | hadolint | 0m 0s | | hadolint was not available. | | +0 :ok: | shellcheck | 0m 0s | | Shellcheck was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 37m 46s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | blanks | 0m 0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/artifact/out/blanks-eol.txt) | The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply | | +1 :green_heart: | shadedclient | 34m 39s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 53s | | The patch does not generate ASF License warnings. | | | | 98m 48s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8001 | | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint | | uname | Linux 01b5b1df2935 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 7ccea846897ea6a8209a2238c06933afb4c489bc | | Max. process+thread count | 554 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/1/console | | versions | git=2.43.7 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-28T01:26:24.689+0000]: pan3793 commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3342170970 Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly?\n[ASF GitHub Bot @ 2025-09-30T01:48:27.552+0000]: slfan1989 commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3349642263 > Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly? @vinayakumarb Thank you very much for your contribution. However, I still have some concerns. Expanding support to many operating systems could be a rather heavy undertaking, since it requires us to pay closer attention to their EOL and version lifecycles. I'm wondering if it might be more sustainable to maintain a smaller subset of supported systems instead. If users have other requirements, they could always try customizing the build themselves. cc: @pan3793 @ayushtkn @cnauroth\n[ASF GitHub Bot @ 2025-10-07T10:59:13.217+0000]: vinayakumarb commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376374939 > > Previously, there were concerns about having many versions of Linux dist Dockerfiles, how about upgrading Debian 10 to 13 directly? > > @vinayakumarb Thank you very much for your contribution. However, I still have some concerns. Expanding support to many operating systems could be a rather heavy undertaking, since it requires us to pay closer attention to their EOL and version lifecycles. I'm wondering if it might be more sustainable to maintain a smaller subset of supported systems instead. If users have other requirements, they could always try customizing the build themselves. > > cc: @pan3793 @ayushtkn @cnauroth I understand the concern. Directly upgrading the debian:10 to debian:13 may break existing pipelines. However, having a Dockerfiles for various platforms provides the developers to build an environment as per their choice. It not necessarily means Hadoop binaries (jars and tar) are compiled in these. if users are interested in building Hadoop in their own choice of environment, these Dockerfiles will be a good starting point.\n[ASF GitHub Bot @ 2025-10-07T11:28:11.135+0000]: slfan1989 commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376469046 @vinayakumarb Thank you for the clarification \u2014 I agree (+1). However, given the complexity of operating system EOL management, I would carefully evaluate the introduction of Docker support for new systems in the future, considering both maintenance costs and long-term sustainability.\n[ASF GitHub Bot @ 2025-10-07T12:40:28.529+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3376715593 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 31m 43s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | hadolint | 0m 0s | | hadolint was not available. | | +0 :ok: | shellcheck | 0m 0s | | Shellcheck was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 1s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 40m 53s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | -1 :x: | blanks | 0m 0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/artifact/out/blanks-eol.txt) | The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply | | +1 :green_heart: | shadedclient | 37m 52s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 59s | | The patch does not generate ASF License warnings. | | | | 113m 29s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8001 | | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint | | uname | Linux 9e7987a7030b 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 92bd7478449829a0e7b987157945cfd72199e4ac | | Max. process+thread count | 647 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/2/console | | versions | git=2.43.7 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-08T03:28:03.011+0000]: pan3793 commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2412409276 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -263,6 +352,14 @@ \"openjdk-11-jdk\", \"openjdk-17-jdk\" ], + \"debian:12\": [ + \"temurin-17-jdk\", + \"temurin-24-jdk\" + ], + \"debian:13\": [ + \"temurin-17-jdk\", + \"temurin-24-jdk\" Review Comment: temurin-25 is out BTW, I think we should prefer to use the JDK provided by official APT repo if possible, Debian 13 already has `openjdk-25-jdk`\n[ASF GitHub Bot @ 2025-10-08T03:28:27.870+0000]: pan3793 commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2412409614 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -353,26 +472,34 @@ }, \"software-properties-common\": { \"debian:11\": \"software-properties-common\", + + Review Comment: ?\n[ASF GitHub Bot @ 2025-10-08T03:44:34.377+0000]: pan3793 commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2412425091 ########## dev-support/docker/Dockerfile_debian_13: ########## @@ -0,0 +1,110 @@ +# Licensed to the Apache Software Foundation (ASF) under one +# or more contributor license agreements. See the NOTICE file +# distributed with this work for additional information +# regarding copyright ownership. The ASF licenses this file +# to you under the Apache License, Version 2.0 (the +# \"License\"); you may not use this file except in compliance +# with the License. You may obtain a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an \"AS IS\" BASIS, +# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. +# See the License for the specific language governing permissions and +# limitations under the License. + +# Dockerfile for installing the necessary dependencies for building Hadoop. +# See BUILDING.txt. + +FROM debian:13 + +WORKDIR /root + +SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"] + +##### +# Disable suggests/recommends +##### +RUN echo 'APT::Install-Recommends \"0\";' > /etc/apt/apt.conf.d/10disableextras +RUN echo 'APT::Install-Suggests \"0\";' >> /etc/apt/apt.conf.d/10disableextras + +ENV DEBIAN_FRONTEND=noninteractive +ENV DEBCONF_TERSE=true + +###### +# Platform package dependency resolver +###### +COPY pkg-resolver pkg-resolver +RUN chmod a+x pkg-resolver/*.sh pkg-resolver/*.py \\ + && chmod a+r pkg-resolver/*.json + +###### +# Install packages from apt +###### +# hadolint ignore=DL3008,SC2046 +RUN apt-get -q update +RUN apt-get -q install -y --no-install-recommends wget apt-transport-https gpg gpg-agent gawk ca-certificates +RUN apt-get -q install -y --no-install-recommends python3 +RUN echo \"deb https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main\" > /etc/apt/sources.list.d/adoptium.list +RUN wget -q -O - https://packages.adoptium.net/artifactory/api/gpg/key/public > /etc/apt/trusted.gpg.d/adoptium.asc +RUN apt-get -q update +RUN apt-get -q install -y --no-install-recommends $(pkg-resolver/resolve.py debian:13) +RUN apt-get clean +RUN update-java-alternatives -s temurin-17-jdk-amd64 +RUN rm -rf /var/lib/apt/lists/* Review Comment: each RUN produces one image layer, you should concat those shell commands by && instead\n[ASF GitHub Bot @ 2025-10-08T03:48:46.924+0000]: pan3793 commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3379465889 @vinayakumarb, in addition to creating a dev container from the Dockerfile, have you verified that Hadoop can build successfully with native and frontend components in the created dev container?\n[ASF GitHub Bot @ 2025-10-11T13:07:53.269+0000]: vinayakumarb commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2422824903 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -263,6 +352,14 @@ \"openjdk-11-jdk\", \"openjdk-17-jdk\" ], + \"debian:12\": [ + \"temurin-17-jdk\", + \"temurin-24-jdk\" + ], + \"debian:13\": [ + \"temurin-17-jdk\", + \"temurin-24-jdk\" Review Comment: Done. Using openjdk-25-jdk in debian-13 and temurin-25-jdk in debian 12 as openjdk is not available in debian repository for bookworm.\n[ASF GitHub Bot @ 2025-10-11T13:08:23.085+0000]: vinayakumarb commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2422825814 ########## dev-support/docker/Dockerfile_debian_13: ########## @@ -0,0 +1,110 @@ +# Licensed to the Apache Software Foundation (ASF) under one +# or more contributor license agreements. See the NOTICE file +# distributed with this work for additional information +# regarding copyright ownership. The ASF licenses this file +# to you under the Apache License, Version 2.0 (the +# \"License\"); you may not use this file except in compliance +# with the License. You may obtain a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an \"AS IS\" BASIS, +# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. +# See the License for the specific language governing permissions and +# limitations under the License. + +# Dockerfile for installing the necessary dependencies for building Hadoop. +# See BUILDING.txt. + +FROM debian:13 + +WORKDIR /root + +SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"] + +##### +# Disable suggests/recommends +##### +RUN echo 'APT::Install-Recommends \"0\";' > /etc/apt/apt.conf.d/10disableextras +RUN echo 'APT::Install-Suggests \"0\";' >> /etc/apt/apt.conf.d/10disableextras + +ENV DEBIAN_FRONTEND=noninteractive +ENV DEBCONF_TERSE=true + +###### +# Platform package dependency resolver +###### +COPY pkg-resolver pkg-resolver +RUN chmod a+x pkg-resolver/*.sh pkg-resolver/*.py \\ + && chmod a+r pkg-resolver/*.json + +###### +# Install packages from apt +###### +# hadolint ignore=DL3008,SC2046 +RUN apt-get -q update +RUN apt-get -q install -y --no-install-recommends wget apt-transport-https gpg gpg-agent gawk ca-certificates +RUN apt-get -q install -y --no-install-recommends python3 +RUN echo \"deb https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main\" > /etc/apt/sources.list.d/adoptium.list +RUN wget -q -O - https://packages.adoptium.net/artifactory/api/gpg/key/public > /etc/apt/trusted.gpg.d/adoptium.asc +RUN apt-get -q update +RUN apt-get -q install -y --no-install-recommends $(pkg-resolver/resolve.py debian:13) +RUN apt-get clean +RUN update-java-alternatives -s temurin-17-jdk-amd64 +RUN rm -rf /var/lib/apt/lists/* Review Comment: Done.\n[ASF GitHub Bot @ 2025-10-11T13:21:27.822+0000]: vinayakumarb commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393325468 > @vinayakumarb, in addition to creating a dev container from the Dockerfile, have you verified that Hadoop can build successfully with native and frontend components in the created dev container? Yes. I have verified building both native and frontend.\n[ASF GitHub Bot @ 2025-10-11T13:23:14.869+0000]: vinayakumarb commented on code in PR #8001: URL: https://github.com/apache/hadoop/pull/8001#discussion_r2422836979 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -353,26 +472,34 @@ }, \"software-properties-common\": { \"debian:11\": \"software-properties-common\", + + Review Comment: Forgot to remove empty lines. `software-properties-common` not available for debian 12 and 13. Also does not look like it was needed.\n[ASF GitHub Bot @ 2025-10-11T14:07:48.325+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393364407 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 13m 33s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | hadolint | 0m 0s | | hadolint was not available. | | +0 :ok: | shellcheck | 0m 0s | | Shellcheck was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 1s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 24m 31s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 21m 24s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 41s | | The patch does not generate ASF License warnings. | | | | 61m 20s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8001 | | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint | | uname | Linux 5a71556ea849 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 | | Max. process+thread count | 559 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console | | versions | git=2.43.7 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-11T14:48:41.044+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393395506 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 11m 43s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 1s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 1s | | Shelldocs was not available. | | +0 :ok: | jsonlint | 0m 1s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 14m 3s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | hadolint | 0m 1s | | No new issues. | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | shadedclient | 13m 26s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 21s | | The patch does not generate ASF License warnings. | | | | 40m 45s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8001 | | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint | | uname | Linux 4e9b089f3372 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 | | Max. process+thread count | 575 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console | | versions | git=2.30.2 maven=3.9.11 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.1 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-11T14:49:36.386+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393395990 (!) A patch to the testing environment has been detected. Re-executing against the patched versions to perform further tests. The console is at https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console in case of problems.\n[ASF GitHub Bot @ 2025-10-11T15:38:02.482+0000]: hadoop-yetus commented on PR #8001: URL: https://github.com/apache/hadoop/pull/8001#issuecomment-3393432943 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 8m 32s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 1s | | Shelldocs was not available. | | +0 :ok: | jsonlint | 0m 1s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 19m 49s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | hadolint | 0m 2s | | No new issues. | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | shadedclient | 19m 24s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 19s | | The patch does not generate ASF License warnings. | | | | 49m 15s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/8001 | | Optional Tests | dupname asflicense codespell detsecrets hadolint shellcheck shelldocs jsonlint | | uname | Linux 167189e0eac1 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / e371f08075c145585c0d620978733fceb30c93b0 | | Max. process+thread count | 568 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8001/3/console | | versions | git=2.25.1 maven=3.9.11 hadolint=1.11.1-0-g0e692dd shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-21T16:28:26.949+0000]: vinayakumarb merged PR #8001: URL: https://github.com/apache/hadoop/pull/8001","key":"HADOOP-19709","status":"Open","labels":"pull-request-available"}
{"summary":"volcano tos: disable shading when -DskipShade is set on a build","created":"2025-09-26T09:30:31.000+0000","description":"hadoop-tos is shaded, includes things like httpclient5, which leads to a big 4M artifact, with unknown content inside\r\n{code}\r\n 92K    share/hadoop/common/lib/hadoop-aliyun-3.5.0-20250916.124028-685.jar\r\n912K    share/hadoop/common/lib/hadoop-aws-3.5.0-20250916.124028-686.jar\r\n808K    share/hadoop/common/lib/hadoop-azure-3.5.0-20250916.124028-685.jar\r\n 36K    share/hadoop/common/lib/hadoop-azure-datalake-3.5.0-20250916.124028-685.jar\r\n 72K    share/hadoop/common/lib/hadoop-cos-3.5.0-20250916.124028-683.jar\r\n136K    share/hadoop/common/lib/hadoop-gcp-3.5.0-SNAPSHOT.jar\r\n140K    share/hadoop/common/lib/hadoop-huaweicloud-3.5.0-SNAPSHOT.jar\r\n3.8M    share/hadoop/common/lib/hadoop-tos-3.5.0-20250916.124028-202.jar\r\n{code}\r\n\r\nOne thing it includes is yet-another mozilla/public-suffix-list.txt. These are a recurrent PITA and I don't want\r\nto find them surfacing again.\r\n{code}\r\n\r\n15. Required Resources\r\n======================\r\n\r\nresource: mozilla/public-suffix-list.txt\r\n       jar:file:/Users/stevel/Projects/Releases/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib/hadoop-tos-3.5.0-20250916.124028-202.jar!/mozilla/public-suffix-list.txt\r\n{code}\r\n\r\nPlan\r\n* Move the shade stage behind a profile; off for ASF releases. Exclude mozilla/public-suffix-list.txt  \r\n* Explicitly declare and manage httpclient5 dependency\r\n* hadoop-cloud-storage pom to include hadoop-tos but not dependencies in build, unless asked.\r\n* LICENSE-binary to declare optional redist of ve-tos-java-sdk-hadoop and its license.\r\n\r\n","assignee":"Steve Loughran","priority":"Major","updated":"2025-10-09T19:59:47.000+0000","commentText":"[Steve Loughran @ 2025-09-26T09:31:45.459+0000]: doing this inside HADOOP-19696, as that's where I need the leaner artifacts\n[Steve Loughran @ 2025-10-08T15:13:05.515+0000]: (note the shading is troubled anyway {code} [INFO] Dependency-reduced POM written at: /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/dependency-reduced-pom.xml [WARNING] httpclient5-5.3.jar, httpcore5-5.2.4.jar, httpcore5-h2-5.2.4.jar define 3 overlapping resources: [WARNING] - META-INF/DEPENDENCIES [WARNING] - META-INF/LICENSE [WARNING] - META-INF/NOTICE [WARNING] hadoop-tos-3.5.0-SNAPSHOT.jar, httpclient5-5.3.jar, httpcore5-5.2.4.jar, httpcore5-h2-5.2.4.jar, nimbus-jose-jwt-10.4.jar, ve-tos-java-sdk-hadoop-2.8.9.jar define 1 overlapping resource: [WARNING] - META-INF/MANIFEST.MF [WARNING] maven-shade-plugin has detected that some files are [WARNING] present in two or more JARs. When this happens, only one [WARNING] single version of the file is copied to the uber jar. [WARNING] Usually this is not harmful and you can skip these warnings, [WARNING] otherwise try to manually exclude artifacts based on [WARNING] mvn dependency:tree -Ddetail=true and the above output. [WARNING] See https://maven.apache.org/plugins/maven-shade-plugin/ [INFO] Replacing original artifact with shaded artifact. [INFO] Replacing /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/target/hadoop-tos-3.5.0-SNAPSHOT.jar with /Users/stevel/Projects/hadoop-trunk/hadoop-cloud-storage-project/hadoop-tos/target/hadoop-tos-3.5.0-SNAPSHOT-shaded.jar [INFO] [INFO] --- cyclonedx:2.9.1:makeBom (default) @ hadoop-tos --- {code}","key":"HADOOP-19708","status":"In Progress","labels":""}
{"summary":"Surefire upgrade leads to increased report output, can cause Jenkins OOM","created":"2025-09-25T23:37:18.000+0000","description":"The Surefire upgrade to 3.3+ added enableOutErrElements which defaults to true and includes system-out and system-err in the xml artifacts. This significantly increases their size: ~45KB to ~1MB in many cases. In my test environment, that leads to\r\n{code}\r\nRecording test results\r\nERROR: Step \u2018Publish JUnit test result report\u2019 aborted due to exception: \r\njava.lang.OutOfMemoryError: Java heap space\r\n{code}\r\n\r\nCapturing stdout seems useful when doing ad-hoc testing or smaller test runs. I'd propose adding a profile to set enableOutErrElements=false for CI environments where that extra output can cause problems.","assignee":"Michael Smith","priority":"Major","updated":"2025-10-02T19:02:11.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-25T23:59:49.919+0000]: MikaelSmith opened a new pull request, #7998: URL: https://github.com/apache/hadoop/pull/7998 ### Description of PR Adds the `quiet-surefire` profile to set enableOutErrElements=false for maven-surefire-plugin. This restores the behavior prior to Surefire 3.3 that stdout/stderr are not included in the TEST-<package>.<class>.xml file for passing tests. The newer default behavior results in much larger TEST-*.xml files that can be a problem for CI tools processing them. ### How was this patch tested? Ran `mvn clean test -Dtest=TestHttpServer` and `mvn clean test -Dtest=TestHttpServer -Pquiet-surefire` and compared size and contents of hadoop-common-project/hadoop-common/target/surefire-reports/TEST-org.apache.hadoop.http.TestHttpServer.xml. ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-26T02:44:51.291+0000]: hadoop-yetus commented on PR #7998: URL: https://github.com/apache/hadoop/pull/7998#issuecomment-3336586704 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 21m 28s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 56m 17s | | trunk passed | | +1 :green_heart: | compile | 0m 22s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 23s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 0m 27s | | trunk passed | | +1 :green_heart: | javadoc | 0m 27s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 23s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 98m 4s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 15s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | compile | 0m 14s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 0m 14s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 0m 17s | | the patch passed | | +1 :green_heart: | javadoc | 0m 15s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 14s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 40m 47s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 17s | | hadoop-project in the patch passed. | | +1 :green_heart: | asflicense | 0m 35s | | The patch does not generate ASF License warnings. | | | | 163m 42s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7998 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 6c02dd609cd9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 895391e2c52eadd071997eacaaf7bb2f2af8be30 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/testReport/ | | Max. process+thread count | 533 (vs. ulimit of 5500) | | modules | C: hadoop-project U: hadoop-project | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7998/1/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-02T19:01:55.191+0000]: steveloughran merged PR #7998: URL: https://github.com/apache/hadoop/pull/7998","key":"HADOOP-19707","status":"Resolved","labels":"pull-request-available"}
{"summary":"Support Java Modularity","created":"2025-09-24T20:03:42.000+0000","description":"This is an umbrella JIRA for supporting Java 9 Modularity.","assignee":"","priority":"Major","updated":"2025-09-24T20:04:21.000+0000","commentText":"","key":"HADOOP-19706","status":"Open","labels":""}
{"summary":"[JDK17] Do not use Long(long) and similar constructors","created":"2025-09-24T19:00:19.000+0000","description":"'Long(long)' is deprecated since version 9 and marked for removal.","assignee":"","priority":"Major","updated":"2025-09-24T19:00:19.000+0000","commentText":"","key":"HADOOP-19705","status":"Open","labels":""}
{"summary":"UserGroupInformation.java is using a non-support operation in JDK25","created":"2025-09-24T13:42:31.000+0000","description":"Hello,\r\n\r\nI'm trying to upgrade my version of ParquetJava and I'm seeing the following error locally\r\n{code:java}\r\nÂ Â Â  java.lang.UnsupportedOperationException: getSubject is not supported\r\n\r\n\r\nÂ Â Â Â Â Â Â  at java.base/javax.security.auth.Subject.getSubject(Subject.java:277)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3852)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3842)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3630)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:290)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:541)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at org.apache.parquet.hadoop.util.HadoopOutputFile.fromPath(HadoopOutputFile.java:58)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at com.amazon.networkvalidator.parquet.ParquetWriter.write(ParquetWriter.kt:75)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at com.amazon.networkvalidator.parquet.ParquetWriterTest$test \r\nwriting to parquet$1.invokeSuspend(ParquetWriterTest.kt:88)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at com.amazon.networkvalidator.parquet.ParquetWriterTest$test writing to parquet$1.invoke(ParquetWriterTest.kt)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at com.amazon.networkvalidator.parquet.ParquetWriterTest$test writing to parquet$1.invoke(ParquetWriterTest.kt)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt$runTest$2$1$1.invokeSuspend(TestBuilders.kt:318)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:101)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestDispatcher.processEvent$kotlinx_coroutines_test(TestDispatcher.kt:24)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at \r\nkotlinx.coroutines.test.TestCoroutineScheduler.tryRunNextTaskUnless$kotlinx_coroutines_test(TestCoroutineScheduler.kt:99)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt$runTest$2$1$workRunner$1.invokeSuspend(TestBuilders.kt:327)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:101)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:263)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.BlockingCoroutine.joinBlocking(Builders.kt:95)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking(Builders.kt:69)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.BuildersKt.runBlocking(Unknown Source)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.BuildersKt__BuildersKt.runBlocking$default(Builders.kt:47)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.BuildersKt.runBlocking$default(Unknown Source)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersJvmKt.createTestResult(TestBuildersJvm.kt:10)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0(TestBuilders.kt:310)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0(Unknown Source)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0(TestBuilders.kt:168)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0(Unknown Source)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt__TestBuildersKt.runTest-8Mi8wO0$default(TestBuilders.kt:160)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at kotlinx.coroutines.test.TestBuildersKt.runTest-8Mi8wO0$default(Unknown Source)\r\n\r\n\r\nÂ Â Â Â Â Â Â  at com.amazon.networkvalidator.parquet.ParquetWriterTest.test writing to parquet(ParquetWriterTest.kt:76)\r\n {code}\r\nThe class making this unsupported call is UserGroupInformation, which is part of the common hadoop pkg - https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common/3.4.2","assignee":"","priority":"Major","updated":"2025-09-24T15:26:11.000+0000","commentText":"[PJ Fanning @ 2025-09-24T13:59:57.267+0000]: Hadoop only supports Java 11. https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions There is work in progress to support Java 17. Java 21 and 25 will be worked on later. HADOOP-19486\n[Hugo Costa @ 2025-09-24T15:26:11.203+0000]: Appreciate the link, thanks PJ, will keep a watch on that :)","key":"HADOOP-19703","status":"Open","labels":""}
{"summary":"Update non-thirdparty Guava version to  33.4.8-jre","created":"2025-09-23T17:28:42.000+0000","description":"Keep in sync with recently upgraded thirdparty Guava","assignee":"Istvan Toth","priority":"Major","updated":"2025-10-03T06:56:03.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-24T04:19:26.810+0000]: stoty opened a new pull request, #7994: URL: https://github.com/apache/hadoop/pull/7994 ### Description of PR Update non-thirdparty Guava version to 33.4.8-jre The motivation is the same as for updating the thirdparty one. ### How was this patch tested? CI ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-24T05:05:59.086+0000]: hadoop-yetus commented on PR #7994: URL: https://github.com/apache/hadoop/pull/7994#issuecomment-3326537486 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 8m 28s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 31m 21s | | trunk passed | | +1 :green_heart: | compile | 0m 13s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 13s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 0m 20s | | trunk passed | | +1 :green_heart: | javadoc | 0m 16s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 14s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 33m 33s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 9s | | the patch passed | | +1 :green_heart: | compile | 0m 9s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 9s | | the patch passed | | +1 :green_heart: | compile | 0m 9s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 0m 9s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 0m 10s | | the patch passed | | +1 :green_heart: | javadoc | 0m 8s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 10s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 1m 22s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 10s | | hadoop-project in the patch passed. | | +1 :green_heart: | asflicense | 0m 19s | | The patch does not generate ASF License warnings. | | | | 45m 32s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7994 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 9c1032fe6d33 5.15.0-153-generic #163-Ubuntu SMP Thu Aug 7 16:37:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / bd6bdde979214be1291cda6a340e8e629a848d7a | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/testReport/ | | Max. process+thread count | 98 (vs. ulimit of 5500) | | modules | C: hadoop-project U: hadoop-project | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7994/1/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-25T06:35:55.498+0000]: slfan1989 commented on PR #7994: URL: https://github.com/apache/hadoop/pull/7994#issuecomment-3332389576 @stoty In my opinion, there is no issue with this PR. I have one question, why not upgrade to 33.5.0-jre?\n[ASF GitHub Bot @ 2025-09-25T07:27:29.617+0000]: stoty commented on PR #7994: URL: https://github.com/apache/hadoop/pull/7994#issuecomment-3332540273 > @stoty In my opinion, there is no issue with this PR. I have one question, why not upgrade to 33.5.0-jre? The hadoop-thirdparty guava is being updated to 33.4.8-jre, and I thought that it's easier to manage if we keep the unshaded version in sync with that, as long as we're able to. Also, we've already updated to 33.4.8-jre at my day job without issues, but I don't have experience yet with 33.5.0.\n[ASF GitHub Bot @ 2025-09-30T01:49:59.989+0000]: slfan1989 commented on PR #7994: URL: https://github.com/apache/hadoop/pull/7994#issuecomment-3349644523 If there are no further comments, I will merge this PR today.\n[ASF GitHub Bot @ 2025-10-03T06:54:43.146+0000]: slfan1989 merged PR #7994: URL: https://github.com/apache/hadoop/pull/7994\n[ASF GitHub Bot @ 2025-10-03T06:55:02.753+0000]: slfan1989 commented on PR #7994: URL: https://github.com/apache/hadoop/pull/7994#issuecomment-3364494335 @stoty Thanks for the contribution! Merged into trunk.","key":"HADOOP-19702","status":"Resolved","labels":"pull-request-available"}
{"summary":"Remove invalid `licenses` field of `hadoop-aliyun` SBOM by upgradding `cyclonedx` to 2.9.1","created":"2025-09-23T04:55:31.000+0000","description":"","assignee":"Dongjoon Hyun","priority":"Major","updated":"2025-09-24T04:18:44.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-23T04:59:12.692+0000]: dongjoon-hyun opened a new pull request, #7990: URL: https://github.com/apache/hadoop/pull/7990 \u2026 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR ### How was this patch tested? ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-23T05:47:00.951+0000]: dongjoon-hyun commented on PR #7990: URL: https://github.com/apache/hadoop/pull/7990#issuecomment-3322518878 Thank you, @slfan1989 .\n[ASF GitHub Bot @ 2025-09-23T19:41:31.354+0000]: hadoop-yetus commented on PR #7990: URL: https://github.com/apache/hadoop/pull/7990#issuecomment-3325310193 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 60m 11s | | trunk passed | | +1 :green_heart: | compile | 20m 20s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 16m 2s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 23m 22s | | trunk passed | | +1 :green_heart: | javadoc | 11m 38s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 9m 20s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 185m 36s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 49m 43s | | the patch passed | | +1 :green_heart: | compile | 21m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 21m 13s | | the patch passed | | +1 :green_heart: | compile | 18m 49s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 18m 49s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 21m 50s | | the patch passed | | +1 :green_heart: | javadoc | 11m 53s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 9m 0s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 88m 52s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 511m 54s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 1m 18s | | The patch does not generate ASF License warnings. | | | | 880m 54s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7990 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 3a691ff72698 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / f944112d4216160cc394f6ea7bd013f7b92796a9 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/testReport/ | | Max. process+thread count | 2369 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7990/1/console | | versions | git=2.25.1 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-23T19:46:29.998+0000]: dongjoon-hyun commented on PR #7990: URL: https://github.com/apache/hadoop/pull/7990#issuecomment-3325322984 All tests passes except `test4tests` and `unit` tests which checks new or revised test cases. So, I believe this PR is ready.\n[ASF GitHub Bot @ 2025-09-24T01:16:26.495+0000]: slfan1989 merged PR #7990: URL: https://github.com/apache/hadoop/pull/7990\n[ASF GitHub Bot @ 2025-09-24T01:16:50.249+0000]: slfan1989 commented on PR #7990: URL: https://github.com/apache/hadoop/pull/7990#issuecomment-3326078332 @dongjoon-hyun Thanks for the contribution! Merged into trunk.\n[ASF GitHub Bot @ 2025-09-24T04:18:43.614+0000]: dongjoon-hyun commented on PR #7990: URL: https://github.com/apache/hadoop/pull/7990#issuecomment-3326405610 Thank you so much, @slfan1989 .","key":"HADOOP-19701","status":"Resolved","labels":"pull-request-available"}
{"summary":"hadoop-thirdparty build to update maven plugin dependencies","created":"2025-09-22T13:05:13.000+0000","description":"github action builds of PRs for hadoopHthirdparty fail because of throttling NVE throttling of requests; needs an update to a later version with either retries or use of a github source cve list.\r\n\r\ndependency checker 11+ \r\n\r\n{code}\r\nMandatory Upgrade Notice\r\nUpgrading to 10.0.2 or later is mandatory\r\n\r\nOlder versions of dependency-check are causing numerous, duplicative requests that end in processing failures are causing unnecassary load on the NVD API. Dependency-check 10.0.2 uses an updated User-Agent header that will allow the NVD to block calls from the older client.\r\n{code}\r\n\r\n----\r\n\r\nThe upgraded dependency checker now *requires* java11+, and *prefers* the provision of an API key for the national vulnerabilities database. It also skips the sonatype check as that no longer supports anonymous checks at all\r\n","assignee":"Steve Loughran","priority":"Major","updated":"2025-09-30T10:02:32.000+0000","commentText":"[Istvan Toth @ 2025-09-23T04:51:05.531+0000]: 10.x cannot parse the current DB files, even if it manages to download them, [~stevel@apache.org].\n[Steve Loughran @ 2025-09-23T18:46:36.540+0000]: latest pr does it, just needs java11 for that action. And I've turned off the sonatype checking","key":"HADOOP-19700","status":"Resolved","labels":"pull-request-available"}
{"summary":"S3A Analytics-Accelerator: Update LICENSE-binary","created":"2025-09-18T10:46:22.000+0000","description":"update LICENSE-binary to include AAL dependencyÂ ","assignee":"Ahmar Suhail","priority":"Major","updated":"2025-09-18T13:23:56.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-18T10:51:11.792+0000]: ahmarsuhail opened a new pull request, #7982: URL: https://github.com/apache/hadoop/pull/7982 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR Adds in AAL dependency to License-binary. ### How was this patch tested? not required. ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-18T10:51:30.843+0000]: ahmarsuhail commented on PR #7982: URL: https://github.com/apache/hadoop/pull/7982#issuecomment-3306787342 @steveloughran PR to add in license binary.\n[ASF GitHub Bot @ 2025-09-18T12:22:45.440+0000]: hadoop-yetus commented on PR #7982: URL: https://github.com/apache/hadoop/pull/7982#issuecomment-3307163564 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | shadedclient | 46m 8s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | shadedclient | 40m 42s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 40s | | The patch does not generate ASF License warnings. | | | | 90m 19s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7982/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7982 | | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs | | uname | Linux 8e1ed683c4d3 5.15.0-151-generic #161-Ubuntu SMP Tue Jul 22 14:25:40 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / bf18e340d1dc826e0c031dc1e88e59a58fcb59d7 | | Max. process+thread count | 530 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7982/1/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-18T13:23:28.873+0000]: steveloughran merged PR #7982: URL: https://github.com/apache/hadoop/pull/7982","key":"HADOOP-19698","status":"Resolved","labels":"pull-request-available"}
{"summary":"google gs connector registration failing","created":"2025-09-17T14:04:27.000+0000","description":"Surfaced during HADOOP-19696 and work with all the cloud connectors on the classpath.\r\n\r\nThere's a missing dependency causing the gcs connector to fail to register *when the first filesystem is instantiated*, because the service registration process loads the gcs connector class, instantiates one and asks for its schema.\r\n\r\nAs well as a sign of a problem, it's better to just add an entry in core-default.xml as this saves all classloading overhead. It's what the other asf bundled ones do.","assignee":"","priority":"Blocker","updated":"2025-10-08T04:44:25.000+0000","commentText":"[Steve Loughran @ 2025-09-17T14:06:18.904+0000]: Trying to list local root If there are dependencies needed in the HADOOP-19696 let's make sure they get into common/lib, but this registration process mustn't fail this way, so let's just have a fs.gs.impl declararation in core-default.xml {code} bin/hadoop fs -ls file:/// 2025-09-17 15:03:47,688 [main] WARN fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.gs.GoogleHadoopFileSystem Unable to get public no-arg constructor at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586) at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679) at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240) at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273) at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309) at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393) at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3522) at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3612) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3716) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3667) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557) at org.apache.hadoop.fs.Path.getFileSystem(Path.java:373) at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:347) at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:265) at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:248) at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:105) at org.apache.hadoop.fs.shell.Command.run(Command.java:192) at org.apache.hadoop.fs.FsShell.run(FsShell.java:327) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97) at org.apache.hadoop.fs.FsShell.main(FsShell.java:390) Caused by: java.lang.NoClassDefFoundError: com/google/auth/Credentials at java.base/java.lang.Class.getDeclaredConstructors0(Native Method) at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373) at java.base/java.lang.Class.getConstructor0(Class.java:3578) at java.base/java.lang.Class.getConstructor(Class.java:2271) at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666) at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663) at java.base/java.security.AccessController.doPrivileged(AccessController.java:569) at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674) ... 20 more Caused by: java.lang.ClassNotFoundException: com.google.auth.Credentials at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525) ... 28 more Found 20 items ---------- 1 root admin 0 2025-08-16 19:44 file:///.file ... {code}\n[Chris Nauroth @ 2025-10-08T04:44:25.761+0000]: Hi [~stevel@apache.org]. Not fully caught up on this one, but there is a {{fs.gs.impl}} entry in core-default.xml now. Was that all we needed? https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml#L4508","key":"HADOOP-19697","status":"Open","labels":""}
{"summary":"hadoop binary distribution to move cloud connectors to hadoop common/lib","created":"2025-09-17T13:36:12.000+0000","description":"Place all the cloud connector hadoop-* artifacts and dependencies into hadoop/common/lib so that the stores can be directly accessed.\r\n\r\n* filesystem operations against abfs, s3a, gcs, etc don't need any effort setting things up. \r\n* Releases without the aws bundle.jar can be trivially updated by adding any version of the sdk libraries to the common/lib dir. \r\n\r\nThis adds a lot more stuff into the distribution, so I'm doing the following design\r\n* all hadoop-* modules in common/lib\r\n* minimal dependencies for hadoop-azure and hadoop-gcs (once we get those right!)\r\n* hadoop-aws: everything except bundle.jar\r\n* other connectors: only included with explicit profiles.\r\n\r\nASF releases will support azure out the box, the others once you add the dependencies. And anyone can build their own release with everything\r\n\r\nOne concern here, we make hadoop-cloud-storage artifact incomplete at pulling in things when depended on. We may need a separate module for the distro setup.\r\n\r\nNoticed during this that the hadoop-tos component is shaded and includes stuff (httpclient5) that we need under control. Filed HADOOP-19708 and incorporating here. \r\n\r\n\r\n","assignee":"Steve Loughran","priority":"Major","updated":"2025-10-21T22:22:37.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-17T13:51:39.228+0000]: steveloughran opened a new pull request, #7980: URL: https://github.com/apache/hadoop/pull/7980 * new assembly for hadoop cloud storage * hadoop-cloud-storage does the assembly on -Pdist * layout stitching to move into share/hadoop/common/lib * remove connectors from hadoop-tools-dist * cut old jackson version from huawaei cloud dependency -even though it was being upgraded by our own artifacts, it was a complication. ### How was this patch tested? Manual build, review, storediag, hadoop fs commands ### For code changes: - [=] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-17T13:56:19.944+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303127263 * This puts the hadoop-azure, hadoop-aws &c binaries into common/lib and so on the classpath everywhere * some problem with gcs instantiation during enum (will file later, as while it surfaces here, I think it's unrelated) * my local builds end up (today) with some versioned jars as well as the -SNAPSHOT. I think this is from me tainting my maven repo, would like to see what others see ``` total 1401704 -rw-r--r--@ 1 stevel staff 106151 Sep 17 12:57 aliyun-java-core-0.2.11-beta.jar -rw-r--r--@ 1 stevel staff 194215 Sep 17 12:57 aliyun-java-sdk-core-4.5.10.jar -rw-r--r--@ 1 stevel staff 163698 Sep 17 12:57 aliyun-java-sdk-kms-2.11.0.jar -rw-r--r--@ 1 stevel staff 220800 Sep 17 12:57 aliyun-java-sdk-ram-3.1.0.jar -rw-r--r--@ 1 stevel staff 928456 Sep 17 12:57 aliyun-sdk-oss-3.18.1.jar -rw-r--r--@ 1 stevel staff 2470776 Sep 17 12:57 analyticsaccelerator-s3-1.3.0.jar -rw-r--r--@ 1 stevel staff 27006 Sep 17 13:11 aopalliance-repackaged-2.6.1.jar -rw-r--r--@ 1 stevel staff 20891 Sep 17 13:11 audience-annotations-0.12.0.jar -rw-r--r--@ 1 stevel staff 651391 Sep 17 13:11 avro-1.11.4.jar -rw-r--r--@ 1 stevel staff 113966 Sep 17 12:57 azure-data-lake-store-sdk-2.3.9.jar -rw-r--r--@ 1 stevel staff 10288 Sep 17 12:57 azure-keyvault-core-1.0.0.jar -rw-r--r--@ 1 stevel staff 815331 Sep 17 12:57 azure-storage-7.0.1.jar -rw-r--r--@ 1 stevel staff 8324412 Sep 17 13:11 bcprov-jdk18on-1.78.1.jar -rw-r--r--@ 1 stevel staff 641534749 Sep 17 12:57 bundle-2.29.52.jar -rw-r--r--@ 1 stevel staff 223979 Sep 17 13:11 checker-qual-3.33.0.jar -rw-r--r--@ 1 stevel staff 75479 Sep 17 13:11 commons-cli-1.9.0.jar -rw-r--r--@ 1 stevel staff 353793 Sep 17 13:11 commons-codec-1.15.jar -rw-r--r--@ 1 stevel staff 751914 Sep 17 13:11 commons-collections4-4.4.jar -rw-r--r--@ 1 stevel staff 1079377 Sep 17 13:11 commons-compress-1.26.1.jar -rw-r--r--@ 1 stevel staff 657516 Sep 17 13:11 commons-configuration2-2.10.1.jar -rw-r--r--@ 1 stevel staff 24239 Sep 17 13:11 commons-daemon-1.0.13.jar -rw-r--r--@ 1 stevel staff 508826 Sep 17 13:11 commons-io-2.16.1.jar -rw-r--r--@ 1 stevel staff 673587 Sep 17 13:11 commons-lang3-3.17.0.jar -rw-r--r--@ 1 stevel staff 70816 Sep 17 13:11 commons-logging-1.3.0.jar -rw-r--r--@ 1 stevel staff 2213560 Sep 17 13:11 commons-math3-3.6.1.jar -rw-r--r--@ 1 stevel staff 316431 Sep 17 13:11 commons-net-3.9.0.jar -rw-r--r--@ 1 stevel staff 238400 Sep 17 13:11 commons-text-1.10.0.jar -rw-r--r--@ 1 stevel staff 8661164 Sep 17 12:57 cos_api-bundle-5.6.19.jar -rw-r--r--@ 1 stevel staff 2983237 Sep 17 13:11 curator-client-5.2.0.jar -rw-r--r--@ 1 stevel staff 336384 Sep 17 13:11 curator-framework-5.2.0.jar -rw-r--r--@ 1 stevel staff 315569 Sep 17 13:11 curator-recipes-5.2.0.jar -rw-r--r--@ 1 stevel staff 583996 Sep 17 13:11 dnsjava-3.6.1.jar -rw-r--r--@ 1 stevel staff 324655 Sep 17 12:57 dom4j-2.1.4.jar -rw-r--r--@ 1 stevel staff 670059 Sep 17 12:57 esdk-obs-java-3.20.4.2.jar -rw-r--r--@ 1 stevel staff 4617 Sep 17 13:11 failureaccess-1.0.1.jar -rw-r--r--@ 1 stevel staff 249277 Sep 17 13:11 gson-2.9.0.jar -rw-r--r--@ 1 stevel staff 3037368 Sep 17 13:11 guava-32.0.1-jre.jar -rw-r--r--@ 1 stevel staff 94013 Sep 17 12:57 hadoop-aliyun-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 14456 Sep 17 13:11 hadoop-annotations-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 114335 Sep 17 13:11 hadoop-auth-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 930516 Sep 17 12:57 hadoop-aws-3.5.0-20250916.124028-686.jar -rw-r--r--@ 1 stevel staff 827349 Sep 17 12:57 hadoop-azure-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 33363 Sep 17 12:57 hadoop-azure-datalake-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 70007 Sep 17 12:57 hadoop-cos-3.5.0-20250916.124028-683.jar -rw-r--r--@ 1 stevel staff 138447 Sep 17 12:57 hadoop-gcp-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 142274 Sep 17 12:57 hadoop-huaweicloud-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 3519516 Sep 17 13:11 hadoop-shaded-guava-1.4.0.jar -rw-r--r--@ 1 stevel staff 1952967 Sep 17 13:11 hadoop-shaded-protobuf_3_25-1.4.0.jar -rw-r--r--@ 1 stevel staff 4019589 Sep 17 12:57 hadoop-tos-3.5.0-20250916.124028-202.jar -rw-r--r--@ 1 stevel staff 200223 Sep 17 13:11 hk2-api-2.6.1.jar -rw-r--r--@ 1 stevel staff 203358 Sep 17 13:11 hk2-locator-2.6.1.jar -rw-r--r--@ 1 stevel staff 131590 Sep 17 13:11 hk2-utils-2.6.1.jar -rw-r--r--@ 1 stevel staff 780321 Sep 17 13:11 httpclient-4.5.13.jar -rw-r--r--@ 1 stevel staff 328593 Sep 17 13:11 httpcore-4.4.13.jar -rw-r--r--@ 1 stevel staff 102220 Sep 17 12:57 ini4j-0.5.4.jar -rw-r--r--@ 1 stevel staff 29807 Sep 17 13:11 istack-commons-runtime-3.0.12.jar -rw-r--r--@ 1 stevel staff 9301 Sep 17 13:11 j2objc-annotations-2.8.jar -rw-r--r--@ 1 stevel staff 76636 Sep 17 13:11 jackson-annotations-2.14.3.jar -rw-r--r--@ 1 stevel staff 473081 Sep 17 13:11 jackson-core-2.14.3.jar -rw-r--r--@ 1 stevel staff 1617187 Sep 17 13:11 jackson-databind-2.14.3.jar -rw-r--r--@ 1 stevel staff 68453 Sep 17 13:11 jakarta.activation-1.2.2.jar -rw-r--r--@ 1 stevel staff 44399 Sep 17 13:11 jakarta.activation-api-1.2.1.jar -rw-r--r--@ 1 stevel staff 25058 Sep 17 13:11 jakarta.annotation-api-1.3.5.jar -rw-r--r--@ 1 stevel staff 18140 Sep 17 13:11 jakarta.inject-2.6.1.jar -rw-r--r--@ 1 stevel staff 82973 Sep 17 13:11 jakarta.servlet-api-4.0.4.jar -rw-r--r--@ 1 stevel staff 53683 Sep 17 13:11 jakarta.servlet.jsp-api-2.3.6.jar -rw-r--r--@ 1 stevel staff 91930 Sep 17 13:11 jakarta.validation-api-2.0.2.jar -rw-r--r--@ 1 stevel staff 140376 Sep 17 13:11 jakarta.ws.rs-api-2.1.6.jar -rw-r--r--@ 1 stevel staff 115638 Sep 17 13:11 jakarta.xml.bind-api-2.3.3.jar -rw-r--r--@ 1 stevel staff 7771 Sep 17 12:57 java-trace-api-0.2.11-beta.jar -rw-r--r--@ 1 stevel staff 18432 Sep 17 12:57 java-xmlbuilder-1.2.jar -rw-r--r--@ 1 stevel staff 794714 Sep 17 13:11 javassist-3.30.2-GA.jar -rw-r--r--@ 1 stevel staff 95806 Sep 17 13:11 javax.servlet-api-3.1.0.jar -rw-r--r--@ 1 stevel staff 1019097 Sep 17 13:11 jaxb-runtime-2.3.9.jar -rw-r--r--@ 1 stevel staff 4722 Sep 17 13:11 jcip-annotations-1.0-1.jar -rw-r--r--@ 1 stevel staff 327806 Sep 17 12:57 jdom2-2.0.6.1.jar -rw-r--r--@ 1 stevel staff 311826 Sep 17 13:11 jersey-client-2.46.jar -rw-r--r--@ 1 stevel staff 1267957 Sep 17 13:11 jersey-common-2.46.jar -rw-r--r--@ 1 stevel staff 32929 Sep 17 13:11 jersey-container-servlet-2.46.jar -rw-r--r--@ 1 stevel staff 75742 Sep 17 13:11 jersey-container-servlet-core-2.46.jar -rw-r--r--@ 1 stevel staff 80272 Sep 17 13:11 jersey-hk2-2.46.jar -rw-r--r--@ 1 stevel staff 964550 Sep 17 13:11 jersey-server-2.46.jar -rw-r--r--@ 1 stevel staff 90184 Sep 17 12:57 jettison-1.5.4.jar -rw-r--r--@ 1 stevel staff 249911 Sep 17 13:11 jetty-http-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 183011 Sep 17 13:11 jetty-io-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 118496 Sep 17 13:11 jetty-security-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 739348 Sep 17 13:11 jetty-server-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 146064 Sep 17 13:11 jetty-servlet-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 588962 Sep 17 13:11 jetty-util-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 66643 Sep 17 13:11 jetty-util-ajax-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 140308 Sep 17 13:11 jetty-webapp-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 68894 Sep 17 13:11 jetty-xml-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 282591 Sep 17 13:11 jsch-0.1.55.jar -rw-r--r--@ 1 stevel staff 19936 Sep 17 13:11 jsr305-3.0.2.jar -rw-r--r--@ 1 stevel staff 4519 Sep 17 13:11 jul-to-slf4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 223129 Sep 17 13:11 kerb-core-2.0.3.jar -rw-r--r--@ 1 stevel staff 115065 Sep 17 13:11 kerb-crypto-2.0.3.jar -rw-r--r--@ 1 stevel staff 36361 Sep 17 13:11 kerb-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 100095 Sep 17 13:11 kerby-asn1-2.0.3.jar -rw-r--r--@ 1 stevel staff 30190 Sep 17 13:11 kerby-config-2.0.3.jar -rw-r--r--@ 1 stevel staff 200581 Sep 17 13:11 kerby-pkix-2.0.3.jar -rw-r--r--@ 1 stevel staff 40787 Sep 17 13:11 kerby-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 2199 Sep 17 13:11 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar -rw-r--r--@ 1 stevel staff 136314 Sep 17 13:11 metrics-core-3.2.4.jar -rw-r--r--@ 1 stevel staff 4554 Sep 17 13:11 netty-all-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 339045 Sep 17 13:11 netty-buffer-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 355199 Sep 17 13:11 netty-codec-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 67192 Sep 17 13:11 netty-codec-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37789 Sep 17 13:11 netty-codec-haproxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 674362 Sep 17 13:11 netty-codec-http-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 490985 Sep 17 13:11 netty-codec-http2-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 44736 Sep 17 13:11 netty-codec-memcache-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 113699 Sep 17 13:11 netty-codec-mqtt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 46015 Sep 17 13:11 netty-codec-redis-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 21344 Sep 17 13:11 netty-codec-smtp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 121032 Sep 17 13:11 netty-codec-socks-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 34636 Sep 17 13:11 netty-codec-stomp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19823 Sep 17 13:11 netty-codec-xml-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 719225 Sep 17 13:11 netty-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 580162 Sep 17 13:11 netty-handler-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25650 Sep 17 13:11 netty-handler-proxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 26833 Sep 17 13:11 netty-handler-ssl-ocsp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37842 Sep 17 13:11 netty-resolver-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 188360 Sep 17 13:11 netty-resolver-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 9145 Sep 17 13:11 netty-resolver-dns-classes-macos-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19825 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 19629 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 521428 Sep 17 13:11 netty-transport-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 147621 Sep 17 13:11 netty-transport-classes-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 108558 Sep 17 13:11 netty-transport-classes-kqueue-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 42321 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar -rw-r--r--@ 1 stevel staff 36594 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar -rw-r--r--@ 1 stevel staff 40644 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar -rw-r--r--@ 1 stevel staff 6193 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25741 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 25170 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 44157 Sep 17 13:11 netty-transport-native-unix-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 18241 Sep 17 13:11 netty-transport-rxtx-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 50814 Sep 17 13:11 netty-transport-sctp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 32189 Sep 17 13:11 netty-transport-udt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 779369 Sep 17 13:11 nimbus-jose-jwt-9.37.2.jar -rw-r--r--@ 1 stevel staff 425763 Sep 17 12:57 okhttp-3.14.2.jar -rw-r--r--@ 1 stevel staff 91980 Sep 17 12:57 okio-1.17.2.jar -rw-r--r--@ 1 stevel staff 141734 Sep 17 12:57 opentelemetry-api-1.38.0.jar -rw-r--r--@ 1 stevel staff 47252 Sep 17 12:57 opentelemetry-context-1.38.0.jar -rw-r--r--@ 1 stevel staff 18189 Sep 17 12:57 opentracing-api-0.33.0.jar -rw-r--r--@ 1 stevel staff 10542 Sep 17 12:57 opentracing-noop-0.33.0.jar -rw-r--r--@ 1 stevel staff 7504 Sep 17 12:57 opentracing-util-0.33.0.jar -rw-r--r--@ 1 stevel staff 281989 Sep 17 12:57 org.jacoco.agent-0.8.5-runtime.jar -rw-r--r--@ 1 stevel staff 19479 Sep 17 13:11 osgi-resource-locator-1.0.3.jar -rw-r--r--@ 1 stevel staff 128414 Sep 17 13:11 re2j-1.1.jar -rw-r--r--@ 1 stevel staff 11369 Sep 17 12:57 reactive-streams-1.0.3.jar -rw-r--r--@ 1 stevel staff 332398 Sep 17 13:11 reload4j-1.2.22.jar -rw-r--r--@ 1 stevel staff 41125 Sep 17 13:11 slf4j-api-1.7.36.jar -rw-r--r--@ 1 stevel staff 9824 Sep 17 13:11 slf4j-reload4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 2112099 Sep 17 13:11 snappy-java-1.1.10.4.jar -rw-r--r--@ 1 stevel staff 195909 Sep 17 13:11 stax2-api-4.2.1.jar -rw-r--r--@ 1 stevel staff 72007 Sep 17 13:11 txw2-2.3.9.jar -rw-r--r--@ 1 stevel staff 443788 Sep 17 12:57 wildfly-openssl-2.1.4.Final.jar -rw-r--r--@ 1 stevel staff 522679 Sep 17 13:11 woodstox-core-5.4.0.jar -rw-r--r--@ 1 stevel staff 1323991 Sep 17 13:11 zookeeper-3.8.4.jar -rw-r--r--@ 1 stevel staff 254932 Sep 17 13:11 zookeeper-jute-3.8.4.jar ```\n[ASF GitHub Bot @ 2025-09-17T13:57:33.303+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303133677 for contrast, here's 3.4.2 ``` ../hadoop-3.4.2/: total 272 drwxr-xr-x@ 13 stevel staff 416 Aug 7 12:58 bin -rw-r--r--@ 1 stevel staff 824 Aug 27 16:58 binding.xml drwxr-xr-x@ 3 stevel staff 96 Aug 25 17:09 downloads drwxr-xr-x@ 3 stevel staff 96 Aug 7 12:16 etc drwxr-xr-x@ 7 stevel staff 224 Aug 7 12:58 include drwxr-xr-x@ 3 stevel staff 96 Aug 7 12:58 lib drwxr-xr-x@ 14 stevel staff 448 Aug 7 12:58 libexec -rw-r--r--@ 1 stevel staff 23682 Aug 7 10:40 LICENSE-binary -rw-r--r--@ 1 stevel staff 15791 Aug 7 10:39 LICENSE.txt drwxr-xr-x@ 45 stevel staff 1440 Aug 7 12:58 licenses-binary -rw-r--r--@ 1 stevel staff 45514 Aug 27 17:12 log.txt -rw-r--r--@ 1 stevel staff 27373 Aug 7 10:39 NOTICE-binary -rw-r--r--@ 1 stevel staff 1541 Aug 7 10:39 NOTICE.txt -rw-r--r--@ 1 stevel staff 175 Aug 7 10:39 README.txt drwxr-xr-x@ 29 stevel staff 928 Aug 7 12:16 sbin -rw-r--r--@ 1 stevel staff 438 Aug 25 16:59 secrets.bin drwxr-xr-x@ 4 stevel staff 128 Aug 7 13:23 share -rw-r--r--@ 1 stevel staff 275 Aug 27 17:12 system.properties share/hadoop/common/lib: total 1401704 -rw-r--r--@ 1 stevel staff 106151 Sep 17 12:57 aliyun-java-core-0.2.11-beta.jar -rw-r--r--@ 1 stevel staff 194215 Sep 17 12:57 aliyun-java-sdk-core-4.5.10.jar -rw-r--r--@ 1 stevel staff 163698 Sep 17 12:57 aliyun-java-sdk-kms-2.11.0.jar -rw-r--r--@ 1 stevel staff 220800 Sep 17 12:57 aliyun-java-sdk-ram-3.1.0.jar -rw-r--r--@ 1 stevel staff 928456 Sep 17 12:57 aliyun-sdk-oss-3.18.1.jar -rw-r--r--@ 1 stevel staff 2470776 Sep 17 12:57 analyticsaccelerator-s3-1.3.0.jar -rw-r--r--@ 1 stevel staff 27006 Sep 17 13:11 aopalliance-repackaged-2.6.1.jar -rw-r--r--@ 1 stevel staff 20891 Sep 17 13:11 audience-annotations-0.12.0.jar -rw-r--r--@ 1 stevel staff 651391 Sep 17 13:11 avro-1.11.4.jar -rw-r--r--@ 1 stevel staff 113966 Sep 17 12:57 azure-data-lake-store-sdk-2.3.9.jar -rw-r--r--@ 1 stevel staff 10288 Sep 17 12:57 azure-keyvault-core-1.0.0.jar -rw-r--r--@ 1 stevel staff 815331 Sep 17 12:57 azure-storage-7.0.1.jar -rw-r--r--@ 1 stevel staff 8324412 Sep 17 13:11 bcprov-jdk18on-1.78.1.jar -rw-r--r--@ 1 stevel staff 641534749 Sep 17 12:57 bundle-2.29.52.jar -rw-r--r--@ 1 stevel staff 223979 Sep 17 13:11 checker-qual-3.33.0.jar -rw-r--r--@ 1 stevel staff 75479 Sep 17 13:11 commons-cli-1.9.0.jar -rw-r--r--@ 1 stevel staff 353793 Sep 17 13:11 commons-codec-1.15.jar -rw-r--r--@ 1 stevel staff 751914 Sep 17 13:11 commons-collections4-4.4.jar -rw-r--r--@ 1 stevel staff 1079377 Sep 17 13:11 commons-compress-1.26.1.jar -rw-r--r--@ 1 stevel staff 657516 Sep 17 13:11 commons-configuration2-2.10.1.jar -rw-r--r--@ 1 stevel staff 24239 Sep 17 13:11 commons-daemon-1.0.13.jar -rw-r--r--@ 1 stevel staff 508826 Sep 17 13:11 commons-io-2.16.1.jar -rw-r--r--@ 1 stevel staff 673587 Sep 17 13:11 commons-lang3-3.17.0.jar -rw-r--r--@ 1 stevel staff 70816 Sep 17 13:11 commons-logging-1.3.0.jar -rw-r--r--@ 1 stevel staff 2213560 Sep 17 13:11 commons-math3-3.6.1.jar -rw-r--r--@ 1 stevel staff 316431 Sep 17 13:11 commons-net-3.9.0.jar -rw-r--r--@ 1 stevel staff 238400 Sep 17 13:11 commons-text-1.10.0.jar -rw-r--r--@ 1 stevel staff 8661164 Sep 17 12:57 cos_api-bundle-5.6.19.jar -rw-r--r--@ 1 stevel staff 2983237 Sep 17 13:11 curator-client-5.2.0.jar -rw-r--r--@ 1 stevel staff 336384 Sep 17 13:11 curator-framework-5.2.0.jar -rw-r--r--@ 1 stevel staff 315569 Sep 17 13:11 curator-recipes-5.2.0.jar -rw-r--r--@ 1 stevel staff 583996 Sep 17 13:11 dnsjava-3.6.1.jar -rw-r--r--@ 1 stevel staff 324655 Sep 17 12:57 dom4j-2.1.4.jar -rw-r--r--@ 1 stevel staff 670059 Sep 17 12:57 esdk-obs-java-3.20.4.2.jar -rw-r--r--@ 1 stevel staff 4617 Sep 17 13:11 failureaccess-1.0.1.jar -rw-r--r--@ 1 stevel staff 249277 Sep 17 13:11 gson-2.9.0.jar -rw-r--r--@ 1 stevel staff 3037368 Sep 17 13:11 guava-32.0.1-jre.jar -rw-r--r--@ 1 stevel staff 94013 Sep 17 12:57 hadoop-aliyun-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 14456 Sep 17 13:11 hadoop-annotations-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 114335 Sep 17 13:11 hadoop-auth-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 930516 Sep 17 12:57 hadoop-aws-3.5.0-20250916.124028-686.jar -rw-r--r--@ 1 stevel staff 827349 Sep 17 12:57 hadoop-azure-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 33363 Sep 17 12:57 hadoop-azure-datalake-3.5.0-20250916.124028-685.jar -rw-r--r--@ 1 stevel staff 70007 Sep 17 12:57 hadoop-cos-3.5.0-20250916.124028-683.jar -rw-r--r--@ 1 stevel staff 138447 Sep 17 12:57 hadoop-gcp-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 142274 Sep 17 12:57 hadoop-huaweicloud-3.5.0-SNAPSHOT.jar -rw-r--r--@ 1 stevel staff 3519516 Sep 17 13:11 hadoop-shaded-guava-1.4.0.jar -rw-r--r--@ 1 stevel staff 1952967 Sep 17 13:11 hadoop-shaded-protobuf_3_25-1.4.0.jar -rw-r--r--@ 1 stevel staff 4019589 Sep 17 12:57 hadoop-tos-3.5.0-20250916.124028-202.jar -rw-r--r--@ 1 stevel staff 200223 Sep 17 13:11 hk2-api-2.6.1.jar -rw-r--r--@ 1 stevel staff 203358 Sep 17 13:11 hk2-locator-2.6.1.jar -rw-r--r--@ 1 stevel staff 131590 Sep 17 13:11 hk2-utils-2.6.1.jar -rw-r--r--@ 1 stevel staff 780321 Sep 17 13:11 httpclient-4.5.13.jar -rw-r--r--@ 1 stevel staff 328593 Sep 17 13:11 httpcore-4.4.13.jar -rw-r--r--@ 1 stevel staff 102220 Sep 17 12:57 ini4j-0.5.4.jar -rw-r--r--@ 1 stevel staff 29807 Sep 17 13:11 istack-commons-runtime-3.0.12.jar -rw-r--r--@ 1 stevel staff 9301 Sep 17 13:11 j2objc-annotations-2.8.jar -rw-r--r--@ 1 stevel staff 76636 Sep 17 13:11 jackson-annotations-2.14.3.jar -rw-r--r--@ 1 stevel staff 473081 Sep 17 13:11 jackson-core-2.14.3.jar -rw-r--r--@ 1 stevel staff 1617187 Sep 17 13:11 jackson-databind-2.14.3.jar -rw-r--r--@ 1 stevel staff 68453 Sep 17 13:11 jakarta.activation-1.2.2.jar -rw-r--r--@ 1 stevel staff 44399 Sep 17 13:11 jakarta.activation-api-1.2.1.jar -rw-r--r--@ 1 stevel staff 25058 Sep 17 13:11 jakarta.annotation-api-1.3.5.jar -rw-r--r--@ 1 stevel staff 18140 Sep 17 13:11 jakarta.inject-2.6.1.jar -rw-r--r--@ 1 stevel staff 82973 Sep 17 13:11 jakarta.servlet-api-4.0.4.jar -rw-r--r--@ 1 stevel staff 53683 Sep 17 13:11 jakarta.servlet.jsp-api-2.3.6.jar -rw-r--r--@ 1 stevel staff 91930 Sep 17 13:11 jakarta.validation-api-2.0.2.jar -rw-r--r--@ 1 stevel staff 140376 Sep 17 13:11 jakarta.ws.rs-api-2.1.6.jar -rw-r--r--@ 1 stevel staff 115638 Sep 17 13:11 jakarta.xml.bind-api-2.3.3.jar -rw-r--r--@ 1 stevel staff 7771 Sep 17 12:57 java-trace-api-0.2.11-beta.jar -rw-r--r--@ 1 stevel staff 18432 Sep 17 12:57 java-xmlbuilder-1.2.jar -rw-r--r--@ 1 stevel staff 794714 Sep 17 13:11 javassist-3.30.2-GA.jar -rw-r--r--@ 1 stevel staff 95806 Sep 17 13:11 javax.servlet-api-3.1.0.jar -rw-r--r--@ 1 stevel staff 1019097 Sep 17 13:11 jaxb-runtime-2.3.9.jar -rw-r--r--@ 1 stevel staff 4722 Sep 17 13:11 jcip-annotations-1.0-1.jar -rw-r--r--@ 1 stevel staff 327806 Sep 17 12:57 jdom2-2.0.6.1.jar -rw-r--r--@ 1 stevel staff 311826 Sep 17 13:11 jersey-client-2.46.jar -rw-r--r--@ 1 stevel staff 1267957 Sep 17 13:11 jersey-common-2.46.jar -rw-r--r--@ 1 stevel staff 32929 Sep 17 13:11 jersey-container-servlet-2.46.jar -rw-r--r--@ 1 stevel staff 75742 Sep 17 13:11 jersey-container-servlet-core-2.46.jar -rw-r--r--@ 1 stevel staff 80272 Sep 17 13:11 jersey-hk2-2.46.jar -rw-r--r--@ 1 stevel staff 964550 Sep 17 13:11 jersey-server-2.46.jar -rw-r--r--@ 1 stevel staff 90184 Sep 17 12:57 jettison-1.5.4.jar -rw-r--r--@ 1 stevel staff 249911 Sep 17 13:11 jetty-http-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 183011 Sep 17 13:11 jetty-io-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 118496 Sep 17 13:11 jetty-security-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 739348 Sep 17 13:11 jetty-server-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 146064 Sep 17 13:11 jetty-servlet-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 588962 Sep 17 13:11 jetty-util-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 66643 Sep 17 13:11 jetty-util-ajax-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 140308 Sep 17 13:11 jetty-webapp-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 68894 Sep 17 13:11 jetty-xml-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 282591 Sep 17 13:11 jsch-0.1.55.jar -rw-r--r--@ 1 stevel staff 19936 Sep 17 13:11 jsr305-3.0.2.jar -rw-r--r--@ 1 stevel staff 4519 Sep 17 13:11 jul-to-slf4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 223129 Sep 17 13:11 kerb-core-2.0.3.jar -rw-r--r--@ 1 stevel staff 115065 Sep 17 13:11 kerb-crypto-2.0.3.jar -rw-r--r--@ 1 stevel staff 36361 Sep 17 13:11 kerb-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 100095 Sep 17 13:11 kerby-asn1-2.0.3.jar -rw-r--r--@ 1 stevel staff 30190 Sep 17 13:11 kerby-config-2.0.3.jar -rw-r--r--@ 1 stevel staff 200581 Sep 17 13:11 kerby-pkix-2.0.3.jar -rw-r--r--@ 1 stevel staff 40787 Sep 17 13:11 kerby-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 2199 Sep 17 13:11 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar -rw-r--r--@ 1 stevel staff 136314 Sep 17 13:11 metrics-core-3.2.4.jar -rw-r--r--@ 1 stevel staff 4554 Sep 17 13:11 netty-all-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 339045 Sep 17 13:11 netty-buffer-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 355199 Sep 17 13:11 netty-codec-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 67192 Sep 17 13:11 netty-codec-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37789 Sep 17 13:11 netty-codec-haproxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 674362 Sep 17 13:11 netty-codec-http-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 490985 Sep 17 13:11 netty-codec-http2-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 44736 Sep 17 13:11 netty-codec-memcache-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 113699 Sep 17 13:11 netty-codec-mqtt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 46015 Sep 17 13:11 netty-codec-redis-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 21344 Sep 17 13:11 netty-codec-smtp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 121032 Sep 17 13:11 netty-codec-socks-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 34636 Sep 17 13:11 netty-codec-stomp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19823 Sep 17 13:11 netty-codec-xml-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 719225 Sep 17 13:11 netty-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 580162 Sep 17 13:11 netty-handler-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25650 Sep 17 13:11 netty-handler-proxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 26833 Sep 17 13:11 netty-handler-ssl-ocsp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37842 Sep 17 13:11 netty-resolver-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 188360 Sep 17 13:11 netty-resolver-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 9145 Sep 17 13:11 netty-resolver-dns-classes-macos-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19825 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 19629 Sep 17 13:11 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 521428 Sep 17 13:11 netty-transport-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 147621 Sep 17 13:11 netty-transport-classes-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 108558 Sep 17 13:11 netty-transport-classes-kqueue-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 42321 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar -rw-r--r--@ 1 stevel staff 36594 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar -rw-r--r--@ 1 stevel staff 40644 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar -rw-r--r--@ 1 stevel staff 6193 Sep 17 13:11 netty-transport-native-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25741 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 25170 Sep 17 13:11 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 44157 Sep 17 13:11 netty-transport-native-unix-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 18241 Sep 17 13:11 netty-transport-rxtx-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 50814 Sep 17 13:11 netty-transport-sctp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 32189 Sep 17 13:11 netty-transport-udt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 779369 Sep 17 13:11 nimbus-jose-jwt-9.37.2.jar -rw-r--r--@ 1 stevel staff 425763 Sep 17 12:57 okhttp-3.14.2.jar -rw-r--r--@ 1 stevel staff 91980 Sep 17 12:57 okio-1.17.2.jar -rw-r--r--@ 1 stevel staff 141734 Sep 17 12:57 opentelemetry-api-1.38.0.jar -rw-r--r--@ 1 stevel staff 47252 Sep 17 12:57 opentelemetry-context-1.38.0.jar -rw-r--r--@ 1 stevel staff 18189 Sep 17 12:57 opentracing-api-0.33.0.jar -rw-r--r--@ 1 stevel staff 10542 Sep 17 12:57 opentracing-noop-0.33.0.jar -rw-r--r--@ 1 stevel staff 7504 Sep 17 12:57 opentracing-util-0.33.0.jar -rw-r--r--@ 1 stevel staff 281989 Sep 17 12:57 org.jacoco.agent-0.8.5-runtime.jar -rw-r--r--@ 1 stevel staff 19479 Sep 17 13:11 osgi-resource-locator-1.0.3.jar -rw-r--r--@ 1 stevel staff 128414 Sep 17 13:11 re2j-1.1.jar -rw-r--r--@ 1 stevel staff 11369 Sep 17 12:57 reactive-streams-1.0.3.jar -rw-r--r--@ 1 stevel staff 332398 Sep 17 13:11 reload4j-1.2.22.jar -rw-r--r--@ 1 stevel staff 41125 Sep 17 13:11 slf4j-api-1.7.36.jar -rw-r--r--@ 1 stevel staff 9824 Sep 17 13:11 slf4j-reload4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 2112099 Sep 17 13:11 snappy-java-1.1.10.4.jar -rw-r--r--@ 1 stevel staff 195909 Sep 17 13:11 stax2-api-4.2.1.jar -rw-r--r--@ 1 stevel staff 72007 Sep 17 13:11 txw2-2.3.9.jar -rw-r--r--@ 1 stevel staff 443788 Sep 17 12:57 wildfly-openssl-2.1.4.Final.jar -rw-r--r--@ 1 stevel staff 522679 Sep 17 13:11 woodstox-core-5.4.0.jar -rw-r--r--@ 1 stevel staff 1323991 Sep 17 13:11 zookeeper-3.8.4.jar -rw-r--r--@ 1 stevel staff 254932 Sep 17 13:11 zookeeper-jute-3.8.4.jar ```\n[ASF GitHub Bot @ 2025-09-17T13:58:49.196+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303139199 by contrast: 3.4.2 ``` total 98048 -rw-r--r--@ 1 stevel staff 3448 Aug 7 12:16 animal-sniffer-annotations-1.17.jar -rw-r--r--@ 1 stevel staff 20891 Aug 7 12:16 audience-annotations-0.12.0.jar -rw-r--r--@ 1 stevel staff 651391 Aug 7 12:16 avro-1.11.4.jar -rw-r--r--@ 1 stevel staff 8324412 Aug 7 12:15 bcprov-jdk18on-1.78.1.jar -rw-r--r--@ 1 stevel staff 193322 Aug 7 12:16 checker-qual-2.5.2.jar -rw-r--r--@ 1 stevel staff 75479 Aug 7 12:16 commons-cli-1.9.0.jar -rw-r--r--@ 1 stevel staff 353793 Aug 7 12:16 commons-codec-1.15.jar -rw-r--r--@ 1 stevel staff 751914 Aug 7 12:16 commons-collections4-4.4.jar -rw-r--r--@ 1 stevel staff 1079377 Aug 7 12:16 commons-compress-1.26.1.jar -rw-r--r--@ 1 stevel staff 657516 Aug 7 12:16 commons-configuration2-2.10.1.jar -rw-r--r--@ 1 stevel staff 24239 Aug 7 12:16 commons-daemon-1.0.13.jar -rw-r--r--@ 1 stevel staff 508826 Aug 7 12:16 commons-io-2.16.1.jar -rw-r--r--@ 1 stevel staff 673587 Aug 7 12:16 commons-lang3-3.17.0.jar -rw-r--r--@ 1 stevel staff 70816 Aug 7 12:16 commons-logging-1.3.0.jar -rw-r--r--@ 1 stevel staff 2213560 Aug 7 12:16 commons-math3-3.6.1.jar -rw-r--r--@ 1 stevel staff 316431 Aug 7 12:16 commons-net-3.9.0.jar -rw-r--r--@ 1 stevel staff 238400 Aug 7 12:16 commons-text-1.10.0.jar -rw-r--r--@ 1 stevel staff 2983237 Aug 7 12:16 curator-client-5.2.0.jar -rw-r--r--@ 1 stevel staff 336384 Aug 7 12:16 curator-framework-5.2.0.jar -rw-r--r--@ 1 stevel staff 315569 Aug 7 12:16 curator-recipes-5.2.0.jar -rw-r--r--@ 1 stevel staff 583996 Aug 7 12:16 dnsjava-3.6.1.jar -rw-r--r--@ 1 stevel staff 3727 Aug 7 12:16 failureaccess-1.0.jar -rw-r--r--@ 1 stevel staff 249277 Aug 7 12:16 gson-2.9.0.jar -rw-r--r--@ 1 stevel staff 2747878 Aug 7 12:16 guava-27.0-jre.jar -rw-r--r--@ 1 stevel staff 25517 Aug 7 12:16 hadoop-annotations-3.4.2.jar -rw-r--r--@ 1 stevel staff 110106 Aug 7 12:16 hadoop-auth-3.4.2.jar -rw-r--r--@ 1 stevel staff 810477 Aug 7 12:39 hadoop-azure-3.4.2.jar -rw-r--r--@ 1 stevel staff 3519516 Aug 7 12:16 hadoop-shaded-guava-1.4.0.jar -rw-r--r--@ 1 stevel staff 1952967 Aug 7 12:16 hadoop-shaded-protobuf_3_25-1.4.0.jar -rw-r--r--@ 1 stevel staff 780321 Aug 7 12:16 httpclient-4.5.13.jar -rw-r--r--@ 1 stevel staff 328593 Aug 7 12:16 httpcore-4.4.13.jar -rw-r--r--@ 1 stevel staff 8782 Aug 7 12:16 j2objc-annotations-1.1.jar -rw-r--r--@ 1 stevel staff 75705 Aug 7 12:16 jackson-annotations-2.12.7.jar -rw-r--r--@ 1 stevel staff 365538 Aug 7 12:16 jackson-core-2.12.7.jar -rw-r--r--@ 1 stevel staff 1512418 Aug 7 12:16 jackson-databind-2.12.7.1.jar -rw-r--r--@ 1 stevel staff 44399 Aug 7 12:16 jakarta.activation-api-1.2.1.jar -rw-r--r--@ 1 stevel staff 95806 Aug 7 12:16 javax.servlet-api-3.1.0.jar -rw-r--r--@ 1 stevel staff 102244 Aug 7 12:16 jaxb-api-2.2.11.jar -rw-r--r--@ 1 stevel staff 890168 Aug 7 12:16 jaxb-impl-2.2.3-1.jar -rw-r--r--@ 1 stevel staff 4722 Aug 7 12:16 jcip-annotations-1.0-1.jar -rw-r--r--@ 1 stevel staff 436731 Aug 7 12:16 jersey-core-1.19.4.jar -rw-r--r--@ 1 stevel staff 158890 Aug 7 12:16 jersey-json-1.22.0.jar -rw-r--r--@ 1 stevel staff 705276 Aug 7 12:16 jersey-server-1.19.4.jar -rw-r--r--@ 1 stevel staff 128990 Aug 7 12:16 jersey-servlet-1.19.4.jar -rw-r--r--@ 1 stevel staff 90184 Aug 7 12:16 jettison-1.5.4.jar -rw-r--r--@ 1 stevel staff 249911 Aug 7 12:16 jetty-http-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 183011 Aug 7 12:16 jetty-io-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 118496 Aug 7 12:16 jetty-security-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 739348 Aug 7 12:16 jetty-server-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 146064 Aug 7 12:16 jetty-servlet-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 588962 Aug 7 12:16 jetty-util-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 66643 Aug 7 12:16 jetty-util-ajax-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 140308 Aug 7 12:16 jetty-webapp-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 68894 Aug 7 12:16 jetty-xml-9.4.57.v20241219.jar -rw-r--r--@ 1 stevel staff 282591 Aug 7 12:16 jsch-0.1.55.jar -rw-r--r--@ 1 stevel staff 100636 Aug 7 12:15 jsp-api-2.1.jar -rw-r--r--@ 1 stevel staff 19936 Aug 7 12:16 jsr305-3.0.2.jar -rw-r--r--@ 1 stevel staff 46367 Aug 7 12:16 jsr311-api-1.1.1.jar -rw-r--r--@ 1 stevel staff 4519 Aug 7 12:16 jul-to-slf4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 223129 Aug 7 12:16 kerb-core-2.0.3.jar -rw-r--r--@ 1 stevel staff 115065 Aug 7 12:16 kerb-crypto-2.0.3.jar -rw-r--r--@ 1 stevel staff 36361 Aug 7 12:16 kerb-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 100095 Aug 7 12:16 kerby-asn1-2.0.3.jar -rw-r--r--@ 1 stevel staff 30190 Aug 7 12:16 kerby-config-2.0.3.jar -rw-r--r--@ 1 stevel staff 200581 Aug 7 12:16 kerby-pkix-2.0.3.jar -rw-r--r--@ 1 stevel staff 40787 Aug 7 12:16 kerby-util-2.0.3.jar -rw-r--r--@ 1 stevel staff 2199 Aug 7 12:16 listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar -rw-r--r--@ 1 stevel staff 136314 Aug 7 12:16 metrics-core-3.2.4.jar -rw-r--r--@ 1 stevel staff 4554 Aug 7 12:15 netty-all-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 339045 Aug 7 12:16 netty-buffer-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 355199 Aug 7 12:16 netty-codec-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 67192 Aug 7 12:15 netty-codec-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37789 Aug 7 12:15 netty-codec-haproxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 674362 Aug 7 12:15 netty-codec-http-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 490985 Aug 7 12:15 netty-codec-http2-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 44736 Aug 7 12:15 netty-codec-memcache-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 113699 Aug 7 12:15 netty-codec-mqtt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 46015 Aug 7 12:15 netty-codec-redis-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 21344 Aug 7 12:15 netty-codec-smtp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 121032 Aug 7 12:15 netty-codec-socks-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 34636 Aug 7 12:15 netty-codec-stomp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19823 Aug 7 12:15 netty-codec-xml-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 719225 Aug 7 12:16 netty-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 580162 Aug 7 12:16 netty-handler-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25650 Aug 7 12:15 netty-handler-proxy-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 26833 Aug 7 12:15 netty-handler-ssl-ocsp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 37842 Aug 7 12:16 netty-resolver-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 188360 Aug 7 12:15 netty-resolver-dns-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 9145 Aug 7 12:15 netty-resolver-dns-classes-macos-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 19825 Aug 7 12:15 netty-resolver-dns-native-macos-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 19629 Aug 7 12:15 netty-resolver-dns-native-macos-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 521428 Aug 7 12:16 netty-transport-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 147621 Aug 7 12:16 netty-transport-classes-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 108558 Aug 7 12:15 netty-transport-classes-kqueue-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 42321 Aug 7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar -rw-r--r--@ 1 stevel staff 36594 Aug 7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar -rw-r--r--@ 1 stevel staff 40644 Aug 7 12:15 netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar -rw-r--r--@ 1 stevel staff 6193 Aug 7 12:16 netty-transport-native-epoll-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 25741 Aug 7 12:15 netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar -rw-r--r--@ 1 stevel staff 25170 Aug 7 12:15 netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar -rw-r--r--@ 1 stevel staff 44157 Aug 7 12:16 netty-transport-native-unix-common-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 18241 Aug 7 12:15 netty-transport-rxtx-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 50814 Aug 7 12:15 netty-transport-sctp-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 32189 Aug 7 12:15 netty-transport-udt-4.1.118.Final.jar -rw-r--r--@ 1 stevel staff 779369 Aug 7 12:16 nimbus-jose-jwt-9.37.2.jar -rw-r--r--@ 1 stevel staff 128414 Aug 7 12:16 re2j-1.1.jar -rw-r--r--@ 1 stevel staff 332398 Aug 7 12:16 reload4j-1.2.22.jar -rw-r--r--@ 1 stevel staff 41125 Aug 7 12:15 slf4j-api-1.7.36.jar -rw-r--r--@ 1 stevel staff 9824 Aug 7 12:15 slf4j-reload4j-1.7.36.jar -rw-r--r--@ 1 stevel staff 2112099 Aug 7 12:16 snappy-java-1.1.10.4.jar -rw-r--r--@ 1 stevel staff 195909 Aug 7 12:16 stax2-api-4.2.1.jar -rw-r--r--@ 1 stevel staff 522679 Aug 7 12:16 woodstox-core-5.4.0.jar -rw-r--r--@ 1 stevel staff 1323991 Aug 7 12:16 zookeeper-3.8.4.jar -rw-r--r--@ 1 stevel staff 254932 Aug 7 12:16 zookeeper-jute-3.8.4.jar ```\n[ASF GitHub Bot @ 2025-09-17T15:03:51.648+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303435683 Having audited the files coming off the cloud connectors, we have about a dozen whose licenses aren't in the binary ``` analyticsaccelerator-s3-1.3.0.jar cos_api-bundle-5.6.19.jar dom4j-2.1.4.jar esdk-obs-java-3.20.4.2.jar java-trace-api-0.2.11-beta.jar java-xmlbuilder-1.2.jar opentracing-api-0.33.0.jar opentracing-noop-0.33.0.jar opentracing-util-0.33.0.jar reactive-streams-1.0.3.jar ve-tos-java-sdk-hadoop-2.8.9.jar ``` the analyticsaccelerator is @ahmarsuhail 's work to add to the license, not sure about the others. Proposed: identify which connector the unacknowledged artifacts are coming from, create homework for each team.\n[ASF GitHub Bot @ 2025-09-17T17:27:14.500+0000]: hadoop-yetus commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3303936232 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 33s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 13m 4s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 43m 58s | | trunk passed | | +1 :green_heart: | compile | 16m 16s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 13m 34s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 2m 57s | | trunk passed | | +1 :green_heart: | javadoc | 2m 53s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 43s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 40m 19s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 35s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 1m 10s | | the patch passed | | +1 :green_heart: | compile | 14m 58s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 14m 58s | | the patch passed | | +1 :green_heart: | compile | 13m 51s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 13m 51s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 2m 55s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 2m 47s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 41s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 42m 52s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 39s | | hadoop-assemblies in the patch passed. | | +1 :green_heart: | unit | 0m 41s | | hadoop-tools-dist in the patch passed. | | +1 :green_heart: | unit | 0m 44s | | hadoop-huaweicloud in the patch passed. | | +1 :green_heart: | unit | 0m 41s | | hadoop-cloud-storage in the patch passed. | | +1 :green_heart: | asflicense | 1m 6s | | The patch does not generate ASF License warnings. | | | | 214m 20s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7980 | | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint | | uname | Linux 604f3bcd050e 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / c59e35149ea17b7cea37be9203a265dcbff118fe | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/testReport/ | | Max. process+thread count | 548 (vs. ulimit of 5500) | | modules | C: hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-cloud-storage U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/1/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-19T12:03:19.259+0000]: ahmarsuhail commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3311933628 not very familiar with how the packaging stuff works, so finding this a bit difficult to review. How are testing the packaging, I just ran `mvn package -Pdist -DskipTests -Dmaven.javadoc.skip=true -DskipShade`, but the outputs in : `hadoop-cloud-storage-project/hadoop-cloud-storage/target/hadoop-cloud-storage-3.5.0-SNAPSHOT/share/hadoop/common/lib`, `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/tools/lib` `hadoop/hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib` are all the same before and after your changes, so I must be doing something wrong.\n[ASF GitHub Bot @ 2025-09-19T13:33:05.736+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3312222391 did you do a `mvn clean package`? `hadoop-cloud-storage-project/hadoop-cloud-storage/target/hadoop-cloud-storage-3.5.0-SNAPSHOT/share/hadoop/common/lib` -new, contains all cloud stuff we want in; should cut stuff already going to be there just to reduce copying `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/share/hadoop/tools/lib` should remove hadoop-azure, hadoop-aws, hadoop-gcs, bundle.jar... the big distro created under `hadoop-dist/target/hadoop-3.5.0-SNAPSHOT/` is what is shipped.\n[ASF GitHub Bot @ 2025-09-24T11:03:18.734+0000]: hadoop-yetus commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3327784078 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 15m 12s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 10m 27s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 38m 56s | | trunk passed | | +1 :green_heart: | compile | 16m 7s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 13m 50s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 20m 36s | | trunk passed | | +1 :green_heart: | javadoc | 9m 11s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 39s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 18m 3s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 35s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 38m 59s | | the patch passed | | +1 :green_heart: | compile | 15m 25s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 25s | | the patch passed | | +1 :green_heart: | compile | 13m 56s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 13m 56s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 18m 55s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | -1 :x: | javadoc | 9m 9s | [/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 10 new + 5526 unchanged - 10 fixed = 5536 total (was 5536) | | -1 :x: | javadoc | 7m 34s | [/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 10 new + 1418 unchanged - 10 fixed = 1428 total (was 1428) | | -1 :x: | shadedclient | 19m 38s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 800m 7s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 46s | | The patch does not generate ASF License warnings. | | | | 1046m 13s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler | | | hadoop.mapreduce.v2.TestUberAM | | | hadoop.yarn.sls.appmaster.TestAMSimulator | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7980 | | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint | | uname | Linux 271d5e8aaf6a 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 0aaa6ce66e8a8fc7fc04fa4e2650badf956d531a | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/testReport/ | | Max. process+thread count | 4938 (vs. ulimit of 5500) | | modules | C: hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-cloud-storage . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/2/console | | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[Steve Loughran @ 2025-10-09T17:04:53.181+0000]: I've just discovered quite how many things google-cloud-storage jar pulls in if you don't build a shaded release. Nowhere as big as the aws sdk, but it it is still significant. # I'm going to exclude hadoop-gcp dependencies by default in a build, so if you build hadoop distro with -DskipShade you don't get these in common-lib unless you have a -Dhadoop-gcp-package. # Most of these aren't in our published LICENSE-binary file. some are, but not all. # the opentelemetry/census artifacts are newer than those from one of the other projects; build both and you get conflict (joy!). # a protobuf 2.5 comes in from somewhere I think for now I'd say \"don't make issues 2-3 blockers on merging the PR\" because they're independent. But ideally the gcs imports should be tuned down and we should go for consistent opentelemetry/opencensus versions wherever imported. {code} 3.0K animal-sniffer-annotations-1.24.jar 3.0K annotations-4.1.1.4.jar 49K api-common-2.47.2.jar 7.3K auto-value-annotations-1.11.0.jar 232K checker-qual-3.49.0.jar 4.3M conscrypt-openjdk-uber-2.5.2.jar 18K detector-resources-support-0.33.0.jar 19K error_prone_annotations-2.36.0.jar 39K exporter-metrics-0.33.0.jar 4.6K failureaccess-1.0.2.jar 52K gapic-google-cloud-storage-v2-2.52.0.jar 424K gax-2.64.2.jar 154K gax-grpc-2.64.2.jar 162K gax-httpjson-2.64.2.jar 295K google-api-client-2.7.2.jar 252K google-api-services-storage-v1-rev20250420-2.0.0.jar 8.2K google-auth-library-credentials-1.33.1.jar 294K google-auth-library-oauth2-http-1.33.1.jar 137K google-cloud-core-2.54.2.jar 16K google-cloud-core-grpc-2.54.2.jar 15K google-cloud-core-http-2.54.2.jar 249K google-cloud-monitoring-3.52.0.jar 1.3M google-cloud-storage-2.52.0.jar 289K google-http-client-1.46.3.jar 11K google-http-client-apache-v2-1.46.3.jar 19K google-http-client-appengine-1.46.3.jar 13K google-http-client-gson-1.46.3.jar 9.4K google-http-client-jackson2-1.46.3.jar 80K google-oauth-client-1.37.0.jar 316K grpc-alts-1.70.0.jar 316K grpc-api-1.70.0.jar 14K grpc-auth-1.70.0.jar 293B grpc-context-1.70.0.jar 639K grpc-core-1.70.0.jar 30K grpc-google-cloud-storage-v2-2.52.0.jar 15K grpc-googleapis-1.70.0.jar 175K grpc-grpclb-1.70.0.jar 39K grpc-inprocess-1.70.0.jar 9.3M grpc-netty-shaded-1.70.0.jar 67K grpc-opentelemetry-1.70.0.jar 5.2K grpc-protobuf-1.70.0.jar 7.7K grpc-protobuf-lite-1.70.0.jar 248K grpc-rls-1.70.0.jar 928K grpc-services-1.70.0.jar 59K grpc-stub-1.70.0.jar 98K grpc-util-1.70.0.jar 9.4M grpc-xds-1.70.0.jar 243K gson-2.9.0.jar 2.9M guava-33.4.8-jre.jar 12K j2objc-annotations-3.0.0.jar 462K jackson-core-2.14.3.jar 26K javax.annotation-api-1.3.2.jar 3.7K jspecify-1.0.0.jar 19K jsr305-3.0.2.jar 2.1K listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar 347K opencensus-api-0.31.1.jar 23K opencensus-contrib-http-util-0.31.1.jar 155K opentelemetry-api-1.47.0.jar 48K opentelemetry-context-1.47.0.jar 8.1K opentelemetry-gcp-resources-1.37.0-alpha.jar 6.6K opentelemetry-sdk-1.47.0.jar 54K opentelemetry-sdk-common-1.47.0.jar 20K opentelemetry-sdk-extension-autoconfigure-spi-1.47.0.jar 53K opentelemetry-sdk-logs-1.47.0.jar 322K opentelemetry-sdk-metrics-1.47.0.jar 129K opentelemetry-sdk-trace-1.47.0.jar 73K opentelemetry-semconv-1.29.0-alpha.jar 6.8K perfmark-api-0.27.0.jar 1.9M proto-google-cloud-monitoring-v3-3.52.0.jar 980K proto-google-cloud-storage-v2-2.52.0.jar 2.6M proto-google-common-protos-2.55.2.jar 182K proto-google-iam-v1-1.50.2.jar 521K protobuf-java-2.5.0.jar 71K protobuf-java-util-3.25.5.jar 125K re2j-1.1.jar 91K shared-resourcemapping-0.33.0.jar 40K slf4j-api-1.7.36.jar 503K threetenbp-1.7.0.jar {code}\n[ASF GitHub Bot @ 2025-10-09T19:09:29.393+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3387174385 Latest build generates stack traces from gcs and obs filesystem incomplete CP in service loader. Both need to move to core-default.xml *only* which is faster anyway. ``` 2025-10-09 20:06:44,452 [main] WARN fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.fs.gs.GoogleHadoopFileSystem could not be instantiated at java.util.ServiceLoader.fail(ServiceLoader.java:232) at java.util.ServiceLoader.access$100(ServiceLoader.java:185) at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384) at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404) at java.util.ServiceLoader$1.next(ServiceLoader.java:480) at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3525) at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562) at org.apache.hadoop.fs.store.diag.StoreDiag.probeForFileSystemClass(StoreDiag.java:671) at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:223) at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:170) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97) at org.apache.hadoop.fs.store.diag.StoreDiag.exec(StoreDiag.java:1255) at org.apache.hadoop.fs.store.diag.StoreDiag.main(StoreDiag.java:1264) at storediag.main(storediag.java:25) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:333) at org.apache.hadoop.util.RunJar.main(RunJar.java:254) Caused by: java.lang.NoClassDefFoundError: com/google/auth/Credentials at java.lang.Class.getDeclaredConstructors0(Native Method) at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671) at java.lang.Class.getConstructor0(Class.java:3075) at java.lang.Class.newInstance(Class.java:412) at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380) ... 18 more Caused by: java.lang.ClassNotFoundException: com.google.auth.Credentials at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:419) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:352) ... 23 more 2025-10-09 20:06:44,456 [main] WARN fs.FileSystem (FileSystem.java:loadFileSystems(3539)) - Cannot load filesystem java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.fs.obs.OBSFileSystem could not be instantiated at java.util.ServiceLoader.fail(ServiceLoader.java:232) at java.util.ServiceLoader.access$100(ServiceLoader.java:185) at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384) at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404) at java.util.ServiceLoader$1.next(ServiceLoader.java:480) at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3525) at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562) at org.apache.hadoop.fs.store.diag.StoreDiag.probeForFileSystemClass(StoreDiag.java:671) at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:223) at org.apache.hadoop.fs.store.diag.StoreDiag.run(StoreDiag.java:170) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:82) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:97) at org.apache.hadoop.fs.store.diag.StoreDiag.exec(StoreDiag.java:1255) at org.apache.hadoop.fs.store.diag.StoreDiag.main(StoreDiag.java:1264) at storediag.main(storediag.java:25) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:333) at org.apache.hadoop.util.RunJar.main(RunJar.java:254) Caused by: java.lang.NoClassDefFoundError: com/obs/services/exception/ObsException at java.lang.Class.getDeclaredConstructors0(Native Method) at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671) at java.lang.Class.getConstructor0(Class.java:3075) at java.lang.Class.newInstance(Class.java:412) at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380) ... 18 more Caused by: java.lang.ClassNotFoundException: com.obs.services.exception.ObsException at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:419) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:352) ... 23 more FileSystem for s3a:// is: org.apache.hadoop.fs.s3a.S3AFileSystem Loaded from: file:/Users/stevel/Projects/Releases/hadoop-3.5.0-SNAPSHOT/share/hadoop/common/lib/hadoop-aws-3.5.0-SNAPSHOT.jar via sun.misc.Launcher$AppClassLoader@41906a77 ```\n[ASF GitHub Bot @ 2025-10-09T22:50:28.141+0000]: hadoop-yetus commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3387715974 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 1m 9s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 9m 3s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 38m 50s | | trunk passed | | +1 :green_heart: | compile | 16m 3s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 14m 6s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 21m 2s | | trunk passed | | +1 :green_heart: | javadoc | 9m 0s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 29s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 49m 55s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 40s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 41m 14s | | the patch passed | | +1 :green_heart: | compile | 15m 33s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 33s | | the patch passed | | +1 :green_heart: | compile | 13m 29s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 13m 29s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 18m 48s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | -1 :x: | javadoc | 9m 58s | [/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/results-javadoc-javadoc-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 generated 10 new + 5526 unchanged - 10 fixed = 5536 total (was 5536) | | -1 :x: | javadoc | 8m 2s | [/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/results-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 generated 10 new + 1418 unchanged - 10 fixed = 1428 total (was 1428) | | +1 :green_heart: | shadedclient | 63m 31s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 2m 22s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +0 :ok: | asflicense | 0m 32s | | ASF License check generated no output? | | | | 309m 40s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7980 | | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint | | uname | Linux 01b725e22dc7 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 76b4eae78d738ee73cf68118a87c9204d120d752 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/testReport/ | | Max. process+thread count | 699 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-assemblies hadoop-tools/hadoop-tools-dist hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-tos hadoop-cloud-storage-project/hadoop-cloud-storage hadoop-cloud-storage-project/hadoop-cloud-storage-dist hadoop-cloud-storage-project . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/4/console | | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[Steve Loughran @ 2025-10-13T16:07:33.413+0000]: and full jars if you pull in everything. aws bundle.jar dominates; the rest adds up. {code} 104K aliyun-java-core-0.2.11-beta.jar 190K aliyun-java-sdk-core-4.5.10.jar 160K aliyun-java-sdk-kms-2.11.0.jar 216K aliyun-java-sdk-ram-3.1.0.jar 907K aliyun-sdk-oss-3.18.1.jar 2.4M analyticsaccelerator-s3-1.3.0.jar 3.0K animal-sniffer-annotations-1.24.jar 3.0K annotations-4.1.1.4.jar 49K api-common-2.47.2.jar 7.3K auto-value-annotations-1.11.0.jar 111K azure-data-lake-store-sdk-2.3.9.jar 10K azure-keyvault-core-1.0.0.jar 796K azure-storage-7.0.1.jar 612M bundle-2.29.52.jar 232K checker-qual-3.49.0.jar 346K commons-codec-1.15.jar 69K commons-logging-1.3.0.jar 4.3M conscrypt-openjdk-uber-2.5.2.jar 8.3M cos_api-bundle-5.6.19.jar 18K detector-resources-support-0.33.0.jar 317K dom4j-2.1.4.jar 19K error_prone_annotations-2.36.0.jar 39K exporter-metrics-0.33.0.jar 4.6K failureaccess-1.0.2.jar 52K gapic-google-cloud-storage-v2-2.52.0.jar 424K gax-2.64.2.jar 154K gax-grpc-2.64.2.jar 162K gax-httpjson-2.64.2.jar 295K google-api-client-2.7.2.jar 252K google-api-services-storage-v1-rev20250420-2.0.0.jar 8.2K google-auth-library-credentials-1.33.1.jar 294K google-auth-library-oauth2-http-1.33.1.jar 137K google-cloud-core-2.54.2.jar 16K google-cloud-core-grpc-2.54.2.jar 15K google-cloud-core-http-2.54.2.jar 249K google-cloud-monitoring-3.52.0.jar 1.3M google-cloud-storage-2.52.0.jar 289K google-http-client-1.46.3.jar 11K google-http-client-apache-v2-1.46.3.jar 19K google-http-client-appengine-1.46.3.jar 13K google-http-client-gson-1.46.3.jar 9.4K google-http-client-jackson2-1.46.3.jar 80K google-oauth-client-1.37.0.jar 316K grpc-alts-1.70.0.jar 316K grpc-api-1.70.0.jar 14K grpc-auth-1.70.0.jar 293B grpc-context-1.70.0.jar 639K grpc-core-1.70.0.jar 30K grpc-google-cloud-storage-v2-2.52.0.jar 15K grpc-googleapis-1.70.0.jar 175K grpc-grpclb-1.70.0.jar 39K grpc-inprocess-1.70.0.jar 9.3M grpc-netty-shaded-1.70.0.jar 67K grpc-opentelemetry-1.70.0.jar 5.2K grpc-protobuf-1.70.0.jar 7.7K grpc-protobuf-lite-1.70.0.jar 248K grpc-rls-1.70.0.jar 928K grpc-services-1.70.0.jar 59K grpc-stub-1.70.0.jar 98K grpc-util-1.70.0.jar 9.4M grpc-xds-1.70.0.jar 243K gson-2.9.0.jar 2.9M guava-33.4.8-jre.jar 92K hadoop-aliyun-3.5.0-SNAPSHOT.jar 910K hadoop-aws-3.5.0-SNAPSHOT.jar 810K hadoop-azure-3.5.0-SNAPSHOT.jar 33K hadoop-azure-datalake-3.5.0-SNAPSHOT.jar 68K hadoop-cos-3.5.0-SNAPSHOT.jar 135K hadoop-gcp-3.5.0-SNAPSHOT.jar 142K hadoop-huaweicloud-3.5.0-SNAPSHOT.jar 250K hadoop-tos-3.5.0-SNAPSHOT.jar 762K httpclient-4.5.13.jar 933K httpclient5-5.5.jar 321K httpcore-4.4.13.jar 888K httpcore5-5.3.6.jar 236K httpcore5-h2-5.3.4.jar 100K ini4j-0.5.4.jar 12K j2objc-annotations-3.0.0.jar 462K jackson-core-2.14.3.jar 7.6K java-trace-api-0.2.11-beta.jar 26K javax.annotation-api-1.3.2.jar 320K jdom2-2.0.6.1.jar 88K jettison-1.5.4.jar 575K jetty-util-9.4.57.v20241219.jar 65K jetty-util-ajax-9.4.57.v20241219.jar 3.7K jspecify-1.0.0.jar 19K jsr305-3.0.2.jar 2.1K listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar 347K opencensus-api-0.31.1.jar 23K opencensus-contrib-http-util-0.31.1.jar 155K opentelemetry-api-1.47.0.jar 48K opentelemetry-context-1.47.0.jar 8.1K opentelemetry-gcp-resources-1.37.0-alpha.jar 6.6K opentelemetry-sdk-1.47.0.jar 54K opentelemetry-sdk-common-1.47.0.jar 20K opentelemetry-sdk-extension-autoconfigure-spi-1.47.0.jar 53K opentelemetry-sdk-logs-1.47.0.jar 322K opentelemetry-sdk-metrics-1.47.0.jar 129K opentelemetry-sdk-trace-1.47.0.jar 73K opentelemetry-semconv-1.29.0-alpha.jar 275K org.jacoco.agent-0.8.5-runtime.jar 6.8K perfmark-api-0.27.0.jar 1.9M proto-google-cloud-monitoring-v3-3.52.0.jar 980K proto-google-cloud-storage-v2-2.52.0.jar 2.6M proto-google-common-protos-2.55.2.jar 182K proto-google-iam-v1-1.50.2.jar 521K protobuf-java-2.5.0.jar 71K protobuf-java-util-3.25.5.jar 125K re2j-1.1.jar 11K reactive-streams-1.0.3.jar 91K shared-resourcemapping-0.33.0.jar 40K slf4j-api-1.7.36.jar 503K threetenbp-1.7.0.jar 980K ve-tos-java-sdk-hadoop-2.8.9.jar 433K wildfly-openssl-2.1.4.Final.jar {code} The default settings will produce something a lot leaner {code} 2.4M analyticsaccelerator-s3-1.3.0.jar 10K azure-keyvault-core-1.0.0.jar 796K azure-storage-7.0.1.jar 346K commons-codec-1.15.jar 69K commons-logging-1.3.0.jar 910K hadoop-aws-3.5.0-SNAPSHOT.jar 810K hadoop-azure-3.5.0-SNAPSHOT.jar 33K hadoop-azure-datalake-3.5.0-SNAPSHOT.jar 68K hadoop-cos-3.5.0-SNAPSHOT.jar 135K hadoop-gcp-3.5.0-SNAPSHOT.jar 142K hadoop-huaweicloud-3.5.0-SNAPSHOT.jar 250K hadoop-tos-3.5.0-SNAPSHOT.jar 762K httpclient-4.5.13.jar 321K httpcore-4.4.13.jar 575K jetty-util-9.4.57.v20241219.jar 65K jetty-util-ajax-9.4.57.v20241219.jar 433K wildfly-openssl-2.1.4.Final.jar {code}\n[ASF GitHub Bot @ 2025-10-14T14:23:01.303+0000]: steveloughran commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3402138222 shaded test failures * some in yarn which are presumably unrelated...let's see * lots of more skipped tests in hadoop-azure, hadoop-azuredatalake, such as `TestAbfsInputStreamStatistics` which is skipping .... Looks like maven is back to running these tests and skipping where they don't have the credentials\n[ASF GitHub Bot @ 2025-10-15T09:44:55.130+0000]: hadoop-yetus commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3405523026 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 21m 30s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 9m 15s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 35m 25s | | trunk passed | | +1 :green_heart: | compile | 17m 37s | | trunk passed | | +1 :green_heart: | checkstyle | 3m 40s | | trunk passed | | -1 :x: | mvnsite | 11m 2s | [/branch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-mvnsite-root.txt) | root in trunk failed. | | +1 :green_heart: | javadoc | 9m 44s | | trunk passed | | +0 :ok: | spotbugs | 0m 27s | | branch/hadoop-project no spotbugs output file (spotbugsXml.xml) | | +0 :ok: | spotbugs | 0m 22s | | branch/hadoop-assemblies no spotbugs output file (spotbugsXml.xml) | | -1 :x: | spotbugs | 1m 19s | [/branch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-common-project_hadoop-common.txt) | hadoop-common in trunk failed. | | -1 :x: | spotbugs | 0m 32s | [/branch-spotbugs-hadoop-tools_hadoop-gcp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-tools_hadoop-gcp.txt) | hadoop-gcp in trunk failed. | | +0 :ok: | spotbugs | 0m 23s | | branch/hadoop-tools/hadoop-tools-dist no spotbugs output file (spotbugsXml.xml) | | -1 :x: | spotbugs | 0m 32s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt) | hadoop-huaweicloud in trunk failed. | | -1 :x: | spotbugs | 0m 37s | [/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in trunk failed. | | +0 :ok: | spotbugs | 0m 23s | | branch/hadoop-cloud-storage-project/hadoop-cloud-storage no spotbugs output file (spotbugsXml.xml) | | -1 :x: | spotbugs | 0m 31s | [/branch-spotbugs-hadoop-cloud-storage-project.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-hadoop-cloud-storage-project.txt) | hadoop-cloud-storage-project in trunk failed. | | -1 :x: | spotbugs | 0m 30s | [/branch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/branch-spotbugs-root.txt) | root in trunk failed. | | +1 :green_heart: | shadedclient | 30m 50s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 34s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 43m 52s | | the patch passed | | +1 :green_heart: | compile | 17m 5s | | the patch passed | | +1 :green_heart: | javac | 17m 5s | | the patch passed | | +1 :green_heart: | blanks | 0m 1s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 3m 39s | | the patch passed | | -1 :x: | mvnsite | 7m 36s | [/patch-mvnsite-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-mvnsite-root.txt) | root in the patch failed. | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | -1 :x: | javadoc | 9m 41s | [/results-javadoc-javadoc-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/results-javadoc-javadoc-root.txt) | root generated 30 new + 42985 unchanged - 30 fixed = 43015 total (was 43015) | | +0 :ok: | spotbugs | 0m 22s | | hadoop-project has no data from spotbugs | | +0 :ok: | spotbugs | 0m 22s | | hadoop-assemblies has no data from spotbugs | | -1 :x: | spotbugs | 1m 19s | [/patch-spotbugs-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-common-project_hadoop-common.txt) | hadoop-common in the patch failed. | | +0 :ok: | spotbugs | 0m 24s | | hadoop-tools/hadoop-tools-dist has no data from spotbugs | | -1 :x: | spotbugs | 0m 33s | [/patch-spotbugs-hadoop-tools_hadoop-gcp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-tools_hadoop-gcp.txt) | hadoop-gcp in the patch failed. | | -1 :x: | spotbugs | 0m 32s | [/patch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project_hadoop-huaweicloud.txt) | hadoop-huaweicloud in the patch failed. | | -1 :x: | spotbugs | 0m 36s | [/patch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project_hadoop-tos.txt) | hadoop-tos in the patch failed. | | +0 :ok: | spotbugs | 0m 22s | | hadoop-cloud-storage-project/hadoop-cloud-storage has no data from spotbugs | | +0 :ok: | spotbugs | 0m 23s | | hadoop-cloud-storage-project/hadoop-cloud-storage-dist has no data from spotbugs | | -1 :x: | spotbugs | 0m 31s | [/patch-spotbugs-hadoop-cloud-storage-project.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-hadoop-cloud-storage-project.txt) | hadoop-cloud-storage-project in the patch failed. | | -1 :x: | spotbugs | 0m 30s | [/patch-spotbugs-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-spotbugs-root.txt) | root in the patch failed. | | +1 :green_heart: | shadedclient | 31m 14s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 801m 10s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/patch-unit-root.txt) | root in the patch passed. | | -1 :x: | asflicense | 1m 45s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/results-asflicense.txt) | The patch generated 1 ASF License warnings. | | | | 1072m 30s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.yarn.sls.appmaster.TestAMSimulator | | | hadoop.hdfs.tools.TestDFSAdmin | | | hadoop.yarn.service.TestYarnNativeServices | | | hadoop.yarn.server.router.subcluster.capacity.TestYarnFederationWithCapacityScheduler | | | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST | | | hadoop.yarn.server.router.webapp.TestFederationWebApp | | | hadoop.fs.tosfs.object.TestObjectOutputStream | | | hadoop.fs.tosfs.commit.TestMagicOutputStream | | | hadoop.fs.tosfs.object.tos.auth.TestEnvironmentCredentialsProvider | | | hadoop.fs.tosfs.object.tos.auth.TestDefaultCredentialsProviderChain | | | hadoop.fs.tosfs.object.TestObjectRangeInputStream | | | hadoop.fs.tosfs.object.TestObjectMultiRangeInputStream | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7980 | | Optional Tests | dupname asflicense codespell detsecrets shellcheck shelldocs compile javac javadoc mvninstall mvnsite unit shadedclient xmllint spotbugs checkstyle | | uname | Linux 209e4e5576fc 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 0254bb430e1623793f30744d7b32a37202f2d586 | | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/testReport/ | | Max. process+thread count | 3665 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-assemblies hadoop-common-project/hadoop-common hadoop-tools/hadoop-tools-dist hadoop-tools/hadoop-gcp hadoop-cloud-storage-project/hadoop-huaweicloud hadoop-cloud-storage-project/hadoop-tos hadoop-cloud-storage-project/hadoop-cloud-storage hadoop-cloud-storage-project/hadoop-cloud-storage-dist hadoop-cloud-storage-project . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/7/console | | versions | git=2.25.1 maven=3.9.11 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-20T23:40:44.245+0000]: cnauroth commented on code in PR #7980: URL: https://github.com/apache/hadoop/pull/7980#discussion_r2446383325 ########## hadoop-cloud-storage-project/pom.xml: ########## @@ -34,6 +34,7 @@ <module>hadoop-cos<\/module> <module>hadoop-huaweicloud<\/module> <module>hadoop-tos<\/module> + <module>hadoop-cloud-storage-dist<\/module> Review Comment: It seems like we would never need to enter execution of `hadoop-cloud-storage-dist` unless we are building a distro (activating `-Pdist`). Should we also wrap inclusion of the sub-module here behind activation of the `dist` profile? ########## BUILDING.txt: ########## @@ -388,6 +388,58 @@ Create a local staging version of the website (in /tmp/hadoop-site) Note that the site needs to be built in a second pass after other artifacts. +---------------------------------------------------------------------------------- +Including Cloud Connector Dependencies in Distributions: + +Hadoop distributions include the hadoop modules need to work with data and services Review Comment: Nitpick: \"modules needed\".\n[ASF GitHub Bot @ 2025-10-21T10:47:12.420+0000]: steveloughran commented on code in PR #7980: URL: https://github.com/apache/hadoop/pull/7980#discussion_r2447670994 ########## hadoop-cloud-storage-project/pom.xml: ########## @@ -34,6 +34,7 @@ <module>hadoop-cos<\/module> <module>hadoop-huaweicloud<\/module> <module>hadoop-tos<\/module> + <module>hadoop-cloud-storage-dist<\/module> Review Comment: valid point. Will do, as it'll save on disk space as well as time.\n[ASF GitHub Bot @ 2025-10-21T10:57:22.714+0000]: hadoop-yetus commented on PR #7980: URL: https://github.com/apache/hadoop/pull/7980#issuecomment-3425948823 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 0s | | Docker mode activated. | | -1 :x: | patch | 0m 16s | | https://github.com/apache/hadoop/pull/7980 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help. | | Subsystem | Report/Notes | |----------:|:-------------| | GITHUB PR | https://github.com/apache/hadoop/pull/7980 | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7980/10/console | | versions | git=2.34.1 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-21T22:22:36.924+0000]: cnauroth commented on code in PR #7980: URL: https://github.com/apache/hadoop/pull/7980#discussion_r2449857037 ########## BUILDING.txt: ########## @@ -388,6 +388,57 @@ Create a local staging version of the website (in /tmp/hadoop-site) Note that the site needs to be built in a second pass after other artifacts. +---------------------------------------------------------------------------------- +Including Cloud Connector Dependencies in Distributions: + +Hadoop distributions include the hadoop modules needed to work with data and services +on cloud infrastructure + +However, dependencies are omitted for all cloud connectors except hadoop-azure +(abfs:// and wasb://) and possibly hadoop-gcp (gs://) and hadoop-tos (tos://). +For the latter two modules, it depends on shading options. + +For hadoop-aws the AWS SDK bundle.jar is omitted, but everything else is included. + +Excluding the extra binaries: +* Keeps release artifact size below the limit of the ASF distribution network. +* Reduces download and size overhead in docker usage. +* Reduces the CVE attack surface and audit-related complaints about those same ScVES. Review Comment: Nitpick: \"CVEs.\"","key":"HADOOP-19696","status":"Open","labels":"pull-request-available"}
{"summary":"Add dual-stack/IPv6 Support to HttpServer2","created":"2025-09-17T11:21:23.000+0000","description":"To support clients connecting to JHS via IPv6, we need to equip the YARN WebApp class to bind to an IPv6 address. WebApp uses the HttpServer2, and adding the IPv6 connector to this class makes the solution more elegant.\r\n\r\nTo enable dual-stack or IPv6 support, use InetAddress.getAllByName(hostname) to resolve the IP addresses of a host.\r\nWhen the system property java.net.preferIPv4Stack is set to true, only IPv4 addresses are returned, and any IPv6 addresses are ignored, so no extra check is needed to exclude IPv6.\r\nWhen java.net.preferIPv4Stack is false, both IPv4 and IPv6 addresses may be returned, and any IPv6 addresses will also be added as connectors.\r\nTo disable IPv4, you need to configure the OS at the system level.\r\n ","assignee":"Ferenc Erdelyi","priority":"Minor","updated":"2025-10-13T08:48:57.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-17T11:39:42.443+0000]: ferdelyi opened a new pull request, #7979: URL: https://github.com/apache/hadoop/pull/7979 To enable dual-stack or IPv6 support, use InetAddress.getAllByName(hostname) to resolve the IP addresses of a host. When the system property java.net.preferIPv4Stack is set to true, only IPv4 addresses are returned, and any IPv6 addresses are ignored, so no extra check is needed to exclude IPv6. When java.net.preferIPv4Stack is false, both IPv4 and IPv6 addresses may be returned, and any IPv6 addresses will also be added as connectors. To disable IPv4, you need to configure the OS at the system level. <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-17T15:52:09.794+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3303626071 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 47s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 57m 18s | | trunk passed | | +1 :green_heart: | compile | 17m 55s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 34s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 18s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 41s | | trunk passed | | +1 :green_heart: | javadoc | 1m 18s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 52s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 33s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 47s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 57s | | the patch passed | | +1 :green_heart: | compile | 17m 1s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 1s | | the patch passed | | +1 :green_heart: | compile | 15m 40s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 40s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 1m 14s | [/results-checkstyle-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/artifact/out/results-checkstyle-hadoop-common-project_hadoop-common.txt) | hadoop-common-project/hadoop-common: The patch generated 1 new + 68 unchanged - 0 fixed = 69 total (was 68) | | +1 :green_heart: | mvnsite | 1m 34s | | the patch passed | | +1 :green_heart: | javadoc | 1m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 52s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 44s | | the patch passed | | -1 :x: | shadedclient | 42m 42s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 33s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 5s | | The patch does not generate ASF License warnings. | | | | 251m 12s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 69abc2152550 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 05144e7770fd55d4ed400b5ee8d71ea02d4d37b6 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/testReport/ | | Max. process+thread count | 3098 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/1/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-17T20:13:02.240+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3304428637 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 48s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 57m 20s | | trunk passed | | +1 :green_heart: | compile | 18m 0s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 26s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 19s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 43s | | trunk passed | | +1 :green_heart: | javadoc | 1m 18s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 53s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 36s | | trunk passed | | +1 :green_heart: | shadedclient | 43m 16s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 56s | | the patch passed | | +1 :green_heart: | compile | 16m 57s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 16m 57s | | the patch passed | | +1 :green_heart: | compile | 15m 17s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 17s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 14s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 38s | | the patch passed | | +1 :green_heart: | javadoc | 1m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 52s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 43s | | the patch passed | | -1 :x: | shadedclient | 42m 52s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 37s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 5s | | The patch does not generate ASF License warnings. | | | | 251m 40s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 2f758f82d727 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 4e384cfeaf21c2674e992b6ec288d9403a8d1adb | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/testReport/ | | Max. process+thread count | 2679 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/2/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-18T13:13:15.989+0000]: brumi1024 commented on code in PR #7979: URL: https://github.com/apache/hadoop/pull/7979#discussion_r2359223851 ########## hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java: ########## @@ -549,25 +550,50 @@ public HttpServer2 build() throws IOException { } for (URI ep : endpoints) { - final ServerConnector connector; + // + // To enable dual-stack or IPv6 support, use InetAddress + // .getAllByName(hostname) to resolve the IP addresses of a host. + // When the system property java.net.preferIPv4Stack is set to true, + // only IPv4 addresses are returned, and any IPv6 addresses are + // ignored, so no extra check is needed to exclude IPv6. + // When java.net.preferIPv4Stack is false, both IPv4 and IPv6 + // addresses may be returned, and any IPv6 addresses will also be + // added as connectors. + // To disable IPv4, you need to configure the OS at the system level. + // + InetAddress[] addresses = InetAddress.getAllByName(ep.getHost()); + server = addConnectors( + ep, addresses, server, httpConfig, backlogSize, idleTimeout); + } + server.loadListeners(); + return server; + } + + @VisibleForTesting + HttpServer2 addConnectors( + URI ep, InetAddress[] addresses, HttpServer2 server, + HttpConfiguration httpConfig, int backlogSize, int idleTimeout){ + for (InetAddress addr : addresses) { + ServerConnector connector; String scheme = ep.getScheme(); if (HTTP_SCHEME.equals(scheme)) { - connector = createHttpChannelConnector(server.webServer, - httpConfig); + connector = createHttpChannelConnector( + server.webServer, httpConfig); } else if (HTTPS_SCHEME.equals(scheme)) { - connector = createHttpsChannelConnector(server.webServer, - httpConfig); + connector = createHttpsChannelConnector( + server.webServer, httpConfig); } else { throw new HadoopIllegalArgumentException( \"unknown scheme for endpoint:\" + ep); } - connector.setHost(ep.getHost()); + LOG.info(\"Adding connector to WebServer for address {}\", Review Comment: Do we need info level for this? Debug might be enough.\n[ASF GitHub Bot @ 2025-09-18T14:58:00.773+0000]: ferdelyi commented on code in PR #7979: URL: https://github.com/apache/hadoop/pull/7979#discussion_r2359742305 ########## hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java: ########## @@ -549,25 +550,50 @@ public HttpServer2 build() throws IOException { } for (URI ep : endpoints) { - final ServerConnector connector; + // + // To enable dual-stack or IPv6 support, use InetAddress + // .getAllByName(hostname) to resolve the IP addresses of a host. + // When the system property java.net.preferIPv4Stack is set to true, + // only IPv4 addresses are returned, and any IPv6 addresses are + // ignored, so no extra check is needed to exclude IPv6. + // When java.net.preferIPv4Stack is false, both IPv4 and IPv6 + // addresses may be returned, and any IPv6 addresses will also be + // added as connectors. + // To disable IPv4, you need to configure the OS at the system level. + // + InetAddress[] addresses = InetAddress.getAllByName(ep.getHost()); + server = addConnectors( + ep, addresses, server, httpConfig, backlogSize, idleTimeout); + } + server.loadListeners(); + return server; + } + + @VisibleForTesting + HttpServer2 addConnectors( + URI ep, InetAddress[] addresses, HttpServer2 server, + HttpConfiguration httpConfig, int backlogSize, int idleTimeout){ + for (InetAddress addr : addresses) { + ServerConnector connector; String scheme = ep.getScheme(); if (HTTP_SCHEME.equals(scheme)) { - connector = createHttpChannelConnector(server.webServer, - httpConfig); + connector = createHttpChannelConnector( + server.webServer, httpConfig); } else if (HTTPS_SCHEME.equals(scheme)) { - connector = createHttpsChannelConnector(server.webServer, - httpConfig); + connector = createHttpsChannelConnector( + server.webServer, httpConfig); } else { throw new HadoopIllegalArgumentException( \"unknown scheme for endpoint:\" + ep); } - connector.setHost(ep.getHost()); + LOG.info(\"Adding connector to WebServer for address {}\", Review Comment: @brumi1024 thank you for your review! I've pushed a new commit with the suggested change.\n[ASF GitHub Bot @ 2025-09-18T19:07:10.599+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3309202536 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 57m 54s | | trunk passed | | +1 :green_heart: | compile | 17m 54s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 14s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 18s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 42s | | trunk passed | | +1 :green_heart: | javadoc | 1m 17s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 53s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 36s | | trunk passed | | +1 :green_heart: | shadedclient | 43m 42s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 58s | | the patch passed | | +1 :green_heart: | compile | 16m 55s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 16m 55s | | the patch passed | | +1 :green_heart: | compile | 15m 33s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 33s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 13s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 39s | | the patch passed | | +1 :green_heart: | javadoc | 1m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 52s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 45s | | the patch passed | | -1 :x: | shadedclient | 42m 49s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 40s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 5s | | The patch does not generate ASF License warnings. | | | | 253m 33s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux d2fb039015c7 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 792d7c033b10af7f44ef638aa249d7594e5f3bcd | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/testReport/ | | Max. process+thread count | 1273 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/3/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-22T14:22:14.066+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3319347658 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 22m 12s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 1s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 54m 26s | | trunk passed | | +1 :green_heart: | compile | 17m 55s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 16m 29s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 21s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 42s | | trunk passed | | +1 :green_heart: | javadoc | 1m 17s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 53s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 35s | | trunk passed | | +1 :green_heart: | shadedclient | 44m 9s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 58s | | the patch passed | | +1 :green_heart: | compile | 17m 4s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 4s | | the patch passed | | +1 :green_heart: | compile | 15m 33s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 33s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 15s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 41s | | the patch passed | | +1 :green_heart: | javadoc | 1m 14s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 52s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 48s | | the patch passed | | -1 :x: | shadedclient | 43m 28s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 23m 7s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 6s | | The patch does not generate ASF License warnings. | | | | 273m 25s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux b753ac7f62a8 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 7d394e5b895e03fa9e42057aa4ea2a74b3d0d034 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/testReport/ | | Max. process+thread count | 3098 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/4/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-23T14:11:46.510+0000]: ferdelyi commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3324196841 Earlier shadedclient failures: [ERROR] ITUseMiniCluster.clusterUp:78 Â» IO Problem starting http server Latest failure: ERROR: Failed to write github status. Token expired or missing repo:status write?\n[ASF GitHub Bot @ 2025-09-23T18:45:54.266+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3325156959 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 22m 16s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 57m 46s | | trunk passed | | +1 :green_heart: | compile | 18m 4s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 16m 24s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 19s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 43s | | trunk passed | | +1 :green_heart: | javadoc | 1m 19s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 54s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 35s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 52s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 57s | | the patch passed | | +1 :green_heart: | compile | 16m 59s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 16m 59s | | the patch passed | | +1 :green_heart: | compile | 15m 23s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 23s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 1m 13s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 41s | | the patch passed | | +1 :green_heart: | javadoc | 1m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 54s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 44s | | the patch passed | | -1 :x: | shadedclient | 42m 44s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 31s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 7s | | The patch does not generate ASF License warnings. | | | | 273m 56s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux afe6e7544141 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 48a180410434866489d88bb6cfda181f2bcc602d | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/testReport/ | | Max. process+thread count | 3100 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/5/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-25T13:13:37.358+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3333947403 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 59s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 53m 11s | | trunk passed | | +1 :green_heart: | compile | 18m 17s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 17m 43s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 1m 7s | | trunk passed | | +1 :green_heart: | mvnsite | 1m 50s | | trunk passed | | +1 :green_heart: | javadoc | 1m 23s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 56s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 55s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 38s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 58s | | the patch passed | | +1 :green_heart: | compile | 17m 14s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 14s | | the patch passed | | +1 :green_heart: | compile | 15m 19s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 19s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 56s | | the patch passed | | +1 :green_heart: | mvnsite | 1m 40s | | the patch passed | | +1 :green_heart: | javadoc | 1m 13s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 55s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 2m 45s | | the patch passed | | -1 :x: | shadedclient | 42m 1s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 35s | | hadoop-common in the patch passed. | | +1 :green_heart: | asflicense | 1m 4s | | The patch does not generate ASF License warnings. | | | | 248m 51s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 04cfc8fa6705 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 2b42d965a1cda228b2307bf26b0444c9b047d8c8 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/testReport/ | | Max. process+thread count | 1249 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/6/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-25T18:29:25.152+0000]: ferdelyi commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3335426490 shadedclient was failing on this: [INFO] Running org.apache.hadoop.example.ITUseMiniCluster [ERROR] Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 19.60 s <<< FAILURE!\n[ASF GitHub Bot @ 2025-09-26T03:37:41.630+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3336661768 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 1m 4s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 10m 37s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 47m 15s | | trunk passed | | +1 :green_heart: | compile | 18m 8s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 47s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 3m 8s | | trunk passed | | +1 :green_heart: | mvnsite | 3m 18s | | trunk passed | | +1 :green_heart: | javadoc | 2m 40s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 52s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 6m 3s | | trunk passed | | +1 :green_heart: | shadedclient | 43m 38s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 33s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 12s | | the patch passed | | +1 :green_heart: | compile | 17m 17s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 17s | | the patch passed | | +1 :green_heart: | compile | 15m 57s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 57s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 3m 6s | | the patch passed | | +1 :green_heart: | mvnsite | 3m 20s | | the patch passed | | +1 :green_heart: | javadoc | 2m 36s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 54s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 6m 22s | | the patch passed | | -1 :x: | shadedclient | 42m 14s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 39s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 276m 18s | | hadoop-hdfs in the patch passed. | | +1 :green_heart: | asflicense | 1m 20s | | The patch does not generate ASF License warnings. | | | | 552m 3s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux ed92b822cf7a 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 8aa88fc3e70c245050e33aab0a585dd5a9606340 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/testReport/ | | Max. process+thread count | 3098 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/7/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-26T12:29:59.857+0000]: ferdelyi commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3338485084 In the patch-shadedclient.txt the exception now is: Caused by: java.lang.IllegalStateException: Insufficient configured threads: required=5 < max=5 for QueuedThreadPool[qtp164052991]@9c73fff{STARTED,5<=5<=5,i=3,r=-1,q=0}[ReservedThreadExecutor@29be997f{reserved=0/1,pending=0}] I've increased HTTP_MAX_THREADS by one, and the required number of threads also increased by one. Just out of curiosity will puch e.g. 10 and see if it keeps increasing.\n[ASF GitHub Bot @ 2025-09-26T21:45:17.824+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3340611486 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 50s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 7m 44s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 47m 11s | | trunk passed | | +1 :green_heart: | compile | 18m 6s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 38s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 3m 14s | | trunk passed | | +1 :green_heart: | mvnsite | 3m 16s | | trunk passed | | +1 :green_heart: | javadoc | 2m 38s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 50s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 6m 0s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 47s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 35s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 11s | | the patch passed | | +1 :green_heart: | compile | 17m 6s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 6s | | the patch passed | | +1 :green_heart: | compile | 15m 23s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 23s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 3m 9s | | the patch passed | | +1 :green_heart: | mvnsite | 3m 16s | | the patch passed | | +1 :green_heart: | javadoc | 2m 35s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 47s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 6m 26s | | the patch passed | | +1 :green_heart: | shadedclient | 43m 6s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 42s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 278m 6s | | hadoop-hdfs in the patch passed. | | +1 :green_heart: | asflicense | 1m 21s | | The patch does not generate ASF License warnings. | | | | 549m 29s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 2ff86f039bb0 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / e14a395fa6450d1aeb2f0054197292b5af1540dc | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/testReport/ | | Max. process+thread count | 2198 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/8/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T08:17:39.726+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3375718964 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 30m 10s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 9m 52s | | Maven dependency ordering for branch | | -1 :x: | mvninstall | 45m 43s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 11m 43s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 10m 13s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 2m 58s | | trunk passed | | +1 :green_heart: | mvnsite | 2m 51s | | trunk passed | | +1 :green_heart: | javadoc | 2m 14s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 29s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 5m 35s | | trunk passed | | +1 :green_heart: | shadedclient | 42m 2s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 34s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 9s | | the patch passed | | -1 :x: | compile | 11m 28s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 11m 28s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 10m 9s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 10m 9s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 2m 49s | | the patch passed | | +1 :green_heart: | mvnsite | 2m 42s | | the patch passed | | +1 :green_heart: | javadoc | 2m 3s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 18s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 5m 51s | | the patch passed | | +1 :green_heart: | shadedclient | 42m 33s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 22s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 470m 28s | | hadoop-hdfs in the patch passed. | | +1 :green_heart: | asflicense | 0m 57s | | The patch does not generate ASF License warnings. | | | | 741m 16s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 83d811e5f434 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 8e2cd7f590381ff77458ec6a44f0d3b83779eb53 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/testReport/ | | Max. process+thread count | 2216 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/9/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-07T17:11:04.220+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3377795853 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 50s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 8m 32s | | Maven dependency ordering for branch | | -1 :x: | mvninstall | 46m 25s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-mvninstall-root.txt) | root in trunk failed. | | -1 :x: | compile | 11m 42s | [/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in trunk failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 59s | [/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in trunk failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | checkstyle | 2m 58s | | trunk passed | | +1 :green_heart: | mvnsite | 2m 52s | | trunk passed | | +1 :green_heart: | javadoc | 2m 12s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 23s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 5m 32s | | trunk passed | | +1 :green_heart: | shadedclient | 43m 36s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 36s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 29s | | the patch passed | | -1 :x: | compile | 11m 52s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 11m 52s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 9m 42s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 2m 45s | | the patch passed | | +1 :green_heart: | mvnsite | 2m 43s | | the patch passed | | +1 :green_heart: | javadoc | 2m 3s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 19s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 5m 52s | | the patch passed | | +1 :green_heart: | shadedclient | 42m 51s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 25s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 279m 19s | | hadoop-hdfs in the patch passed. | | +1 :green_heart: | asflicense | 0m 54s | | The patch does not generate ASF License warnings. | | | | 521m 50s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux d9d0c21591bb 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 7adcb39cbe58f85adc3d03fa0ad751c64b87624e | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/testReport/ | | Max. process+thread count | 3098 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/10/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-09T17:48:48.839+0000]: hadoop-yetus commented on PR #7979: URL: https://github.com/apache/hadoop/pull/7979#issuecomment-3386925666 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 21m 36s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 8m 2s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 41m 3s | | trunk passed | | +1 :green_heart: | compile | 15m 50s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 13m 55s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 2m 53s | | trunk passed | | +1 :green_heart: | mvnsite | 3m 21s | | trunk passed | | +1 :green_heart: | javadoc | 2m 33s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 53s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 5m 55s | | trunk passed | | +1 :green_heart: | shadedclient | 37m 1s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 34s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 9s | | the patch passed | | +1 :green_heart: | compile | 15m 24s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 24s | | the patch passed | | +1 :green_heart: | compile | 13m 45s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 13m 45s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 2m 49s | | the patch passed | | +1 :green_heart: | mvnsite | 3m 17s | | the patch passed | | +1 :green_heart: | javadoc | 2m 34s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 2m 51s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 6m 16s | | the patch passed | | +1 :green_heart: | shadedclient | 38m 43s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 22m 50s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 289m 16s | | hadoop-hdfs in the patch passed. | | +1 :green_heart: | asflicense | 1m 19s | | The patch does not generate ASF License warnings. | | | | 557m 31s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7979 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 22968369ed69 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 87e9944f809d56e1c99a5ff5138c93377e99f464 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/testReport/ | | Max. process+thread count | 3152 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7979/12/console | | versions | git=2.25.1 maven=3.9.11 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-10-13T08:46:17.170+0000]: brumi1024 merged PR #7979: URL: https://github.com/apache/hadoop/pull/7979","key":"HADOOP-19695","status":"Resolved","labels":"pull-request-available"}
{"summary":"Bump guava to  33.4.8-jre due to EOL","created":"2025-09-17T11:01:22.000+0000","description":"We can use the latest 33.4.8-jre version as the current one is quite old.","assignee":"Rohit Kumar","priority":"Major","updated":"2025-10-20T16:41:38.000+0000","commentText":"[Steve Loughran @ 2025-09-22T13:37:32.907+0000]: When I do a thirdparty build I now get a warning of duplicate module 9 info. {code} [INFO] No artifact matching filter org.checkerframework:checker-qual [WARNING] error_prone_annotations-2.36.0.jar, guava-33.4.8-jre.jar, failureaccess-1.0.3.jar, jspecify-1.0.0.jar, j2objc-annotations-3.0.0.jar define 1 overlapping classes: [WARNING] - META-INF.versions.9.module-info [WARNING] maven-shade-plugin has detected that some class files are [WARNING] present in two or more JARs. When this happens, only one [WARNING] single version of the class is copied to the uber jar. [WARNING] Usually this is not harmful and you can skip these warnings, [WARNING] otherwise try to manually exclude artifacts based on [WARNING] mvn dependency:tree -Ddetail=true and the above output. [WARNING] See http://maven.apache.org/plugins/maven-shade-plugin/ {code} This is new. given we want this to work on java17+ , we need to come up with a way of resolving the conflict, at the very least by making the guava one dominant.\n[Steve Loughran @ 2025-10-20T16:41:38.036+0000]: ahh, the later versions of guava exclude a dependency on checkerframework. So any references in our code (there are four) fail. Which means we have to manually add it if we want a drop in replacement. PITA.","key":"HADOOP-19694","status":"Resolved","labels":"pull-request-available"}
{"summary":"Update Java 24 to 25 in docker images","created":"2025-09-17T07:57:36.000+0000","description":"Temurin JDK25 packages are expected to be available shortly, update JDK 24 to 25 in the docker images.","assignee":"Istvan Toth","priority":"Major","updated":"2025-10-06T00:33:24.000+0000","commentText":"[Istvan Toth @ 2025-09-23T05:58:19.929+0000]: The ubuntu packages have been released.\n[ASF GitHub Bot @ 2025-09-23T06:21:48.009+0000]: stoty opened a new pull request, #7991: URL: https://github.com/apache/hadoop/pull/7991 ### Description of PR Update Java 24 to 25 in docker images ### How was this patch tested? Built ubuntu_20 and ubuntu_24 x64 images, and ran java 25 in them. ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-23T07:10:50.258+0000]: stoty commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3322708226 PTAL @slfan1989\n[ASF GitHub Bot @ 2025-09-23T08:33:12.973+0000]: hadoop-yetus commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3322950127 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 31m 53s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 10m 51s | | Maven dependency ordering for branch | | +1 :green_heart: | shadedclient | 53m 17s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 46s | | Maven dependency ordering for patch | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 41m 20s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 58s | | The patch does not generate ASF License warnings. | | | | 130m 13s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7991 | | Optional Tests | dupname asflicense codespell detsecrets jsonlint | | uname | Linux 7aa6647a89a6 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / edaa6e0885eeb0c0db357ef86e5defa0dfcc28d8 | | Max. process+thread count | 525 (vs. ulimit of 5500) | | modules | C: U: | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/console | | versions | git=2.43.7 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-23T09:43:23.005+0000]: hadoop-yetus commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3323181520 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 27m 28s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 0m 27s | | Maven dependency ordering for branch | | -1 :x: | shadedclient | 8m 53s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 24s | | Maven dependency ordering for patch | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 31m 4s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 32s | | The patch does not generate ASF License warnings. | | | | 70m 0s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7991 | | Optional Tests | dupname asflicense codespell detsecrets jsonlint | | uname | Linux 242b70b5bd76 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / edaa6e0885eeb0c0db357ef86e5defa0dfcc28d8 | | Max. process+thread count | 538 (vs. ulimit of 5500) | | modules | C: U: | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7991/1/console | | versions | git=2.30.2 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-25T06:49:56.855+0000]: slfan1989 commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3332430073 @pan3793 Could you please review this PR? Thank you very much! Pan has some experience with higher versions of JDK.\n[ASF GitHub Bot @ 2025-09-25T07:19:36.547+0000]: stoty commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3332517143 Not much to review here @slfan1989 . This is just the first step to being able to test with JDK25. TBH I don't see much value in supporting or testing for JDK24, the real goal is JDK25, the stable release. Generally, I would test with the supported stable Java releases, plus the latest supported non-stable Java release. i.e when JDK 26 is released it, then keep Java 25 and add Java 26, then keep replacing Java 26 with 27,28,29,29... until the next stable Java is released (with the optimistic assumption that Hadoop is going to keep up with the non-stable Java releases, and we won't have to do any more big bang updates for 10+ java releases)\n[ASF GitHub Bot @ 2025-10-06T00:32:07.196+0000]: slfan1989 merged PR #7991: URL: https://github.com/apache/hadoop/pull/7991\n[ASF GitHub Bot @ 2025-10-06T00:33:24.204+0000]: slfan1989 commented on PR #7991: URL: https://github.com/apache/hadoop/pull/7991#issuecomment-3369570388 @stoty Thanks for the contribution!","key":"HADOOP-19693","status":"Resolved","labels":"Java25|pull-request-available"}
{"summary":"Exclude junit 4 transitive dependency","created":"2025-09-16T18:18:40.000+0000","description":"HADOOP-19617 removed direct junit 4 dependency.  However, junit 4 is still pulled transitively by other dependencies.","assignee":"Tsz-wo Sze","priority":"Major","updated":"2025-09-19T17:06:35.000+0000","commentText":"[Tsz-wo Sze @ 2025-09-16T18:19:00.169+0000]: {code} [INFO] ------------------< org.apache.hadoop:hadoop-common >------------------- [INFO] Building Apache Hadoop Common 3.5.0-SNAPSHOT [11/117] [INFO] from hadoop-common-project/hadoop-common/pom.xml ... [INFO] +- com.squareup.okhttp3:mockwebserver:jar:4.11.0:test [INFO] | +- com.squareup.okhttp3:okhttp:jar:4.11.0:test [INFO] | | \\- com.squareup.okio:okio:jar:3.2.0:test [INFO] | | \\- com.squareup.okio:okio-jvm:jar:3.2.0:test [INFO] | \\- junit:junit:jar:4.13:test [INFO] | \\- org.hamcrest:hamcrest-core:jar:1.3:test {code}\n[Tsz-wo Sze @ 2025-09-16T18:19:28.685+0000]: {code} [INFO] ----------------< org.apache.hadoop:hadoop-hdfs-httpfs >---------------- [INFO] Building Apache Hadoop HttpFS 3.5.0-SNAPSHOT [19/117] [INFO] from hadoop-hdfs-project/hadoop-hdfs-httpfs/pom.xml ... [INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile [INFO] | Â \\- junit:junit:jar:4.10:compile {code}\n[Tsz-wo Sze @ 2025-09-16T18:20:02.222+0000]: {code} [INFO] -----< org.apache.hadoop:hadoop-yarn-applications-catalog-webapp >------ [INFO] Building Apache Hadoop YARN Application Catalog Webapp 3.5.0-SNAPSHOT [63/117] [INFO] from hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/pom.xml ... [INFO] +- org.apache.solr:solr-test-framework:jar:8.11.2:test [INFO] | +- org.apache.lucene:lucene-test-framework:jar:8.11.2:test [INFO] | +- com.carrotsearch.randomizedtesting:junit4-ant:jar:2.7.2:test [INFO] | +- com.carrotsearch.randomizedtesting:randomizedtesting-runner:jar:2.7.2:test [INFO] | +- io.opentracing:opentracing-mock:jar:0.33.0:test [INFO] | +- junit:junit:jar:4.13.1:test {code}\n[Tsz-wo Sze @ 2025-09-16T18:21:02.034+0000]: {code} [INFO] --< org.apache.hadoop.applications.mawo:hadoop-yarn-applications-mawo >-- [INFO] Building Apache Hadoop YARN Application MaWo 3.5.0-SNAPSHOT [65/117] [INFO] from hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/pom.xml ... [INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile [INFO] | \\- junit:junit:jar:4.10:compile [INFO] | \\- org.hamcrest:hamcrest-core:jar:1.1:compile {code}\n[ASF GitHub Bot @ 2025-09-16T18:37:14.755+0000]: szetszwo opened a new pull request, #7978: URL: https://github.com/apache/hadoop/pull/7978 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR HADOOP-19692 The direct junit 4 dependency was removed by HADOOP-19617. However, junit 4 is still pulled transitively by other dependencies. ### How was this patch tested? By the pull request action. ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [NA] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [NA] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [NA] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-16T22:21:25.871+0000]: hadoop-yetus commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300529165 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 49s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 1s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 12m 11s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 47m 40s | | trunk passed | | +1 :green_heart: | compile | 17m 49s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 15s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 4m 53s | | trunk passed | | +1 :green_heart: | javadoc | 3m 58s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 3m 26s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 146m 52s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 33s | | Maven dependency ordering for patch | | -1 :x: | mvninstall | 0m 53s | [/patch-mvninstall-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-common.txt) | hadoop-common in the patch failed. | | -1 :x: | compile | 1m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | javac | 1m 23s | [/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkUbuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04.txt) | root in the patch failed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04. | | -1 :x: | compile | 1m 13s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | -1 :x: | javac | 1m 13s | [/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09.txt) | root in the patch failed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09. | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -1 :x: | mvnsite | 0m 59s | [/patch-mvnsite-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt) | hadoop-common in the patch failed. | | +1 :green_heart: | javadoc | 2m 9s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 1m 42s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 10m 7s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 14s | | hadoop-project in the patch passed. | | -1 :x: | unit | 0m 59s | [/patch-unit-hadoop-common-project_hadoop-common.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt) | hadoop-common in the patch failed. | | +1 :green_heart: | unit | 5m 32s | | hadoop-hdfs-httpfs in the patch passed. | | -1 :x: | unit | 0m 48s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) | hadoop-yarn-applications-catalog-webapp in the patch passed. | | +1 :green_heart: | unit | 0m 20s | | hadoop-yarn-applications-mawo-core in the patch passed. | | +1 :green_heart: | asflicense | 0m 32s | | The patch does not generate ASF License warnings. | | | | 173m 47s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7978 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux b2d417db0dc5 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 613024d63ccccb96c39f1fab428aa1356b68d2d4 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/testReport/ | | Max. process+thread count | 863 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/2/console | | versions | git=2.25.1 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-16T22:59:45.653+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300605779 It turns out that we have not completely removed junit tests. ``` ERROR] /home/jenkins/jenkins-agent/workspace/hadoop-multibranch_PR-7978/ubuntu-focal/src/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/http/TestHttpFileSystem.java:[57,5] cannot access org.junit.rules.ExternalResource class file for org.junit.rules.ExternalResource not found ```\n[ASF GitHub Bot @ 2025-09-16T23:51:07.450+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3300697473 > ... we have not completely removed junit tests. The reason is that `mockwebserver` uses junit 4. We should replace it with `mockwebserver3-junit5`.\n[ASF GitHub Bot @ 2025-09-17T04:54:45.219+0000]: hadoop-yetus commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3301302828 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 49s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 10m 57s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 49m 40s | | trunk passed | | +1 :green_heart: | compile | 17m 59s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 25s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 4m 44s | | trunk passed | | +1 :green_heart: | mvnsite | 4m 53s | | trunk passed | | +1 :green_heart: | javadoc | 3m 54s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 3m 27s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +0 :ok: | spotbugs | 0m 41s | | branch/hadoop-project no spotbugs output file (spotbugsXml.xml) | | +1 :green_heart: | shadedclient | 41m 5s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 39s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 31s | | the patch passed | | +1 :green_heart: | compile | 17m 9s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 9s | | the patch passed | | +1 :green_heart: | compile | 15m 21s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 21s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 4m 32s | | the patch passed | | +1 :green_heart: | mvnsite | 4m 50s | | the patch passed | | +1 :green_heart: | javadoc | 3m 55s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 3m 27s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +0 :ok: | spotbugs | 0m 35s | | hadoop-project has no data from spotbugs | | +1 :green_heart: | shadedclient | 41m 57s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 36s | | hadoop-project in the patch passed. | | +1 :green_heart: | unit | 22m 35s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 5m 55s | | hadoop-hdfs-httpfs in the patch passed. | | -1 :x: | unit | 1m 10s | [/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-catalog_hadoop-yarn-applications-catalog-webapp.txt) | hadoop-yarn-applications-catalog-webapp in the patch passed. | | +1 :green_heart: | unit | 0m 42s | | hadoop-yarn-applications-mawo-core in the patch passed. | | +1 :green_heart: | asflicense | 1m 7s | | The patch does not generate ASF License warnings. | | | | 298m 25s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7978 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle | | uname | Linux 19a387ca4ff9 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 715044a0192f83d7661d00e9ede87d1067004e52 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/testReport/ | | Max. process+thread count | 1294 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/3/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-17T18:30:45.885+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304127134 ``` [ERROR] org.apache.hadoop.yarn.appcatalog.application.TestAppCatalogSolrClient.testNotFoundSearch\n[ASF GitHub Bot @ 2025-09-17T23:30:39.223+0000]: hadoop-yetus commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304842636 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 48s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 11m 52s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 48m 8s | | trunk passed | | +1 :green_heart: | compile | 17m 56s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 19s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 4m 41s | | trunk passed | | +1 :green_heart: | mvnsite | 4m 49s | | trunk passed | | +1 :green_heart: | javadoc | 3m 58s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 3m 26s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +0 :ok: | spotbugs | 0m 42s | | branch/hadoop-project no spotbugs output file (spotbugsXml.xml) | | +1 :green_heart: | shadedclient | 41m 30s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 37s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 2m 34s | | the patch passed | | +1 :green_heart: | compile | 16m 58s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 16m 58s | | the patch passed | | +1 :green_heart: | compile | 15m 14s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 14s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 4m 37s | | the patch passed | | +1 :green_heart: | mvnsite | 4m 51s | | the patch passed | | +1 :green_heart: | javadoc | 3m 56s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 3m 27s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +0 :ok: | spotbugs | 0m 37s | | hadoop-project has no data from spotbugs | | +1 :green_heart: | shadedclient | 41m 8s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 0m 36s | | hadoop-project in the patch passed. | | +1 :green_heart: | unit | 22m 38s | | hadoop-common in the patch passed. | | +1 :green_heart: | unit | 5m 54s | | hadoop-hdfs-httpfs in the patch passed. | | +1 :green_heart: | unit | 1m 15s | | hadoop-yarn-applications-catalog-webapp in the patch passed. | | +1 :green_heart: | unit | 0m 42s | | hadoop-yarn-applications-mawo-core in the patch passed. | | +1 :green_heart: | asflicense | 1m 6s | | The patch does not generate ASF License warnings. | | | | 297m 9s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7978 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle | | uname | Linux ded193a6470d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 90ed7ecdaeec392fff06e28edc555a5420794f66 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/testReport/ | | Max. process+thread count | 2987 (vs. ulimit of 5500) | | modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-httpfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-mawo/hadoop-yarn-applications-mawo-core U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7978/4/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-17T23:41:11.650+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3304863270 > The junit 4 Assert is in LuceneTestCase. Not sure if updating the solr-test-framework version 8.11.2 could fix it. The current code in LuceneTestCase still use JUnit 4. https://github.com/apache/lucene/blob/13a7e1e53d0e69233e775f2fb241b86c3ac0e527/lucene/test-framework/src/java/org/apache/lucene/tests/util/LuceneTestCase.java#L202C1-L217C3\n[ASF GitHub Bot @ 2025-09-18T16:36:42.876+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3308469834 Filed HADOOP-19699 for TestAppCatalogSolrClient\n[ASF GitHub Bot @ 2025-09-18T16:39:11.824+0000]: szetszwo merged PR #7978: URL: https://github.com/apache/hadoop/pull/7978\n[ASF GitHub Bot @ 2025-09-18T16:39:49.502+0000]: szetszwo commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3308483383 Thanks @cnauroth and @slfan1989 for reviewing this!\n[Tsz-wo Sze @ 2025-09-18T16:40:48.592+0000]: The pull request was merged.\n[ASF GitHub Bot @ 2025-09-19T00:56:57.538+0000]: slfan1989 commented on PR #7978: URL: https://github.com/apache/hadoop/pull/7978#issuecomment-3310127385 > Thanks @cnauroth and @slfan1989 for reviewing this! @szetszwo Thank you for the contribution!","key":"HADOOP-19692","status":"Resolved","labels":"pull-request-available"}
{"summary":"[JDK17] Disallow JUnit4 Imports After JUnit5 Migration","created":"2025-09-16T03:05:49.000+0000","description":"As our project has fully migrated to JUnit5, we should now enforce a rule that prevents the import and usage of JUnit4 classes (such as org.junit.Test, org.junit.Assert, etc.) to ensure consistency, avoid regressions, and allow safe removal of legacy dependencies.\r\n\r\nThis task involves identifying and eliminating any remaining JUnit4 imports, and introducing static code analysis or linting rules to ban future usage.","assignee":"Shilun Fan","priority":"Major","updated":"2025-09-24T22:13:59.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-16T11:07:34.654+0000]: slfan1989 commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3297850797 @TaoYang526 We are currently working on upgrading the project to JUnit 5, and I have added a validation rule to prevent users from reintroducing JUnit 4 dependencies. During the review, I found that the testAsyncScheduleThreadExit method used JUnit 4 features, so I made some modifications. Could you please take a look and let me know if the changes are reasonable?\n[ASF GitHub Bot @ 2025-09-16T19:43:10.302+0000]: hadoop-yetus commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3300118538 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 52s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 10m 33s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 47m 14s | | trunk passed | | +1 :green_heart: | compile | 17m 57s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 16s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 4m 40s | | trunk passed | | +1 :green_heart: | mvnsite | 23m 18s | | trunk passed | | +1 :green_heart: | javadoc | 10m 32s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 51s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 36m 56s | | trunk passed | | +1 :green_heart: | shadedclient | 73m 12s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 45s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 48m 15s | | the patch passed | | +1 :green_heart: | compile | 17m 20s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 20s | | the patch passed | | +1 :green_heart: | compile | 15m 29s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 29s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 4m 42s | | the patch passed | | +1 :green_heart: | mvnsite | 19m 33s | | the patch passed | | +1 :green_heart: | javadoc | 10m 25s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 47s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 37m 40s | | the patch passed | | +1 :green_heart: | shadedclient | 73m 40s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 503m 15s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 2m 21s | | The patch does not generate ASF License warnings. | | | | 930m 38s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7976 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint | | uname | Linux 946810b75b42 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 78ed6e9e068b8c35d3eb372e09440128bf4fd0d8 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/testReport/ | | Max. process+thread count | 3137 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/1/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-17T02:28:30.566+0000]: slfan1989 commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3300985791 > +1. Thanks @slfan1989 . > > I was going to suggest also banning `org.hamcrest`, but it looks like there is still a tiny amount of hamcrest remaining in YARN. Maybe this is a topic for a different PR. > > ``` > > grep -r --include '*.java' 'org.hamcrest' * > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppListControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppListControllerTest.java:import static org.hamcrest.core.Is.is; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppDetailsControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppDetailsControllerTest.java:import static org.hamcrest.core.Is.is; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppStoreControllerTest.java:import static org.hamcrest.MatcherAssert.assertThat; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/test/java/org/apache/hadoop/yarn/appcatalog/controller/AppStoreControllerTest.java:import static org.hamcrest.core.Is.is; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.MatcherAssert.assertThat; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.core.IsInstanceOf.instanceOf; > hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestResourceCalculatorProcessTree.java:import static org.hamcrest.core.IsSame.sameInstance; > ``` @cnauroth Thank you for reviewing the code! I\u2019ll submit a separate PR to replace the usage of `org.hamcrest.`.\n[ASF GitHub Bot @ 2025-09-19T16:33:26.654+0000]: hadoop-yetus commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3312878887 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 55s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 1s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 11m 55s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 47m 48s | | trunk passed | | +1 :green_heart: | compile | 18m 6s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 15s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 4m 40s | | trunk passed | | +1 :green_heart: | mvnsite | 23m 14s | | trunk passed | | +1 :green_heart: | javadoc | 10m 19s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 43s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 36m 53s | | trunk passed | | +1 :green_heart: | shadedclient | 72m 58s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 45s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 48m 31s | | the patch passed | | +1 :green_heart: | compile | 17m 26s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 26s | | the patch passed | | +1 :green_heart: | compile | 15m 16s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 16s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 4m 46s | | the patch passed | | +1 :green_heart: | mvnsite | 20m 6s | | the patch passed | | +1 :green_heart: | javadoc | 10m 22s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 54s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 37m 38s | | the patch passed | | +1 :green_heart: | shadedclient | 73m 1s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 509m 47s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 1m 26s | | The patch does not generate ASF License warnings. | | | | 937m 20s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7976 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets xmllint | | uname | Linux b7280a78b909 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / b0d0b609f7714de5a35a2e356b8eca12903f5d3b | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/testReport/ | | Max. process+thread count | 2676 (vs. ulimit of 5500) | | modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/2/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-24T14:14:18.338+0000]: hadoop-yetus commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3328740044 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 22m 34s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 1s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 54m 10s | | trunk passed | | +1 :green_heart: | compile | 18m 17s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 16m 7s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 22m 48s | | trunk passed | | +1 :green_heart: | javadoc | 9m 45s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 25s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 130m 22s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 45m 37s | | the patch passed | | +1 :green_heart: | compile | 17m 35s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 35s | | the patch passed | | +1 :green_heart: | compile | 15m 28s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 28s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 19m 34s | | the patch passed | | +1 :green_heart: | javadoc | 9m 43s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 32s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 39m 36s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 503m 30s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 1m 16s | | The patch does not generate ASF License warnings. | | | | 778m 24s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7976 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 0b5b9083f652 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / c161c9b215d2498c3c9a2d060a0be1701444b768 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/testReport/ | | Max. process+thread count | 3135 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/4/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-24T14:44:13.881+0000]: hadoop-yetus commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3328991107 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 21m 40s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 54m 49s | | trunk passed | | +1 :green_heart: | compile | 18m 9s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 15m 13s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 23m 19s | | trunk passed | | +1 :green_heart: | javadoc | 9m 49s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 26s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 130m 34s | | branch has errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 47m 25s | | the patch passed | | +1 :green_heart: | compile | 17m 24s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 24s | | the patch passed | | +1 :green_heart: | compile | 15m 31s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 15m 31s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 19m 40s | | the patch passed | | +1 :green_heart: | javadoc | 9m 46s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 28s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | -1 :x: | shadedclient | 39m 49s | | patch has errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 538m 55s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/artifact/out/patch-unit-root.txt) | root in the patch failed. | | +1 :green_heart: | asflicense | 1m 47s | | The patch does not generate ASF License warnings. | | | | 815m 59s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.hdfs.TestRollingUpgrade | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7976 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint | | uname | Linux 8c48d2e66c3e 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / c161c9b215d2498c3c9a2d060a0be1701444b768 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/testReport/ | | Max. process+thread count | 3137 (vs. ulimit of 5500) | | modules | C: . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7976/3/console | | versions | git=2.25.1 maven=3.9.11 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-24T22:12:21.757+0000]: slfan1989 commented on PR #7976: URL: https://github.com/apache/hadoop/pull/7976#issuecomment-3330876058 This PR enforces import restrictions to prohibit the use of JUnit4. The previously reported shade error has already been resolved in #7995. Given the lengthy compilation time, I will not re-trigger the build for this PR. I will continue to investigate and address the YARN crash issue separately. @cnauroth Thanks for the review!\n[ASF GitHub Bot @ 2025-09-24T22:13:26.101+0000]: slfan1989 merged PR #7976: URL: https://github.com/apache/hadoop/pull/7976","key":"HADOOP-19691","status":"Resolved","labels":"pull-request-available"}
{"summary":"Bump commons-lang3 to 3.18.0 due to CVE-2025-48924","created":"2025-09-15T17:53:25.000+0000","description":"https://www.cve.org/CVERecord?id=CVE-2025-48924\r\n\r\nWill update commons-text to 1.14.0 which was released with commons-lang3 3.18.0. Due to https://issues.apache.org/jira/browse/HADOOP-19532 - seems best to upgrade them together.  ","assignee":"PJ Fanning","priority":"Major","updated":"2025-09-23T05:30:25.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-15T18:01:43.048+0000]: pjfanning opened a new pull request, #7970: URL: https://github.com/apache/hadoop/pull/7970 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR CVE-2025-48924 See https://issues.apache.org/jira/browse/HADOOP-19690 for reason to upgrade commons-text too. ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-18T04:48:34.065+0000]: hadoop-yetus commented on PR #7970: URL: https://github.com/apache/hadoop/pull/7970#issuecomment-3305413646 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 22s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 9m 19s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 24m 23s | | trunk passed | | +1 :green_heart: | compile | 8m 23s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 7m 20s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 14m 9s | | trunk passed | | +1 :green_heart: | javadoc | 5m 34s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 4m 58s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 31m 4s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 23s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 22m 56s | | the patch passed | | +1 :green_heart: | compile | 8m 11s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 8m 11s | | the patch passed | | +1 :green_heart: | compile | 7m 26s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 7m 26s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 11m 38s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 5m 29s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 5m 6s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 32m 0s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 963m 33s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 4s | | The patch does not generate ASF License warnings. | | | | 1144m 26s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.yarn.server.router.subcluster.fair.TestYarnFederationWithFairScheduler | | | hadoop.yarn.server.router.webapp.TestFederationWebApp | | | hadoop.yarn.server.router.webapp.TestRouterWebServicesREST | | | hadoop.mapreduce.v2.TestUberAM | | | hadoop.yarn.sls.appmaster.TestAMSimulator | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7970 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs | | uname | Linux e242a07f343d 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 82dae1282632826d8977c56821441f5b32ee1ec8 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/testReport/ | | Max. process+thread count | 4334 (vs. ulimit of 5500) | | modules | C: hadoop-project . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7970/2/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-19T00:43:30.894+0000]: slfan1989 merged PR #7970: URL: https://github.com/apache/hadoop/pull/7970\n[ASF GitHub Bot @ 2025-09-19T00:48:07.373+0000]: slfan1989 commented on PR #7970: URL: https://github.com/apache/hadoop/pull/7970#issuecomment-3310116432 @pjfanning Thanks for the contribution! The unit test errors are unrelated to this PR. Could you please take a look at the branch-3.4? I think this PR should also be backported there.\n[ASF GitHub Bot @ 2025-09-19T08:51:01.996+0000]: pjfanning opened a new pull request, #7985: URL: https://github.com/apache/hadoop/pull/7985 * relates to #7970 * HADOOP-19690. bump commons-lang3 to 3.18.0 due to CVE-2025-48924 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-19T12:10:13.990+0000]: hadoop-yetus commented on PR #7985: URL: https://github.com/apache/hadoop/pull/7985#issuecomment-3311953658 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 7m 12s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ branch-3.4 Compile Tests _ | | +0 :ok: | mvndep | 2m 18s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 22m 13s | | branch-3.4 passed | | +1 :green_heart: | compile | 8m 32s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 7m 43s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 13m 58s | | branch-3.4 passed | | +1 :green_heart: | javadoc | 4m 40s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 4m 52s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 28m 7s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 21s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 20m 8s | | the patch passed | | +1 :green_heart: | compile | 8m 42s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 8m 42s | | the patch passed | | +1 :green_heart: | compile | 7m 47s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 7m 47s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 8m 21s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 4m 44s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 4m 54s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 34m 4s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 25m 52s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/patch-unit-root.txt) | root in the patch failed. | | -1 :x: | asflicense | 0m 19s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/results-asflicense.txt) | The patch generated 296 ASF License warnings. | | | | 197m 56s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.metrics2.source.TestJvmMetrics | | | hadoop.ipc.TestCallQueueManager | | | hadoop.fs.shell.TestHdfsTextCommand | | | hadoop.hdfs.util.TestByteArrayManager | | | hadoop.hdfs.web.TestWebHDFSOAuth2 | | | hadoop.hdfs.web.TestWebHdfsContentLength | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7985 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs | | uname | Linux 71fdfc267120 5.15.0-142-generic #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | branch-3.4 / fa8656b628557693f6cd66800a5d84bebd80501c | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/testReport/ | | Max. process+thread count | 685 (vs. ulimit of 5500) | | modules | C: hadoop-project . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7985/1/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-23T05:30:03.160+0000]: slfan1989 merged PR #7985: URL: https://github.com/apache/hadoop/pull/7985\n[ASF GitHub Bot @ 2025-09-23T05:30:25.482+0000]: slfan1989 commented on PR #7985: URL: https://github.com/apache/hadoop/pull/7985#issuecomment-3322481127 @pjfanning Thanks for the contribution! Merged into branch-3.4.","key":"HADOOP-19690","status":"Resolved","labels":"pull-request-available"}
{"summary":"Bump netty to 4.1.127 due to CVE-2025-58057","created":"2025-09-15T17:45:00.000+0000","description":"https://www.cve.org/CVERecord?id=CVE-2025-58057\r\n\r\nfixed in 4.1.125 but no harm upgrading to latest","assignee":"PJ Fanning","priority":"Major","updated":"2025-09-23T05:31:15.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-15T17:50:24.562+0000]: pjfanning opened a new pull request, #7969: URL: https://github.com/apache/hadoop/pull/7969 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR Upgrade netty due to CVE-2025-58057 ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-19T00:52:13.917+0000]: slfan1989 merged PR #7969: URL: https://github.com/apache/hadoop/pull/7969\n[ASF GitHub Bot @ 2025-09-19T00:53:10.166+0000]: slfan1989 commented on PR #7969: URL: https://github.com/apache/hadoop/pull/7969#issuecomment-3310122835 @pjfanning Thanks for the contribution! Merged into trunk. The branch-3.4 should also be taken into consideration.\n[ASF GitHub Bot @ 2025-09-19T08:45:46.127+0000]: pjfanning opened a new pull request, #7984: URL: https://github.com/apache/hadoop/pull/7984 * HADOOP-19689: bump netty to 4.1.127.Final due to CVE-2025-58057 Signed-off-by: Shilun Fan <slfan1989@apache.org> Update LICENSE-binary <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR ### How was this patch tested? ### For code changes: - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-20T02:17:12.897+0000]: hadoop-yetus commented on PR #7984: URL: https://github.com/apache/hadoop/pull/7984#issuecomment-3314414435 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 13m 42s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | xmllint | 0m 0s | | xmllint was not available. | | +0 :ok: | shelldocs | 0m 0s | | Shelldocs was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | -1 :x: | test4tests | 0m 0s | | The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. | |||| _ branch-3.4 Compile Tests _ | | +0 :ok: | mvndep | 2m 19s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 38m 3s | | branch-3.4 passed | | +1 :green_heart: | compile | 19m 9s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 17m 20s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | mvnsite | 23m 6s | | branch-3.4 passed | | +1 :green_heart: | javadoc | 8m 58s | | branch-3.4 passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 8m 19s | | branch-3.4 passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 54m 54s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 38s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 32m 36s | | the patch passed | | +1 :green_heart: | compile | 17m 43s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 17m 43s | | the patch passed | | +1 :green_heart: | compile | 16m 20s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 16m 20s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | mvnsite | 18m 39s | | the patch passed | | +1 :green_heart: | shellcheck | 0m 0s | | No new issues. | | +1 :green_heart: | javadoc | 8m 22s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 7m 52s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | shadedclient | 51m 4s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | -1 :x: | unit | 738m 57s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/artifact/out/patch-unit-root.txt) | root in the patch passed. | | +1 :green_heart: | asflicense | 1m 37s | | The patch does not generate ASF License warnings. | | | | 1050m 3s | | | | Reason | Tests | |-------:|:------| | Failed junit tests | hadoop.mapred.gridmix.TestGridmixSubmission | | | hadoop.mapred.gridmix.TestLoadJob | | | hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2 | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7984 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint shellcheck shelldocs | | uname | Linux df829c2020d7 5.15.0-144-generic #157-Ubuntu SMP Mon Jun 16 07:33:10 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | branch-3.4 / 80ba81ead32289cc5ee5aceb75950ca4e5a9c50e | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/testReport/ | | Max. process+thread count | 3744 (vs. ulimit of 5500) | | modules | C: hadoop-project . U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7984/1/console | | versions | git=2.25.1 maven=3.6.3 shellcheck=0.7.0 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-23T05:30:51.172+0000]: slfan1989 merged PR #7984: URL: https://github.com/apache/hadoop/pull/7984\n[ASF GitHub Bot @ 2025-09-23T05:31:15.256+0000]: slfan1989 commented on PR #7984: URL: https://github.com/apache/hadoop/pull/7984#issuecomment-3322482594 @pjfanning Thanks for the contribution! Merged into branch-3.4.","key":"HADOOP-19689","status":"Resolved","labels":"pull-request-available"}
{"summary":"S3A: ITestS3ACommitterMRJob failing on Junit5","created":"2025-09-15T17:38:39.000+0000","description":"NPE in test200 of ITestS3ACommitterMRJob.\r\n\r\nCause is\r\n* test dir setup and propagation calls Path.getRoot().toUri() which returns the /home dir\r\n* somehow the locatedFileStatus of that path being 1 so a codepath in FileInputFormat NPEs.\r\n\r\nFix is in test code, though FileInputFormat has its NPE messages improved to help understand what is going wrong. ","assignee":"Steve Loughran","priority":"Major","updated":"2025-09-16T12:05:03.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-15T17:45:04.356+0000]: steveloughran opened a new pull request, #7968: URL: https://github.com/apache/hadoop/pull/7968 Adds extra logging as to what is happening, passes in actual test dir set at class level. ### How was this patch tested? s3 london ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [X] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-15T17:46:02.551+0000]: steveloughran commented on PR #7968: URL: https://github.com/apache/hadoop/pull/7968#issuecomment-3293282933 ``` [INFO] Running org.apache.hadoop.fs.s3a.commit.integration.ITestS3ACommitterMRJob [INFO] Running org.apache.hadoop.fs.s3a.commit.integration.ITestS3ACommitterMRJob [INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.97 s\n[ASF GitHub Bot @ 2025-09-15T17:46:46.890+0000]: steveloughran commented on PR #7968: URL: https://github.com/apache/hadoop/pull/7968#issuecomment-3293285487 fyi @slfan1989 @ahmarsuhail @mukund-thakur one of the final nits of junit5 migration\n[ASF GitHub Bot @ 2025-09-15T21:37:08.520+0000]: hadoop-yetus commented on PR #7968: URL: https://github.com/apache/hadoop/pull/7968#issuecomment-3294044978 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 34s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 1s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 1s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 11m 17s | | Maven dependency ordering for branch | | +1 :green_heart: | mvninstall | 41m 11s | | trunk passed | | +1 :green_heart: | compile | 15m 54s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 13m 34s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 4m 12s | | trunk passed | | +1 :green_heart: | mvnsite | 2m 0s | | trunk passed | | +1 :green_heart: | javadoc | 1m 44s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 1m 38s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 3m 2s | | trunk passed | | +1 :green_heart: | shadedclient | 36m 28s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 35s | | Maven dependency ordering for patch | | +1 :green_heart: | mvninstall | 1m 7s | | the patch passed | | +1 :green_heart: | compile | 15m 15s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 15m 15s | | the patch passed | | +1 :green_heart: | compile | 13m 37s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 13m 37s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | -0 :warning: | checkstyle | 4m 17s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/artifact/out/results-checkstyle-root.txt) | root: The patch generated 1 new + 45 unchanged - 1 fixed = 46 total (was 46) | | +1 :green_heart: | mvnsite | 1m 58s | | the patch passed | | +1 :green_heart: | javadoc | 1m 40s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 1m 38s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 3m 21s | | the patch passed | | +1 :green_heart: | shadedclient | 36m 11s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 9m 58s | | hadoop-mapreduce-client-core in the patch passed. | | +1 :green_heart: | unit | 3m 47s | | hadoop-aws in the patch passed. | | +1 :green_heart: | asflicense | 1m 8s | | The patch does not generate ASF License warnings. | | | | 230m 49s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7968 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux 0d73de768dd4 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / a86c300286ffb8cd8884923b5d6a0deaf9095d63 | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/testReport/ | | Max. process+thread count | 1567 (vs. ulimit of 5500) | | modules | C: hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-tools/hadoop-aws U: . | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7968/1/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-15T23:59:34.234+0000]: slfan1989 commented on PR #7968: URL: https://github.com/apache/hadoop/pull/7968#issuecomment-3294374360 LGTM\n[ASF GitHub Bot @ 2025-09-16T12:04:51.044+0000]: steveloughran merged PR #7968: URL: https://github.com/apache/hadoop/pull/7968","key":"HADOOP-19688","status":"Resolved","labels":"pull-request-available"}
{"summary":"Upgrade nimbus-jose-jwt to 10.0.2+ due to CVE-2025-53864","created":"2025-09-15T11:29:00.000+0000","description":"*CVE-2025-53864:*\r\n\r\nConnect2id Nimbus JOSE + JWT before 10.0.2 allows a remote attacker to cause a denial of service via a deeply nested JSON object supplied in a JWT claim set, because of uncontrolled recursion. NOTE: this is independent of the Gson 2.11.0 issue because the Connect2id product could have checked the JSON object nesting depth, regardless of what limits (if any) were imposed by Gson.\r\n\r\nSeverity: 6.9 (medium)","assignee":"","priority":"Major","updated":"2025-09-17T10:25:28.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-15T11:36:57.169+0000]: rohit-kb opened a new pull request, #7965: URL: https://github.com/apache/hadoop/pull/7965 <!-- Thanks for sending a pull request! 1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute 2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'. --> ### Description of PR 1. Bumping nimbus-jose-jwt to 10.4 due to CVEs 2. com.github.stephenc.jcip:jcip-annotations is being shaded and is no more a transitive dependency from nimbus starting from versions 9.38, so we can add it as an explicit dependency. ### How was this patch tested? ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[PJ Fanning @ 2025-09-15T12:11:10.556+0000]: duplicate of HADOOP-19632 for which there are already PRs\n[ASF GitHub Bot @ 2025-09-17T10:08:17.170+0000]: rohit-kb commented on PR #7965: URL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302275652 Hi @pjfanning, can we use this patch instead of the original one as I don't see any progress on that? We need this upgrade in the downstream soon. Also, it seems like the original patch hasn't handled the shading of com.github.stephenc.jcip:jcip-annotations in later nimbus versions. Thanks\n[ASF GitHub Bot @ 2025-09-17T10:17:25.975+0000]: pjfanning commented on PR #7965: URL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302315128 Could you rebase this to force a new CI run? The tests crashed in the last run.\n[ASF GitHub Bot @ 2025-09-17T10:25:27.971+0000]: pjfanning commented on PR #7965: URL: https://github.com/apache/hadoop/pull/7965#issuecomment-3302343034 Could you change the name of the PR and the git commit to use [HADOOP-19632](https://issues.apache.org/jira/browse/HADOOP-19632)?","key":"HADOOP-19687","status":"Resolved","labels":"pull-request-available"}
{"summary":"Clover breaks on double semicolon","created":"2025-09-12T20:38:19.000+0000","description":"Building with {{-Pclover}} fails with\r\n{code}\r\n[INFO] Instrumentation error\r\ncom.atlassian.clover.api.CloverException: /home/jenkins/hadoop/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ITestS3APutIfMatchAndIfNoneMatch.java:43:43:unexpected token: ;\r\n...\r\nFailed to execute goal org.openclover:clover-maven-plugin:4.4.1:setup (clover-setup) on project hadoop-aws: Clover has failed to instrument the source files in the [/home/jenkins/hadoop/hadoop-tools/hadoop-aws/target/clover/src-test-instrumented] directory -> [Help 1]\r\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.openclover:clover-maven-plugin:4.4.1:setup (clover-setup) on project hadoop-aws: Clover has failed to instrument the source files in the [/home/jenkins/hadoop/hadoop-tools/hadoop-aws/target/clover/src-test-instrumented] directory\r\n{code}\r\n\r\nIt doesn't seem to like a double semicolon in ITestS3APutIfMatchAndIfNoneMatch.java that was added in HADOOP-19256.","assignee":"Michael Smith","priority":"Major","updated":"2025-09-12T23:48:23.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-12T20:49:51.569+0000]: MikaelSmith opened a new pull request, #7956: URL: https://github.com/apache/hadoop/pull/7956 ### Description of PR Removes the extra semicolon after an import that causes `-Pclover` to fail with com.atlassian.clover.api.CloverException: hadoop/hadoop-tools/ hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/impl/ ITestS3APutIfMatchAndIfNoneMatch.java:43:43:unexpected token: ;` ### How was this patch tested? ``` mvn -e -Pclover install -DskipTests -DskipShade --projects 'hadoop-tools/hadoop-aws' ``` ### For code changes: - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-12T23:11:11.091+0000]: hadoop-yetus commented on PR #7956: URL: https://github.com/apache/hadoop/pull/7956#issuecomment-3287077606 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 15m 13s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | | +1 :green_heart: | test4tests | 0m 0s | | The patch appears to include 1 new or modified test files. | |||| _ trunk Compile Tests _ | | +1 :green_heart: | mvninstall | 39m 40s | | trunk passed | | +1 :green_heart: | compile | 0m 45s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | compile | 0m 38s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | checkstyle | 0m 34s | | trunk passed | | +1 :green_heart: | mvnsite | 0m 44s | | trunk passed | | +1 :green_heart: | javadoc | 0m 43s | | trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 36s | | trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 1m 10s | | trunk passed | | +1 :green_heart: | shadedclient | 35m 27s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +1 :green_heart: | mvninstall | 0m 31s | | the patch passed | | +1 :green_heart: | compile | 0m 37s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javac | 0m 37s | | the patch passed | | +1 :green_heart: | compile | 0m 28s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | javac | 0m 28s | | the patch passed | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | checkstyle | 0m 22s | | the patch passed | | +1 :green_heart: | mvnsite | 0m 33s | | the patch passed | | +1 :green_heart: | javadoc | 0m 29s | | the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 | | +1 :green_heart: | javadoc | 0m 25s | | the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | +1 :green_heart: | spotbugs | 1m 9s | | the patch passed | | +1 :green_heart: | shadedclient | 34m 38s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | unit | 3m 21s | | hadoop-aws in the patch passed. | | +1 :green_heart: | asflicense | 0m 39s | | The patch does not generate ASF License warnings. | | | | 140m 9s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7956 | | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets | | uname | Linux d1403c764b02 5.15.0-152-generic #162-Ubuntu SMP Wed Jul 23 09:48:42 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 9fc528eeb6112dd9b3209b648fb33da720214dff | | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 | | Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/testReport/ | | Max. process+thread count | 709 (vs. ulimit of 5500) | | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7956/1/console | | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-12T23:47:23.404+0000]: cnauroth closed pull request #7956: HADOOP-19685. Fix double semicolon breaking clover URL: https://github.com/apache/hadoop/pull/7956\n[ASF GitHub Bot @ 2025-09-12T23:48:09.653+0000]: cnauroth commented on PR #7956: URL: https://github.com/apache/hadoop/pull/7956#issuecomment-3287154332 I committed this to trunk and branch-3.4. Thank you for the patch @MikaelSmith !","key":"HADOOP-19685","status":"Resolved","labels":"pull-request-available"}
{"summary":"Add JDK 21 to Ubuntu 20.04 docker development images","created":"2025-09-10T14:00:14.000+0000","description":"We want to support JDK21, we better have it available in the development image for testing.\r\n","assignee":"Istvan Toth","priority":"Major","updated":"2025-09-14T07:14:28.000+0000","commentText":"[ASF GitHub Bot @ 2025-09-10T14:19:26.843+0000]: stoty opened a new pull request, #7947: URL: https://github.com/apache/hadoop/pull/7947 ### Description of PR Add JDK 21 to Ubuntu 20.04 and 24.04 docker development images ### How was this patch tested? Built the default image locally and started JDK21. ### For code changes: - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')? - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation? - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\n[ASF GitHub Bot @ 2025-09-10T14:25:20.405+0000]: hadoop-yetus commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3275227945 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 0s | | Docker mode activated. | | -1 :x: | docker | 1m 32s | | Docker failed to build run-specific yetus/hadoop:tp-5188}. | | Subsystem | Report/Notes | |----------:|:-------------| | GITHUB PR | https://github.com/apache/hadoop/pull/7947 | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/1/console | | versions | git=2.34.1 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-11T12:33:39.929+0000]: pan3793 commented on code in PR #7947: URL: https://github.com/apache/hadoop/pull/7947#discussion_r2340621524 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -268,17 +268,20 @@ ], \"ubuntu:focal\": [ \"temurin-24-jdk\", + \"temurin-21-jdk\", Review Comment: the ubuntu official apt repo provides `openjdk-21-jdk`, it's unnecessary to install from 3rd party. let's use the official one and put it at the end of the list.\n[ASF GitHub Bot @ 2025-09-11T12:34:17.562+0000]: pan3793 commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3280408907 The Jenkins failure should be fixed by https://github.com/apache/hadoop/pull/7938, @slfan1989 can you help merging that to unblock this patch?\n[ASF GitHub Bot @ 2025-09-11T13:16:38.729+0000]: stoty commented on code in PR #7947: URL: https://github.com/apache/hadoop/pull/7947#discussion_r2340811930 ########## dev-support/docker/pkg-resolver/packages.json: ########## @@ -268,17 +268,20 @@ ], \"ubuntu:focal\": [ \"temurin-24-jdk\", + \"temurin-21-jdk\", Review Comment: Thanks. Done @pan3793 .\n[ASF GitHub Bot @ 2025-09-11T13:20:02.259+0000]: hadoop-yetus commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3280638248 :broken_heart: **-1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 0s | | Docker mode activated. | | -1 :x: | docker | 1m 21s | | Docker failed to build run-specific yetus/hadoop:tp-1035}. | | Subsystem | Report/Notes | |----------:|:-------------| | GITHUB PR | https://github.com/apache/hadoop/pull/7947 | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/2/console | | versions | git=2.34.1 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-11T22:59:32.390+0000]: slfan1989 commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3282893605 > The Jenkins failure should be fixed by #7938, @slfan1989 can you help merge that to unblock this patch? @stoty I\u2019ve already merged #7938 into the trunk branch, so we can move forward with this PR.\n[ASF GitHub Bot @ 2025-09-12T03:53:55.775+0000]: stoty commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283557198 restarted CI\n[ASF GitHub Bot @ 2025-09-12T05:41:42.071+0000]: hadoop-yetus commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283756503 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 25m 28s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 9m 48s | | Maven dependency ordering for branch | | +1 :green_heart: | shadedclient | 46m 30s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 45s | | Maven dependency ordering for patch | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 36m 2s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 56s | | The patch does not generate ASF License warnings. | | | | 111m 23s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7947 | | Optional Tests | dupname asflicense codespell detsecrets jsonlint | | uname | Linux 68e70612efec 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d | | Max. process+thread count | 708 (vs. ulimit of 5500) | | modules | C: U: | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console | | versions | git=2.43.7 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-12T05:57:53.642+0000]: slfan1989 commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3283820061 The CI results meet expectations. I will proceed with merging the change shortly.\n[ASF GitHub Bot @ 2025-09-12T06:56:49.782+0000]: hadoop-yetus commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3284002090 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 20m 27s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 0m 35s | | Maven dependency ordering for branch | | +1 :green_heart: | shadedclient | 26m 20s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 30s | | Maven dependency ordering for patch | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 25m 38s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 35s | | The patch does not generate ASF License warnings. | | | | 74m 57s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7947 | | Optional Tests | dupname asflicense codespell detsecrets jsonlint | | uname | Linux 26f820c8794f 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d | | modules | C: U: | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console | | versions | git=2.30.2 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-12T08:08:47.595+0000]: hadoop-yetus commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3284223003 :confetti_ball: **+1 overall** | Vote | Subsystem | Runtime | Logfile | Comment | |:----:|----------:|--------:|:--------:|:-------:| | +0 :ok: | reexec | 0m 33s | | Docker mode activated. | |||| _ Prechecks _ | | +1 :green_heart: | dupname | 0m 0s | | No case conflicting files found. | | +0 :ok: | codespell | 0m 0s | | codespell was not available. | | +0 :ok: | detsecrets | 0m 0s | | detect-secrets was not available. | | +0 :ok: | jsonlint | 0m 0s | | jsonlint was not available. | | +1 :green_heart: | @author | 0m 0s | | The patch does not contain any @author tags. | |||| _ trunk Compile Tests _ | | +0 :ok: | mvndep | 0m 34s | | Maven dependency ordering for branch | | +1 :green_heart: | shadedclient | 34m 46s | | branch has no errors when building and testing our client artifacts. | |||| _ Patch Compile Tests _ | | +0 :ok: | mvndep | 0m 32s | | Maven dependency ordering for patch | | +1 :green_heart: | blanks | 0m 0s | | The patch has no blanks issues. | | +1 :green_heart: | shadedclient | 33m 55s | | patch has no errors when building and testing our client artifacts. | |||| _ Other Tests _ | | +1 :green_heart: | asflicense | 0m 36s | | The patch does not generate ASF License warnings. | | | | 71m 51s | | | | Subsystem | Report/Notes | |----------:|:-------------| | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/artifact/out/Dockerfile | | GITHUB PR | https://github.com/apache/hadoop/pull/7947 | | Optional Tests | dupname asflicense codespell detsecrets jsonlint | | uname | Linux cedf7863bb64 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux | | Build tool | maven | | Personality | dev-support/bin/hadoop.sh | | git revision | trunk / 4ed7fc2da756cc4332d3f9ecc8cce291d094b50d | | Max. process+thread count | 567 (vs. ulimit of 5500) | | modules | C: U: | | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7947/3/console | | versions | git=2.25.1 maven=3.6.3 | | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org | This message was automatically generated.\n[ASF GitHub Bot @ 2025-09-14T07:11:03.021+0000]: slfan1989 merged PR #7947: URL: https://github.com/apache/hadoop/pull/7947\n[ASF GitHub Bot @ 2025-09-14T07:11:29.823+0000]: slfan1989 commented on PR #7947: URL: https://github.com/apache/hadoop/pull/7947#issuecomment-3289299477 @stoty Thanks for the contribution! @pan3793 Thanks for the review!","key":"HADOOP-19684","status":"Resolved","labels":"pull-request-available"}
{"summary":"Fix incorrect link from current3 of hadoop-site","created":"2025-09-09T03:15:33.000+0000","description":"Fix hadoop site incorrect link which reported by https://lists.apache.org/thread/ozvkh0x7qdr8d3vr0tbm5g7jx1jprbct.","assignee":"Xiaoqiao He","priority":"Major","updated":"2025-09-09T03:57:52.000+0000","commentText":"","key":"HADOOP-19682","status":"Resolved","labels":"pull-request-available"}
